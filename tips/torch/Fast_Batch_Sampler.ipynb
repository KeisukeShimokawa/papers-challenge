{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fast Batch Sampler.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjFnPPDs0OHt/qMHotrZkN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeisukeShimokawa/papers-challenge/blob/master/tips/torch/Fast_Batch_Sampler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luteGih1XUFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doRaUCA3Xbea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = torch.randn(1000000,10)\n",
        "labels = torch.randint(low=0, high=10, size=(1000000,))\n",
        "batch_size = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaaLa1TlXlM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_loader(loader):\n",
        "    for inputs, labels in loader:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7XUSPRTXe9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0b78246-807c-48e6-d333-e881c83137fe"
      },
      "source": [
        "dataset = torch.utils.data.TensorDataset(inputs, labels)\n",
        "loader1 = torch.utils.data.DataLoader(dataset,\n",
        "                                      batch_size=batch_size,\n",
        "                                      shuffle=True)\n",
        "\n",
        "%timeit -n1 -r1 run_loader(loader1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 1: 6.69 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5pxaBmSYy3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Sampler\n",
        "from torch._six import int_classes as _int_classes\n",
        "\n",
        "\n",
        "class CustomBatchSampler(Sampler):\n",
        "    r\"\"\"Wraps another sampler to yield a mini-batch of indices.\n",
        "    Args:\n",
        "        sampler (Sampler): Base sampler.\n",
        "        batch_size (int): Size of mini-batch.\n",
        "        drop_last (bool): If ``True``, the sampler will drop the last batch if\n",
        "            its size would be less than ``batch_size``\n",
        "    Example:\n",
        "        >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))\n",
        "        [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n",
        "        >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))\n",
        "        [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sampler, batch_size, drop_last):\n",
        "        if not isinstance(sampler, Sampler):\n",
        "            raise ValueError(\"sampler should be an instance of \"\n",
        "                             \"torch.utils.data.Sampler, but got sampler={}\"\n",
        "                             .format(sampler))\n",
        "        if not isinstance(batch_size, _int_classes) or isinstance(batch_size, bool) or \\\n",
        "                batch_size <= 0:\n",
        "            raise ValueError(\"batch_size should be a positive integer value, \"\n",
        "                             \"but got batch_size={}\".format(batch_size))\n",
        "        if not isinstance(drop_last, bool):\n",
        "            raise ValueError(\"drop_last should be a boolean value, but got \"\n",
        "                             \"drop_last={}\".format(drop_last))\n",
        "        self.sampler = sampler\n",
        "        self.batch_size = batch_size\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "    def __iter__(self):\n",
        "        # convert to list comprehension\n",
        "        batch = [idx for counter, idx in enumerate(self.sampler)\n",
        "                 if counter < self.batch_size]\n",
        "        if len(batch) == self.batch_size:\n",
        "            yield batch\n",
        "            batch = []\n",
        "        if len(batch) > 0 and not self.drop_last:\n",
        "            yield batch\n",
        "\n",
        "    # def __iter__(self):\n",
        "    #     batch = []\n",
        "    #     for idx in self.sampler:\n",
        "    #         batch.append(idx)\n",
        "    #         if len(batch) == self.batch_size:\n",
        "    #             yield batch\n",
        "    #             batch = []\n",
        "    #     if len(batch) > 0 and not self.drop_last:\n",
        "    #         yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.drop_last:\n",
        "            return len(self.sampler) // self.batch_size\n",
        "        else:\n",
        "            return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygwo3JyAbPVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_sampler = CustomBatchSampler(\n",
        "    torch.utils.data.RandomSampler(dataset),\n",
        "    batch_size=batch_size,\n",
        "    drop_last=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-BYbH-DXoaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c9eed11-52a4-4425-ec42-3a2435e9e5c9"
      },
      "source": [
        "dataset = torch.utils.data.TensorDataset(inputs, labels)\n",
        "loader2 = torch.utils.data.DataLoader(dataset,\n",
        "                                      batch_sampler=batch_sampler)\n",
        "\n",
        "%timeit -n1 -r1 run_loader(loader2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 1: 270 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22waTk6vX9XH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}