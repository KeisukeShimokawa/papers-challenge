{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RealnessGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBtVSMvPGA0mT6Nuv/k04v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeisukeShimokawa/papers-challenge/blob/master/src/gan/RealnessGAN/notebooks/RealnessGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZQPacauOKNF",
        "colab_type": "text"
      },
      "source": [
        "`src/gan/RealnessGAN/notebooks/RealnessGAN.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6XTF1ISt7If",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "7ee09d52-57c1-415f-ec97-676ac73126e6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon May 11 15:17:51 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8f9p6mVs7Xd",
        "colab_type": "text"
      },
      "source": [
        "## Kullback-Leibler Divergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HivYmfeqp_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AySILriX5SrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1LrXPY85QL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8007b556-3b9a-4b63-8d82-70e65c750fc1"
      },
      "source": [
        "!pip freeze | grep torch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch==1.5.0+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.6.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oGVjbFQq6RE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = torch.Tensor([0.1, 0.2, 0.3, 0.4, 0.1])\n",
        "q = torch.Tensor([0.1, 0.6, 0.2, 0.1, 0.1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHnHqDd6rt_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "fb206745-6651-4166-fd51-1c98ebf72908"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.bar(np.arange(len(p)), p.numpy(), color=\"blue\", alpha=0.5);\n",
        "ax.bar(np.arange(len(q)), q.numpy(), color=\"red\", alpha=0.5);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg6OR2bvsdI5",
        "colab_type": "text"
      },
      "source": [
        "continous variables\n",
        "\n",
        "$$D_{K L}(p \\| q)=\\int_{-\\infty}^{\\infty} p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right) d x$$\n",
        "\n",
        "discrete variables\n",
        "\n",
        "$$D_{K L}(p \\| q)=\\sum_{x \\in X} p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOHc8NG3wpn2",
        "colab_type": "text"
      },
      "source": [
        "### simple mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yq0I2CbsE5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence_torch(p, q):\n",
        "    return (p * (p / q).log()).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqMXBY37scrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence_torch_nn(p, q):\n",
        "    kl_div = nn.KLDivLoss(size_average=None, reduce=None, reduction=\"mean\")\n",
        "    return kl_div(q.log(), p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdNPnuUhtTa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence_torch_func(p, q):\n",
        "    return F.kl_div(q.log(), p, size_average=None, reduce=None, reduction=\"mean\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR3720ystmjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2909c46-8dbe-444c-d243-0cb287009414"
      },
      "source": [
        "kl_divergence_torch(p, q)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0913)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQE0De8qtvbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "79707f3a-cc10-45e2-bdec-2d0e951d3c74"
      },
      "source": [
        "kl_divergence_torch_nn(p, q)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2247: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0913)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRP4Hw4Ptxgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "787afde9-7f48-493b-91fe-2cdb67ff04c7"
      },
      "source": [
        "kl_divergence_torch_func(p, q)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2247: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0913)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O20iLDezt2tb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5bd4ba4c-87c0-4665-cde7-10eb57fbc0ab"
      },
      "source": [
        "%timeit kl_divergence_torch(p, q)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 23.11 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100000 loops, best of 3: 13.9 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJfA3_GBuDuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f820b05d-655c-480d-e84c-b3232dc18202"
      },
      "source": [
        "%timeit kl_divergence_torch_nn(p, q)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2247: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 49.89 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 3: 47.5 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb1zncgQuFa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2591fe18-28a8-4526-beac-f6df4f23e2c5"
      },
      "source": [
        "%timeit kl_divergence_torch_func(p, q)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2247: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 20.08 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 3: 28 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjzL5cG1wm-U",
        "colab_type": "text"
      },
      "source": [
        "### batchmean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxfu1QR1wzdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = torch.Tensor([[0.1, 0.2, 0.3, 0.4, 0.1], \n",
        "                  [0.1, 0.2, 0.2, 0.3, 0.2]])\n",
        "q = torch.Tensor([[0.1, 0.6, 0.2, 0.1, 0.1], \n",
        "                  [0.3, 0.1, 0.2, 0.3, 0.1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpcccsPCxDHr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "739ef45d-9691-4ef7-cb1d-8d08ea2ec68f"
      },
      "source": [
        "p.sum(dim=-1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1000, 1.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gj_6qxrxE2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35f1607a-c051-4a3f-cda6-c60f7324a406"
      },
      "source": [
        "q.sum(dim=-1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1000, 1.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQdIL5adyRWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence_torch(p, q):\n",
        "    return (p * (p / q).log()).sum() / p.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENiQjuRluIjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence_torch_nn(p, q):\n",
        "    kl_div = nn.KLDivLoss(size_average=None, reduce=None, reduction=\"batchmean\")\n",
        "    return kl_div(q.log(), p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV5qv__-wyoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kl_divergence_torch_func(p, q):\n",
        "    return F.kl_div(q.log(), p, size_average=None, reduce=None, reduction=\"batchmean\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ56wdDQybuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "316428d0-165a-486b-f239-bb8ad2d72c51"
      },
      "source": [
        "kl_divergence_torch(p, q)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3119)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M9Ehke2xT6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "087567f8-fe38-44bf-9733-76cea17beaeb"
      },
      "source": [
        "kl_divergence_torch_nn(p, q)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3119)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xs93FfQxWOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b34699d-6c86-473f-acbe-8baac6db2e07"
      },
      "source": [
        "kl_divergence_torch_func(p, q)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3119)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JWy8KI2xz2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmV5qMsQzYYv",
        "colab_type": "text"
      },
      "source": [
        "## test_z_vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFYYFZisxzy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ef54605-46a1-421f-d802-8ff15a2e9783"
      },
      "source": [
        "!wget -q https://www.dropbox.com/s/9nnjsnyekb6glru/z_test_32_128.pickle -O test_z_vec.pickle\n",
        "!ls"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  test_z_vec.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1z4IavHxzvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"test_z_vec.pickle\", \"rb\") as f:\n",
        "    test_z_vec = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnysYcpSxY5e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f57c0edf-4946-4047-a412-2fa91251a965"
      },
      "source": [
        "print(test_z_vec.size())\n",
        "print(test_z_vec.dtype)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 128, 1, 1])\n",
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSSICr2bz8FU",
        "colab_type": "text"
      },
      "source": [
        "## CelebA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7zSb7elz8B_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data\n",
        "!wget -q https://www.dropbox.com/s/j6tp062e14gg5yc/img_align_celeba.zip -O data/celeba.zip\n",
        "!unzip -q -o -d ./data data/celeba.zip\n",
        "!rm -rf data/celeba.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-RRT0fsz7-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ec9c32c-4f89-4243-bc22-bbdb1fb273bc"
      },
      "source": [
        "import glob\n",
        "\n",
        "print(len(glob.glob(\"data/img_align_celeba/*\")))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "202599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6CWg0Vkz774",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp704MEuxYes",
        "colab_type": "text"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsNyPL7z5AAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej_f-qpx0y1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGAN_G(nn.Module):\n",
        "    def __init__(self, im_size, z_dim, g_dim, out_dim):\n",
        "        super(DCGAN_G, self).__init__()\n",
        "\n",
        "        mult = im_size // 8\n",
        "\n",
        "        # start block\n",
        "        self.start = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, g_dim * mult, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(g_dim * mult),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        # middel block\n",
        "        middle = []\n",
        "        while mult > 1:\n",
        "            middle.append(nn.ConvTranspose2d(g_dim * mult, g_dim * (mult//2), kernel_size=4, stride=2, \n",
        "                                             padding=1, bias=False))\n",
        "            middle.append(nn.BatchNorm2d(g_dim * (mult//2)))\n",
        "            middle.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            mult = mult // 2\n",
        "        self.middle = nn.Sequential(*middle)\n",
        "\n",
        "        # end block\n",
        "        self.end = nn.Sequential(\n",
        "            nn.ConvTranspose2d(g_dim, out_dim, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.start(input)\n",
        "        out = self.middle(out)\n",
        "        out = self.end(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj1bPAPy0yyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "63b62ef7-196a-4afd-aa6b-e80328332d11"
      },
      "source": [
        "summary(DCGAN_G(128, 128, 128, 3).to(device), (128, 1, 1))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "   ConvTranspose2d-1           [-1, 2048, 4, 4]       4,194,304\n",
            "       BatchNorm2d-2           [-1, 2048, 4, 4]           4,096\n",
            "         LeakyReLU-3           [-1, 2048, 4, 4]               0\n",
            "   ConvTranspose2d-4           [-1, 1024, 8, 8]      33,554,432\n",
            "       BatchNorm2d-5           [-1, 1024, 8, 8]           2,048\n",
            "         LeakyReLU-6           [-1, 1024, 8, 8]               0\n",
            "   ConvTranspose2d-7          [-1, 512, 16, 16]       8,388,608\n",
            "       BatchNorm2d-8          [-1, 512, 16, 16]           1,024\n",
            "         LeakyReLU-9          [-1, 512, 16, 16]               0\n",
            "  ConvTranspose2d-10          [-1, 256, 32, 32]       2,097,152\n",
            "      BatchNorm2d-11          [-1, 256, 32, 32]             512\n",
            "        LeakyReLU-12          [-1, 256, 32, 32]               0\n",
            "  ConvTranspose2d-13          [-1, 128, 64, 64]         524,288\n",
            "      BatchNorm2d-14          [-1, 128, 64, 64]             256\n",
            "        LeakyReLU-15          [-1, 128, 64, 64]               0\n",
            "  ConvTranspose2d-16          [-1, 3, 128, 128]           6,144\n",
            "             Tanh-17          [-1, 3, 128, 128]               0\n",
            "================================================================\n",
            "Total params: 48,772,864\n",
            "Trainable params: 48,772,864\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 24.00\n",
            "Params size (MB): 186.05\n",
            "Estimated Total Size (MB): 210.05\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzcE0IhY5otk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfIDBT9Y0yvJ",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVRBq9R659qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils import spectral_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x36fHx-k0ysD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGAN_D(nn.Module):\n",
        "    def __init__(self, im_size, in_dim, d_dim, n_outcomes, use_adaptive_reparam=True):\n",
        "        super(DCGAN_D, self).__init__()\n",
        "\n",
        "        self.n_outcomes = n_outcomes\n",
        "        self.use_adaptive_reparam = use_adaptive_reparam\n",
        "        image_size_new = im_size // 2\n",
        "\n",
        "        # start block\n",
        "        self.start = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(in_dim, d_dim, kernel_size=4, stride=2, padding=1, bias=False)),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        # middle block\n",
        "        mult = 1\n",
        "        middle = []\n",
        "        while image_size_new > 4:\n",
        "            middle.append(spectral_norm(nn.Conv2d(d_dim * mult, d_dim * (2*mult), kernel_size=4, stride=2, padding=1, bias=False)))\n",
        "            middle.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            image_size_new = image_size_new // 2\n",
        "            mult *= 2\n",
        "\n",
        "        self.middle = nn.Sequential(*middle)\n",
        "        self.mult = mult\n",
        "\n",
        "        # end block\n",
        "        self.in_size  = int(d_dim * mult * 4 * 4)\n",
        "        self.out_size = n_outcomes\n",
        "        self.end = spectral_norm(nn.Linear(self.in_size, self.out_size, bias=False))\n",
        "\n",
        "        # resampling trick\n",
        "        self.reparam = spectral_norm(nn.Linear(self.in_size, self.out_size * 2, bias=False))\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.start(input)\n",
        "        y = self.middle(out)\n",
        "\n",
        "        b, c, h, w = y.size()\n",
        "        y = y.view(b, -1)\n",
        "        \n",
        "        output = self.end(y).view(-1, self.n_outcomes)\n",
        "\n",
        "        # re-parameterization trick\n",
        "        if self.use_adaptive_reparam:\n",
        "            # [B, 2*outcomes, 1, 1]\n",
        "            stat_tuple = self.reparam(y).unsqueeze(2).unsqueeze(3)\n",
        "            # [B, outcomes, 1, 1], [B, outcomes, 1, 1]\n",
        "            mu, logvar = stat_tuple.chunk(2, 1)\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            epsilon = torch.randn(input.shape[0], self.n_outcomes, 1, 1).to(stat_tuple)\n",
        "            output = epsilon.mul(std).add_(mu).view(-1, self.n_outcomes)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xneSQ1w-0yo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "8a2030a3-18bf-4216-ad9d-6e8a2fea97f1"
      },
      "source": [
        "summary(DCGAN_D(128, 3, 128, 20, True).to(device), (3, 128, 128))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 128, 64, 64]           6,144\n",
            "         LeakyReLU-2          [-1, 128, 64, 64]               0\n",
            "            Conv2d-3          [-1, 256, 32, 32]         524,288\n",
            "         LeakyReLU-4          [-1, 256, 32, 32]               0\n",
            "            Conv2d-5          [-1, 512, 16, 16]       2,097,152\n",
            "         LeakyReLU-6          [-1, 512, 16, 16]               0\n",
            "            Conv2d-7           [-1, 1024, 8, 8]       8,388,608\n",
            "         LeakyReLU-8           [-1, 1024, 8, 8]               0\n",
            "            Conv2d-9           [-1, 2048, 4, 4]      33,554,432\n",
            "        LeakyReLU-10           [-1, 2048, 4, 4]               0\n",
            "           Linear-11                   [-1, 20]         655,360\n",
            "           Linear-12                   [-1, 40]       1,310,720\n",
            "================================================================\n",
            "Total params: 46,536,704\n",
            "Trainable params: 46,536,704\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 15.50\n",
            "Params size (MB): 177.52\n",
            "Estimated Total Size (MB): 193.21\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUrSTe040yl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-DMOb79810j",
        "colab_type": "text"
      },
      "source": [
        "## Trainer: Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw-o-q-X81xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learnG_Realness(cfg, D, G, optimizerG, random_sample, \n",
        "                    Triplet_Loss, x, anchor1, anchor0):\n",
        "    is_cuda = cfg.cuda and torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda:0\" if is_cuda else \"cpu\")\n",
        "\n",
        "    z = torch.FloatTensor(cfg.batch_size, cfg.z_size, 1, 1)\n",
        "    z = z.to(device)\n",
        "\n",
        "    G.train()\n",
        "    for p in D.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    for t in range(cfg.g_updates):\n",
        "        G.zero_grad()\n",
        "        optimizerG.zero_grad()\n",
        "\n",
        "        # gradients are accumulated through subiters\n",
        "        for _ in range(cfg.effective_batch_size // cfg.batch_size):\n",
        "            images, _ = random_sample.__next__()\n",
        "            x.copy_(images)\n",
        "            del images\n",
        "\n",
        "            num_outcomes = Triplet_Loss.atoms\n",
        "            anchor_real = torch.zeros((x.shape[0], num_outcomes), dtype=torch.float).to(device) + \\\n",
        "                          torch.tensor(anchor1, dtype=torch.float).to(device)\n",
        "            anchor_fake = torch.zeros((x.shape[0], num_outcomes), dtype=torch.float).to(device) + \\\n",
        "                          torch.tensor(anchor0, dtype=torch.float).to(device)\n",
        "\n",
        "            # real images\n",
        "            feat_real = D(x).log_softmax(1).exp()\n",
        "\n",
        "            # fake images\n",
        "            z.normal_(0, 1)\n",
        "            imgs_fake = G(z)\n",
        "            feat_fake = D(imgs_fake).log_softmax(1).exp()\n",
        "\n",
        "            # compute loss\n",
        "            if cfg.relativisticG:\n",
        "                lossG = - Triplet_Loss(anchor_fake, feat_fake, skewness=cfg.negative_skew) + \\\n",
        "                          Triplet_Loss(feat_real, feat_fake)\n",
        "            else:\n",
        "                lossG = - Triplet_Loss(anchor_fake, feat_fake, skewness=cfg.negative_skew) + \\\n",
        "                          Triplet_Loss(anchor_real, feat_fake, skewness=cfg.positive_skew)\n",
        "            lossG.backward()\n",
        "\n",
        "        optimizerG.step()\n",
        "    \n",
        "    return lossG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1QbCqP0_ls3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JqMZXLQ81ul",
        "colab_type": "text"
      },
      "source": [
        "## Trainer: Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcHA2qnL0yiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learnD_Realness(cfg, D, G, optimizerD, random_sample, \n",
        "                    Triplet_Loss, x, anchor1, anchor0):\n",
        "    is_cuda = cfg.cuda and torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda:0\" if is_cuda else \"cpu\")\n",
        "\n",
        "    z = torch.FloatTensor(cfg.batch_size, cfg.z_size, 1, 1)\n",
        "    z = z.to(device)\n",
        "\n",
        "    for p in D.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    for t in range(cfg.d_updates):\n",
        "        D.zero_grad()\n",
        "        optimizerD.zero_grad()\n",
        "\n",
        "        # gradients are accumulated through subiters\n",
        "        for _ in range(cfg.effective_batch_size // cfg.batch_size):\n",
        "            images, _ = random_sample.__next__()\n",
        "            num_outcomes = Triplet_Loss.atoms\n",
        "            x.copy_(images)\n",
        "            del images\n",
        "\n",
        "            anchor_real = torch.zeros((x.shape[0], num_outcomes), dtype=torch.float).to(device) + \\\n",
        "                          torch.tensor(anchor1, dtype=torch.float).to(device)\n",
        "            anchor_fake = torch.zeros((x.shape[0], num_outcomes), dtype=torch.float).to(device) + \\\n",
        "                          torch.tensor(anchor0, dtype=torch.float).to(device)\n",
        "\n",
        "            # real images\n",
        "            feat_real = D(x).log_softmax(1).exp()\n",
        "\n",
        "            # fake images\n",
        "            z.normal_(0, 1)\n",
        "            imgs_fake = G(z)\n",
        "            feat_fake = D(imgs_fake.detach()).log_softmax(1).exp()\n",
        "\n",
        "            lossD_real = Triplet_Loss(anchor_real, feat_real, skewness=cfg.positive_skew)\n",
        "            lossD_real.backward()\n",
        "\n",
        "            lossD_fake = Triplet_Loss(anchor_fake, feat_fake, skewness=cfg.negative_skew)\n",
        "            lossD_fake.backward()\n",
        "\n",
        "            lossD = lossD_real + lossD_fake\n",
        "\n",
        "        optimizerD.step()\n",
        "\n",
        "    return lossD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5827zx9_r1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tDjWxQ4AQ4j",
        "colab_type": "text"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Lrc0_pAQ5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CategoricalLoss(nn.Module):\n",
        "    def __init__(self, atoms=51, v_max=10, v_min=-10):\n",
        "        super(CategoricalLoss, self).__init__()\n",
        "\n",
        "        self.atoms = atoms\n",
        "        self.v_max = v_max\n",
        "        self.v_min = v_min\n",
        "        self.supports = torch.linspace(v_min, v_max, atoms).view(1, 1, atoms) # RL: [bs, #action, #quantiles]\n",
        "        self.delta = (v_max - v_min) / (atoms - 1)\n",
        "\n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        self.supports = self.supports.to(device)\n",
        "\n",
        "    def forward(self, anchor, feature, skewness=0.0):\n",
        "        batch_size = feature.shape[0]\n",
        "        skew = torch.zeros((batch_size, self.atoms)).to(self.device).fill_(skewness)\n",
        "\n",
        "        # experiment to adjust KL divergence between positive/negative anchors\n",
        "        Tz = skew + self.supports.view(1, -1) * torch.ones((batch_size, 1)).to(torch.float).view(-1, 1).to(self.device)\n",
        "        Tz = Tz.clamp(self.v_min, self.v_max)\n",
        "        b = (Tz - self.v_min) / self.delta\n",
        "        l = b.floor().to(torch.int64)\n",
        "        u = b.ceil().to(torch.int64)\n",
        "        l[(u > 0) * (l == u)] -= 1\n",
        "        u[(l < (self.atoms - 1)) * (l == u)] += 1\n",
        "        offset = torch.linspace(0, (batch_size - 1) * self.atoms, batch_size).to(torch.int64).unsqueeze(dim=1).expand(batch_size, self.atoms).to(self.device)\n",
        "        skewed_anchor = torch.zeros(batch_size, self.atoms).to(self.device)\n",
        "        skewed_anchor.view(-1).index_add_(0, (l + offset).view(-1), (anchor * (u.float() - b)).view(-1))  \n",
        "        skewed_anchor.view(-1).index_add_(0, (u + offset).view(-1), (anchor * (b - l.float())).view(-1))  \n",
        "\n",
        "        loss = -(skewed_anchor * (feature + 1e-16).log()).sum(-1).mean()\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9gDI106ARAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FheHxywyAQ9z",
        "colab_type": "text"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIqwPtUDArZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import datetime\n",
        "import numpy as np\n",
        "from scipy.stats import skewnorm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EFprpYeAQ6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_now(cmd, file=None):\n",
        "    time_now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    if file is None:\n",
        "        print('%s %s' % (time_now, cmd))\n",
        "    else:\n",
        "        print_str = '%s %s' % (time_now, cmd)\n",
        "        print(print_str, file=file)\n",
        "    sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63JpxcJEBF2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVV6YgaUBFxC",
        "colab_type": "text"
      },
      "source": [
        "### config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwBH0uoIBQE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulWi9bibBH4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e6b5732-b036-41fb-aac7-81f8c20dc9d3"
      },
      "source": [
        "%%writefile config.yml\n",
        "\n",
        "data_path: \"data/\"\n",
        "seed: 42\n",
        "effective_batch_size: 32\n",
        "batch_size: 32\n",
        "image_size: 128\n",
        "n_channels: 3\n",
        "\n",
        "z_size: 128\n",
        "g_dim: 128\n",
        "d_dim: 128\n",
        "lr_G: 0.0001\n",
        "lr_D: 0.0001\n",
        "total_iters: 100000\n",
        "g_updates: 1\n",
        "d_updates: 1\n",
        "\n",
        "adam_eps: 0.000000001\n",
        "beta1: 0.5\n",
        "beta2: 0.999\n",
        "decay: 0\n",
        "weight_decay: 0\n",
        "\n",
        "cuda: True\n",
        "n_gpu: 1\n",
        "num_workers: 4\n",
        "\n",
        "gen_extra_images: 50000\n",
        "gen_every: 100000\n",
        "print_every: 1000\n",
        "\n",
        "positive_skew: 1.0\n",
        "negative_skew: -1.0\n",
        "num_outcomes: 20\n",
        "relativisticG: True\n",
        "use_adaptive_reparam: True"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing config.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD4pw_1JEvjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DotDict(dict): \n",
        "    def __init__(self, *args, **kwargs): \n",
        "        super().__init__(*args, **kwargs) \n",
        "        self.__dict__ = self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI8NrCWsBH1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"config.yml\", \"r\") as f:\n",
        "    cfg = DotDict(yaml.load(f))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRg77Eq-0yQ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "fb320376-321e-421b-fef1-a0bf0f7e5e3a"
      },
      "source": [
        "cfg"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'adam_eps': 1e-09,\n",
              " 'batch_size': 32,\n",
              " 'beta1': 0.5,\n",
              " 'beta2': 0.999,\n",
              " 'cuda': True,\n",
              " 'd_dim': 128,\n",
              " 'd_updates': 1,\n",
              " 'data_path': 'data/',\n",
              " 'decay': 0,\n",
              " 'effective_batch_size': 32,\n",
              " 'g_dim': 128,\n",
              " 'g_updates': 1,\n",
              " 'gen_every': 100000,\n",
              " 'gen_extra_images': 50000,\n",
              " 'image_size': 128,\n",
              " 'lr_D': 0.0001,\n",
              " 'lr_G': 0.0001,\n",
              " 'n_channels': 3,\n",
              " 'n_gpu': 1,\n",
              " 'negative_skew': -1.0,\n",
              " 'num_outcomes': 20,\n",
              " 'num_workers': 4,\n",
              " 'positive_skew': 1.0,\n",
              " 'print_every': 1000,\n",
              " 'relativisticG': True,\n",
              " 'seed': 42,\n",
              " 'total_iters': 100000,\n",
              " 'use_adaptive_reparam': True,\n",
              " 'weight_decay': 0,\n",
              " 'z_size': 128}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNFBJ7RnE3-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RprnNvTPE37-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_torch(cfg.seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzdmK4oEFN-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTauLCzLFeDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trans = transforms.Compose([\n",
        "    transforms.Resize((cfg.image_size, cfg.image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5TLJzQbFN7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# celeba\n",
        "dataset = datasets.ImageFolder(cfg.data_path, transform=trans)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0fo3tcHECCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataProvider:\n",
        "    def __init__(self, data):\n",
        "        self.data_loader = None\n",
        "        self.iter = None\n",
        "        self.data = data\n",
        "        self.data_loader = None\n",
        "\n",
        "    def build_loader(self, batch_size, num_workers):\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.data_loader = DataLoader(self.data, batch_size=batch_size, shuffle=True, \n",
        "                                      drop_last=True, num_workers=num_workers)\n",
        "        self.iter = iter(self.data_loader)\n",
        "    \n",
        "    def __next__(self):\n",
        "        try:\n",
        "            return self.iter.next()\n",
        "        except StopIteration:  # reload when an epoch finishes\n",
        "            self.build_loader(self.batch_size, self.num_workers)\n",
        "            return self.iter.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmUcVA5MF-dH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_sample = DataProvider(dataset)\n",
        "random_sample.build_loader(cfg.batch_size, cfg.num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjjPX7dlGwXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = DCGAN_G(cfg.image_size, cfg.z_size, cfg.g_dim, cfg.n_channels)\n",
        "D = DCGAN_D(cfg.image_size, cfg.n_channels, cfg.d_dim, cfg.num_outcomes, cfg.use_adaptive_reparam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFFn9X8bHVRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Triplet_Loss = CategoricalLoss(atoms=cfg.num_outcomes, \n",
        "                               v_max=cfg.positive_skew, \n",
        "                               v_min=cfg.negative_skew)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9O9NnayHVOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if cfg.n_gpu > 1:\n",
        "    G = nn.DataParallel(G)\n",
        "    D = nn.DataParallel(D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gW5vxA3HlOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaj5BQ7eHlLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G.apply(weights_init);\n",
        "D.apply(weights_init);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a_gYJSyHT4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "647a7d20-c6e1-4302-8da7-c21632e4d9b9"
      },
      "source": [
        "test_z_vec.size()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMODgLMQHuar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "G = G.to(device)\n",
        "D = D.to(device)\n",
        "Triplet_Loss.to(device)\n",
        "test_z_vec = test_z_vec.to(device)\n",
        "x = torch.FloatTensor(cfg.batch_size, cfg.n_channels, cfg.image_size, cfg.image_size).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKWqA46uHubc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizerD = torch.optim.Adam(D.parameters(), lr=cfg.lr_D, betas=(cfg.beta1, cfg.beta2), weight_decay=cfg.weight_decay, eps=cfg.adam_eps)\n",
        "optimizerG = torch.optim.Adam(G.parameters(), lr=cfg.lr_G, betas=(cfg.beta1, cfg.beta2), weight_decay=cfg.weight_decay)\n",
        "decayD = torch.optim.lr_scheduler.ExponentialLR(optimizerD, gamma=1-cfg.decay)\n",
        "decayG = torch.optim.lr_scheduler.ExponentialLR(optimizerG, gamma=1-cfg.decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qq57qnBHuce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# e.g. normal and uniform\n",
        "gauss = np.random.normal(0, 0.1, 1000)\n",
        "count, bins = np.histogram(gauss, cfg.num_outcomes)\n",
        "anchor0 = count / sum(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecw9YE8sIzIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "6823e61a-c84c-4cc3-e3a6-04f566575904"
      },
      "source": [
        "plt.bar(np.arange(len(anchor0)), anchor0)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 20 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86iDkczeIsTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unif = np.random.uniform(-1, 1, 1000)\n",
        "count, bins = np.histogram(unif, cfg.num_outcomes)\n",
        "anchor1 = count / sum(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8j8hvw8IsQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7f3c8393-788c-447e-94dd-01b513d19be1"
      },
      "source": [
        "plt.bar(np.arange(len(anchor0)), anchor1)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 20 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQCyqo88JLmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import utils as vutils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8TUFvSSQjSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "image_path = Path(\"images\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3RoJMCXQsei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUO9nkjWIsN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = time.time()\n",
        "base_dir = \"sample\"\n",
        "current_set_images = 0\n",
        "iter_offset = 0\n",
        "\n",
        "samples = []\n",
        "for i in range(iter_offset, cfg.total_iters):\n",
        "    D.train()\n",
        "    G.train()\n",
        "\n",
        "    # save training progress\n",
        "    if (i+1) % cfg.print_every == 0:\n",
        "        G.eval()\n",
        "        with torch.no_grad():\n",
        "            fake_test = G(test_z_vec)\n",
        "            vutils.save_image(fake_test.data, f'images/fake_samples_iter{i+1:04}.png', normalize=True)\n",
        "        G.train()\n",
        "\n",
        "    lossD = learnD_Realness(cfg, D, G, optimizerD, random_sample, Triplet_Loss, x, anchor1, anchor0)\n",
        "    lossG = learnG_Realness(cfg, D, G, optimizerG, random_sample, Triplet_Loss, x, anchor1, anchor0)\n",
        "\n",
        "    decayD.step()\n",
        "    decayG.step()\n",
        "\n",
        "    # print progress\n",
        "    if i < 1000 or (i+1) % 100 == 0:\n",
        "        end = time.time()\n",
        "        fmt = '[%d / %d] SD: %d Diff: %.4f loss_D: %.4f loss_G: %.4f time:%.2f'\n",
        "        s = fmt % (i+1, cfg.total_iters, cfg.seed,\n",
        "                    -lossD.data.item() + lossG.data.item() if (lossD is not None) and (lossG is not None) else -1.0,\n",
        "                    lossD.data.item()                      if lossD is not None else -1.0,\n",
        "                    lossG.data.item()                      if lossG is not None else -1.0,\n",
        "                    end - start)\n",
        "\n",
        "    # generate extra images\n",
        "    if (i+1) % cfg.gen_every == 0:\n",
        "        current_set_images += 1\n",
        "        # if not os.path.exists('%s/models/' % (param.extra_folder)):\n",
        "        #     os.mkdir('%s/models/' % (param.extra_folder))\n",
        "        # torch.save({\n",
        "        #     'i': i + 1,\n",
        "        #     'current_set_images': current_set_images,\n",
        "        #     'G_state': G.state_dict(),\n",
        "        #     'D_state': D.state_dict(),\n",
        "        #     'G_optimizer': optimizerG.state_dict(),\n",
        "        #     'D_optimizer': optimizerD.state_dict(),\n",
        "        #     'G_scheduler': decayG.state_dict(),\n",
        "        #     'D_scheduler': decayD.state_dict(),\n",
        "        #     'z_test': z_test,\n",
        "        # }, '%s/models/state_%02d.pth' % (param.extra_folder, current_set_images))\n",
        "        # print_now('Model saved.')\n",
        "\n",
        "        # if os.path.exists('%s/%01d/' % (param.extra_folder, current_set_images)):\n",
        "        #     for root, dirs, files in os.walk('%s/%01d/' % (param.extra_folder, current_set_images)):\n",
        "        #         for f in files:\n",
        "        #             os.unlink(os.path.join(root, f))\n",
        "        # else:\n",
        "        #     os.mkdir('%s/%01d/' % (param.extra_folder, current_set_images))\n",
        "\n",
        "        # G.eval()\n",
        "        # extra_batch = 100 if cfg.image_size <= 256 else cfg.batch_size\n",
        "        # with torch.no_grad():param\n",
        "        #     ext_curr = 0\n",
        "        #     z_extra = torch.FloatTensor(extra_batch, cfg.z_size, 1, 1)\n",
        "        #     z_extra = z_extra.to(device)\n",
        "        #     for ext in range(int(cfg.gen_extra_images/extra_batch)):\n",
        "        #         fake_test = G(z_extra.normal_(0, 1)) \n",
        "                    \n",
        "        #         for ext_i in range(fake_test.size(0)):start = time.time()\n",
        "        #             vutils.save_image((fake_test[ext_i]*.50)+.50, '%s/%01d/fake_samples_%05d.png' % (param.extra_folder, current_set_images, ext_curr),\n",
        "        #                 normalize=False, padding=0)\n",
        "        #             ext_curr += 1\n",
        "        #     del z_extra\n",
        "        #     del fake_test\n",
        "        G.train()\n",
        "        # print_now('Finished generating extra samples at iteration %d'%((i+1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inZ1gxqRIsKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFPfDoUQHuKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}