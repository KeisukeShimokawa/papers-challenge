{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VectorQuantizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM61PZLMXxANR8oUXecDiEE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6727ecf8889443a7bbff63a62667925e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0da1406e59af48058f047100c7d1a886",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e292a8af7ec44cd8ae08227170a7cd4f",
              "IPY_MODEL_fe61109823124397b661ce95f3475f20"
            ]
          }
        },
        "0da1406e59af48058f047100c7d1a886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e292a8af7ec44cd8ae08227170a7cd4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e3c0c1467146463ead540a6e72ee3eee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27e54298f74f412893fe519cbba84f25"
          }
        },
        "fe61109823124397b661ce95f3475f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d887e3f6974c4195b85e129270d23087",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 16454730.66it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef339de6ad474e7f8cce5ba593608617"
          }
        },
        "e3c0c1467146463ead540a6e72ee3eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27e54298f74f412893fe519cbba84f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d887e3f6974c4195b85e129270d23087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef339de6ad474e7f8cce5ba593608617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeisukeShimokawa/papers-challenge/blob/master/src/gan/FQGAN/notebooks/VectorQuantizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw20n75RRmW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqH-2AXDRmSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS9DacfKAIBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters_float32(model):\n",
        "    param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    param_mb = param / 1024 / 1024 / 8 * 32\n",
        "    return param_mb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGr6_novRYFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VectorQuantizer(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_dim=64, num_emb=2**10, commitment=0.25):\n",
        "        super(VectorQuantizer, self).__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_emb = num_emb\n",
        "        self.commitment = commitment\n",
        "        self.embedding = nn.Parameter(torch.randn(emb_dim, num_emb))\n",
        "\n",
        "        self.register_buffer(\"cluster_size\", torch.zeros(self.num_emb))\n",
        "        self.register_buffer(\"ema_embedding\", self.embedding.clone())\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        # [B, C=D, H, W] --> [B, H, W, C=D]\n",
        "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
        "        inputs_shape = inputs.size()\n",
        "\n",
        "        # [B, H, W, D] --> [N(=BxHxW), D]\n",
        "        flatten = inputs.view(-1, self.emb_dim)\n",
        "\n",
        "        # distance d(H[N, D], E[D, K]) --> d[N, K]\n",
        "        # each element show the distance between Hj and Ei\n",
        "        distance = (\n",
        "            flatten.pow(2).sum(1, keepdim=True)\n",
        "            -2 * flatten @ self.embedding\n",
        "            + self.embedding.pow(2).sum(0, keepdim=True)\n",
        "        )\n",
        "\n",
        "        # embedding_idx: [N, K] --> [N, ]\n",
        "        embedding_idx = torch.argmin(distance, dim=1)\n",
        "        # embedding_idx: [N, ] --> [B, H, W, ]\n",
        "        embedding_idx = embedding_idx.view(*inputs_shape[:-1])\n",
        "        # quantize: [B, H, W, ] --> [B, H, W, D]\n",
        "        quantize = F.embedding(embedding_idx, self.embedding.transpose(0, 1))\n",
        "\n",
        "        # loss\n",
        "        e_latent_loss = F.mse_loss(quantize.detach(), inputs)\n",
        "        q_latent_loss = F.mse_loss(quantize, inputs.detach())\n",
        "        loss = q_latent_loss + self.commitment * e_latent_loss\n",
        "\n",
        "        quantize = inputs + (quantize - inputs).detach()\n",
        "        quantize = quantize.permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "        return quantize, loss, embedding_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmXOLkidjBwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VectorQuantizerEMA(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_dim=64, num_emb=2**10, commitment=1.0, decay=0.9, eps=1e-5):\n",
        "        super(VectorQuantizerEMA, self).__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_emb = num_emb\n",
        "        self.commitment = commitment\n",
        "        self.decay = decay\n",
        "        self.eps = eps\n",
        "\n",
        "        embedding = nn.Parameter(torch.randn(emb_dim, num_emb))\n",
        "        self.register_buffer(\"embedding\", embedding)\n",
        "        self.register_buffer(\"cluster_size\", torch.zeros(self.num_emb))\n",
        "        self.register_buffer(\"ema_embedding\", self.embedding.clone())\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # [B, C=D, H, W] --> [B, H, W, C=D]\n",
        "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
        "        inputs_shape = inputs.size()\n",
        "\n",
        "        # [B, H, W, D] --> [N(=BxHxW), D]\n",
        "        flatten = inputs.view(-1, self.emb_dim)\n",
        "\n",
        "        # distance d(H[N, D], E[D, K]) --> d[N, K]\n",
        "        # each element show the distance between Hj and Ei\n",
        "        distance = (\n",
        "            flatten.pow(2).sum(1, keepdim=True)\n",
        "            -2 * flatten @ self.embedding\n",
        "            + self.embedding.pow(2).sum(0, keepdim=True)\n",
        "        )\n",
        "\n",
        "        # embedding_idx: [N, K] --> [N, ]\n",
        "        embedding_idx = torch.argmin(distance, dim=1)\n",
        "        # embedding_onthot: [N, ] --> [N, K]\n",
        "        embedding_onehot = F.one_hot(embedding_idx, self.num_emb).type(flatten.dtype)\n",
        "        # embedding_idx: [N, ] --> [B, H, W, ]\n",
        "        embedding_idx = embedding_idx.view(*inputs_shape[:-1])\n",
        "        # quantize: [B, H, W, ] --> [B, H, W, D]\n",
        "        quantize = F.embedding(embedding_idx, self.embedding.transpose(0, 1))\n",
        "\n",
        "        if self.training:\n",
        "            self.cluster_size.mul_(self.decay).add_(\n",
        "                1-self.decay, embedding_onehot.sum(0)\n",
        "            )\n",
        "            dw = flatten.transpose(0, 1) @ embedding_onehot\n",
        "            self.ema_embedding.data.mul_(self.decay).add_(1-self.decay, dw)\n",
        "            n = self.cluster_size.sum()\n",
        "            smoother_cluster_size = (\n",
        "                (self.cluster_size + self.eps) / (n + self.num_emb * self.eps) * n\n",
        "            )\n",
        "            embedding_norm = self.ema_embedding / smoother_cluster_size.unsqueeze(0)\n",
        "            self.embedding.data.copy_(embedding_norm)\n",
        "\n",
        "        # loss\n",
        "        e_latent_loss = F.mse_loss(quantize.detach(), inputs)\n",
        "        loss = self.commitment * e_latent_loss\n",
        "\n",
        "        quantize = inputs + (quantize - inputs).detach()\n",
        "        quantize = quantize.permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "        return quantize, loss, embedding_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLnoXz5Rw30S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaAvRjCswGbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, nc):\n",
        "        super(Generator, self).__init__()\n",
        "        self.nz = nz\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = input.view(-1, self.nz, 1, 1)\n",
        "        output = self.main(input)\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVlBn07RwGYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79e2d250-9fd7-4cda-880e-fd9b320f48bf"
      },
      "source": [
        "Generator(100, 64, 3)(torch.randn(10, 100)).shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 64, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP5cvbAOAKOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "294498d8-c483-4a9b-def5-b988c51cce03"
      },
      "source": [
        "count_parameters_float32(Generator(100, 64, 3))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.64404296875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQIPs_GLw0aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf, emb_dim, num_emb):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        \n",
        "        self.conv_pre1 = nn.Conv2d(ndf * 1, emb_dim, 1, 1, 0)\n",
        "        self.vq1 = VectorQuantizerEMA(emb_dim, num_emb)\n",
        "        self.conv_pos1 = nn.Conv2d(emb_dim, ndf * 1, 1, 1, 0)\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        \n",
        "        self.conv_pre2 = nn.Conv2d(ndf * 2, emb_dim, 1, 1, 0)\n",
        "        self.vq2 = VectorQuantizerEMA(emb_dim, num_emb)\n",
        "        self.conv_pos2 = nn.Conv2d(emb_dim, ndf * 2, 1, 1, 0)\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "        self.conv_pre3 = nn.Conv2d(ndf * 4, emb_dim, 1, 1, 0)\n",
        "        self.vq3 = VectorQuantizerEMA(emb_dim, num_emb)\n",
        "        self.conv_pos3 = nn.Conv2d(emb_dim, ndf * 4, 1, 1, 0)\n",
        "\n",
        "        self.layer4 = nn.Sequential(\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.layer5 = nn.Sequential(\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        total_loss = torch.tensor(0.0)\n",
        "\n",
        "        output = self.layer1(input)\n",
        "        pre = self.conv_pre1(output)\n",
        "        quantize, loss, embedding_idx = self.vq1(pre); total_loss += loss\n",
        "        pos = self.conv_pos1(quantize)\n",
        "\n",
        "        output = self.layer2(pos)\n",
        "        pre = self.conv_pre2(output)\n",
        "        quantize, loss, embedding_idx = self.vq2(pre); total_loss += loss\n",
        "        pos = self.conv_pos2(quantize)\n",
        "\n",
        "        output = self.layer3(pos)\n",
        "        pre = self.conv_pre3(output)\n",
        "        quantize, loss, embedding_idx = self.vq3(pre); total_loss += loss\n",
        "        pos = self.conv_pos3(quantize)\n",
        "\n",
        "        output = self.layer4(pos)\n",
        "        output = self.layer5(output)\n",
        "        return output.view(-1, 1).squeeze(1), pre, quantize, loss, embedding_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGsa2Mi0w0Wy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b423cd4d-cadd-4d40-82cf-d5f8289a0998"
      },
      "source": [
        "Discriminator(3, 64, 128, 2**10)(torch.randn(10, 3, 64, 64))[0].shape, \\\n",
        "Discriminator(3, 64, 128, 2**10)(torch.randn(10, 3, 64, 64))[1].shape, \\\n",
        "Discriminator(3, 64, 128, 2**10)(torch.randn(10, 3, 64, 64))[2].shape, \\\n",
        "# Discriminator(3, 64, 128, 2**10)(torch.randn(10, 3, 64, 64))[3].shape, \\\n",
        "Discriminator(3, 64, 128, 2**10)(torch.randn(10, 3, 64, 64))[4].shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 8, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD0BWRyO3Rq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ee0f449-f0e2-494a-9aff-94a5e39f3220"
      },
      "source": [
        "Discriminator(3, 64, 128, 2**10)(torch.randn(10, 3, 64, 64))[3]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7769, grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfxu_N98AOpL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c80b290-aff4-40f3-eb47-c605d860b1b5"
      },
      "source": [
        "count_parameters_float32(Discriminator(3, 64, 128, 2**10))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.990478515625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOefEwxOw0Ti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "287501e0-d1c3-412f-9e19-260bc3861ef2"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mWwry5ty9qU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "79753c3f-2b92-436b-fe8a-65d3f82a597b"
      },
      "source": [
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "nc = 3\n",
        "emb_dim = 256\n",
        "num_emb = 2**10\n",
        "\n",
        "netG = Generator(nz, ngf, nc).to(device)\n",
        "netG.apply(weights_init)\n",
        "\n",
        "netD = Discriminator(nc, ndf, emb_dim, num_emb).to(device)\n",
        "netD.apply(weights_init)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv_pre1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (vq1): VectorQuantizerEMA()\n",
              "  (conv_pos1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv_pre2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (vq2): VectorQuantizerEMA()\n",
              "  (conv_pos2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv_pre3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (vq3): VectorQuantizerEMA()\n",
              "  (conv_pos3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (layer4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (layer5): Sequential(\n",
              "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MyEfxody9ni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "6727ecf8889443a7bbff63a62667925e",
            "0da1406e59af48058f047100c7d1a886",
            "e292a8af7ec44cd8ae08227170a7cd4f",
            "fe61109823124397b661ce95f3475f20",
            "e3c0c1467146463ead540a6e72ee3eee",
            "27e54298f74f412893fe519cbba84f25",
            "d887e3f6974c4195b85e129270d23087",
            "ef339de6ad474e7f8cce5ba593608617"
          ]
        },
        "outputId": "3c4c967f-4ca4-4537-afd2-74da7a41186a"
      },
      "source": [
        "from torchvision import datasets as dsets\n",
        "from torchvision import transforms\n",
        "from torchvision import utils as vutils\n",
        "\n",
        "\n",
        "dataset = dsets.CIFAR10(\n",
        "    root=\"./data\", \n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize(64),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        ")\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size=128,\n",
        "    shuffle=True, \n",
        "    num_workers=int(4))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6727ecf8889443a7bbff63a62667925e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnyHKHXty9ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "fixed_noise = torch.randn(128, nz, 1, 1, device=device)\n",
        "real_label = 1\n",
        "fake_label = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emMLlGOVy9iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYEm8ybC4V6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "Path(\"./output\").mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df_A5DHiy9fJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7121dfa8-c04f-4f1c-bc67-6de82db01e4a"
      },
      "source": [
        "n_epochs = 200\n",
        "n_dis = 4\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        # for i in range(n_dis):\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        # train with real\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data[0].to(device)\n",
        "        batch_size = real_cpu.size(0)\n",
        "        label = torch.full((batch_size,), real_label, device=device)\n",
        "        # Quantize\n",
        "        output, pre_real, quant_real, loss_quant_real, embedding_idx_real = netD(real_cpu)\n",
        "        errD_real = criterion(output, label)\n",
        "        lossD_real = errD_real +  loss_quant_real\n",
        "        lossD_real.backward()\n",
        "        D_x = output.sigmoid().mean().item()\n",
        "\n",
        "        # train with fake\n",
        "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        # Quantize\n",
        "        output, pre_fake, quant_fake, loss_quant_fake, embedding_idx_fake = netD(fake.detach())\n",
        "        errD_fake = criterion(output, label)\n",
        "        lossD_fake = errD_fake +  loss_quant_fake\n",
        "        lossD_fake.backward()\n",
        "        D_G_z1 = output.sigmoid().mean().item()\n",
        "\n",
        "        # total loss\n",
        "        errD = lossD_real + lossD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Quantize\n",
        "        output, pre_G, quant_G, loss_quant_G, embedding_idx_G = netD(fake)\n",
        "        errG = criterion(output, label)\n",
        "        lossG = errG + loss_quant_G\n",
        "        lossG.backward()\n",
        "        D_G_z2 = output.sigmoid().mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
        "              % (epoch, n_epochs, i, len(dataloader),\n",
        "                 errD.item(), lossG.item(), D_x, D_G_z1, D_G_z2))\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            vutils.save_image(real_cpu,\n",
        "                    '%s/real_samples.png' % \"./output\",\n",
        "                    normalize=True)\n",
        "            fake = netG(fixed_noise)\n",
        "            vutils.save_image(fake.detach(),\n",
        "                    '%s/amp_fake_samples_epoch_%03d.png' % (\"./output\", epoch),\n",
        "                    normalize=True)\n",
        "\n",
        "    # do checkpointing\n",
        "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (\"./output\", epoch))\n",
        "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (\"./output\", epoch))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/TensorFactories.cpp:361: UserWarning: Deprecation warning: In a future PyTorch release torch.full will no longer return tensors of floating dtype by default. Instead, a bool fill_value will return a tensor of torch.bool dtype, and an integral fill_value will return a tensor of torch.long dtype. Set the optional `dtype` or `out` arguments to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0/200][0/391] Loss_D: 3.6452 Loss_G: 5.8925 D(x): 0.0944 D(G(z)): 0.2351 / 0.0029\n",
            "[0/200][1/391] Loss_D: 6.0402 Loss_G: 0.1530 D(x): 0.0026 D(G(z)): 0.0025 / 0.8924\n",
            "[0/200][2/391] Loss_D: 2.5503 Loss_G: 1.0516 D(x): 0.9008 D(G(z)): 0.9063 / 0.3639\n",
            "[0/200][3/391] Loss_D: 1.5445 Loss_G: 0.7530 D(x): 0.3623 D(G(z)): 0.3610 / 0.4909\n",
            "[0/200][4/391] Loss_D: 1.4692 Loss_G: 0.5629 D(x): 0.4906 D(G(z)): 0.4904 / 0.5939\n",
            "[0/200][5/391] Loss_D: 1.5069 Loss_G: 1.2051 D(x): 0.5942 D(G(z)): 0.5946 / 0.3125\n",
            "[0/200][6/391] Loss_D: 1.6231 Loss_G: 0.2715 D(x): 0.3102 D(G(z)): 0.3081 / 0.7949\n",
            "[0/200][7/391] Loss_D: 1.9098 Loss_G: 1.9501 D(x): 0.7964 D(G(z)): 0.7977 / 0.1484\n",
            "[0/200][8/391] Loss_D: 2.1626 Loss_G: 0.2819 D(x): 0.1464 D(G(z)): 0.1446 / 0.7870\n",
            "[0/200][9/391] Loss_D: 1.8794 Loss_G: 1.2055 D(x): 0.7881 D(G(z)): 0.7892 / 0.3126\n",
            "[0/200][10/391] Loss_D: 1.6237 Loss_G: 0.5244 D(x): 0.3109 D(G(z)): 0.3094 / 0.6177\n",
            "[0/200][11/391] Loss_D: 1.5295 Loss_G: 0.9238 D(x): 0.6180 D(G(z)): 0.6183 / 0.4143\n",
            "[0/200][12/391] Loss_D: 1.5006 Loss_G: 0.5818 D(x): 0.4133 D(G(z)): 0.4125 / 0.5832\n",
            "[0/200][13/391] Loss_D: 1.4998 Loss_G: 0.9599 D(x): 0.5833 D(G(z)): 0.5835 / 0.3995\n",
            "[0/200][14/391] Loss_D: 1.5118 Loss_G: 0.4880 D(x): 0.3986 D(G(z)): 0.3978 / 0.6404\n",
            "[0/200][15/391] Loss_D: 1.5552 Loss_G: 1.2519 D(x): 0.6410 D(G(z)): 0.6415 / 0.2983\n",
            "[0/200][16/391] Loss_D: 1.6492 Loss_G: 0.3025 D(x): 0.2970 D(G(z)): 0.2959 / 0.7708\n",
            "[0/200][17/391] Loss_D: 1.8262 Loss_G: 1.7147 D(x): 0.7720 D(G(z)): 0.7731 / 0.1878\n",
            "[0/200][18/391] Loss_D: 1.9696 Loss_G: 0.2794 D(x): 0.1863 D(G(z)): 0.1849 / 0.7889\n",
            "[0/200][19/391] Loss_D: 1.8861 Loss_G: 1.3415 D(x): 0.7901 D(G(z)): 0.7911 / 0.2728\n",
            "[0/200][20/391] Loss_D: 1.7040 Loss_G: 0.4567 D(x): 0.2715 D(G(z)): 0.2704 / 0.6608\n",
            "[0/200][21/391] Loss_D: 1.5831 Loss_G: 1.0058 D(x): 0.6615 D(G(z)): 0.6621 / 0.3816\n",
            "[0/200][22/391] Loss_D: 1.5285 Loss_G: 0.5587 D(x): 0.3808 D(G(z)): 0.3800 / 0.5967\n",
            "[0/200][23/391] Loss_D: 1.5100 Loss_G: 0.9313 D(x): 0.5970 D(G(z)): 0.5972 / 0.4111\n",
            "[0/200][24/391] Loss_D: 1.5025 Loss_G: 0.5646 D(x): 0.4104 D(G(z)): 0.4098 / 0.5930\n",
            "[0/200][25/391] Loss_D: 1.5065 Loss_G: 0.9730 D(x): 0.5933 D(G(z)): 0.5935 / 0.3942\n",
            "[0/200][26/391] Loss_D: 1.5157 Loss_G: 0.5073 D(x): 0.3935 D(G(z)): 0.3928 / 0.6278\n",
            "[0/200][27/391] Loss_D: 1.5391 Loss_G: 1.1145 D(x): 0.6283 D(G(z)): 0.6287 / 0.3421\n",
            "[0/200][28/391] Loss_D: 1.5749 Loss_G: 0.4090 D(x): 0.3412 D(G(z)): 0.3404 / 0.6924\n",
            "[0/200][29/391] Loss_D: 1.6332 Loss_G: 1.3267 D(x): 0.6932 D(G(z)): 0.6939 / 0.2766\n",
            "[0/200][30/391] Loss_D: 1.6930 Loss_G: 0.3460 D(x): 0.2756 D(G(z)): 0.2747 / 0.7373\n",
            "[0/200][31/391] Loss_D: 1.7295 Loss_G: 1.3553 D(x): 0.7382 D(G(z)): 0.7390 / 0.2688\n",
            "[0/200][32/391] Loss_D: 1.7109 Loss_G: 0.3880 D(x): 0.2678 D(G(z)): 0.2670 / 0.7071\n",
            "[0/200][33/391] Loss_D: 1.6608 Loss_G: 1.1729 D(x): 0.7078 D(G(z)): 0.7085 / 0.3226\n",
            "[0/200][34/391] Loss_D: 1.6041 Loss_G: 0.4692 D(x): 0.3216 D(G(z)): 0.3207 / 0.6519\n",
            "[0/200][35/391] Loss_D: 1.5676 Loss_G: 1.0466 D(x): 0.6524 D(G(z)): 0.6527 / 0.3660\n",
            "[0/200][36/391] Loss_D: 1.5436 Loss_G: 0.5165 D(x): 0.3653 D(G(z)): 0.3647 / 0.6218\n",
            "[0/200][37/391] Loss_D: 1.5319 Loss_G: 1.0026 D(x): 0.6223 D(G(z)): 0.6227 / 0.3825\n",
            "[0/200][38/391] Loss_D: 1.5257 Loss_G: 0.5219 D(x): 0.3818 D(G(z)): 0.3813 / 0.6184\n",
            "[0/200][39/391] Loss_D: 1.5277 Loss_G: 1.0171 D(x): 0.6187 D(G(z)): 0.6191 / 0.3768\n",
            "[0/200][40/391] Loss_D: 1.5309 Loss_G: 0.5030 D(x): 0.3762 D(G(z)): 0.3757 / 0.6299\n",
            "[0/200][41/391] Loss_D: 1.5397 Loss_G: 1.0582 D(x): 0.6304 D(G(z)): 0.6308 / 0.3615\n",
            "[0/200][42/391] Loss_D: 1.5476 Loss_G: 0.4768 D(x): 0.3609 D(G(z)): 0.3604 / 0.6465\n",
            "[0/200][43/391] Loss_D: 1.5591 Loss_G: 1.1044 D(x): 0.6470 D(G(z)): 0.6474 / 0.3451\n",
            "[0/200][44/391] Loss_D: 1.5683 Loss_G: 0.4547 D(x): 0.3445 D(G(z)): 0.3439 / 0.6608\n",
            "[0/200][45/391] Loss_D: 1.5782 Loss_G: 1.1287 D(x): 0.6613 D(G(z)): 0.6617 / 0.3368\n",
            "[0/200][46/391] Loss_D: 1.5799 Loss_G: 0.4533 D(x): 0.3361 D(G(z)): 0.3354 / 0.6616\n",
            "[0/200][47/391] Loss_D: 1.5789 Loss_G: 1.1104 D(x): 0.6620 D(G(z)): 0.6625 / 0.3429\n",
            "[0/200][48/391] Loss_D: 1.5707 Loss_G: 0.4710 D(x): 0.3422 D(G(z)): 0.3416 / 0.6498\n",
            "[0/200][49/391] Loss_D: 1.5620 Loss_G: 1.0704 D(x): 0.6502 D(G(z)): 0.6506 / 0.3569\n",
            "[0/200][50/391] Loss_D: 1.5517 Loss_G: 0.4918 D(x): 0.3562 D(G(z)): 0.3556 / 0.6363\n",
            "[0/200][51/391] Loss_D: 1.5445 Loss_G: 1.0361 D(x): 0.6367 D(G(z)): 0.6371 / 0.3692\n",
            "[0/200][52/391] Loss_D: 1.5365 Loss_G: 0.5081 D(x): 0.3687 D(G(z)): 0.3681 / 0.6258\n",
            "[0/200][53/391] Loss_D: 1.5320 Loss_G: 1.0187 D(x): 0.6262 D(G(z)): 0.6266 / 0.3756\n",
            "[0/200][54/391] Loss_D: 1.5288 Loss_G: 0.5064 D(x): 0.3750 D(G(z)): 0.3744 / 0.6267\n",
            "[0/200][55/391] Loss_D: 1.5325 Loss_G: 1.0362 D(x): 0.6272 D(G(z)): 0.6275 / 0.3690\n",
            "[0/200][56/391] Loss_D: 1.5356 Loss_G: 0.4934 D(x): 0.3684 D(G(z)): 0.3678 / 0.6348\n",
            "[0/200][57/391] Loss_D: 1.5412 Loss_G: 1.0561 D(x): 0.6352 D(G(z)): 0.6357 / 0.3616\n",
            "[0/200][58/391] Loss_D: 1.5438 Loss_G: 0.4857 D(x): 0.3610 D(G(z)): 0.3604 / 0.6396\n",
            "[0/200][59/391] Loss_D: 1.5466 Loss_G: 1.0564 D(x): 0.6401 D(G(z)): 0.6405 / 0.3614\n",
            "[0/200][60/391] Loss_D: 1.5436 Loss_G: 0.4926 D(x): 0.3609 D(G(z)): 0.3604 / 0.6350\n",
            "[0/200][61/391] Loss_D: 1.5406 Loss_G: 1.0333 D(x): 0.6355 D(G(z)): 0.6358 / 0.3698\n",
            "[0/200][62/391] Loss_D: 1.5334 Loss_G: 0.5084 D(x): 0.3693 D(G(z)): 0.3688 / 0.6249\n",
            "[0/200][63/391] Loss_D: 1.5285 Loss_G: 1.0055 D(x): 0.6253 D(G(z)): 0.6256 / 0.3801\n",
            "[0/200][64/391] Loss_D: 1.5216 Loss_G: 0.5234 D(x): 0.3796 D(G(z)): 0.3792 / 0.6154\n",
            "[0/200][65/391] Loss_D: 1.5179 Loss_G: 0.9819 D(x): 0.6157 D(G(z)): 0.6160 / 0.3890\n",
            "[0/200][66/391] Loss_D: 1.5122 Loss_G: 0.5362 D(x): 0.3887 D(G(z)): 0.3883 / 0.6073\n",
            "[0/200][67/391] Loss_D: 1.5097 Loss_G: 0.9669 D(x): 0.6077 D(G(z)): 0.6080 / 0.3948\n",
            "[0/200][68/391] Loss_D: 1.5063 Loss_G: 0.5416 D(x): 0.3944 D(G(z)): 0.3942 / 0.6038\n",
            "[0/200][69/391] Loss_D: 1.5057 Loss_G: 0.9636 D(x): 0.6042 D(G(z)): 0.6045 / 0.3959\n",
            "[0/200][70/391] Loss_D: 1.5046 Loss_G: 0.5385 D(x): 0.3956 D(G(z)): 0.3952 / 0.6055\n",
            "[0/200][71/391] Loss_D: 1.5066 Loss_G: 0.9741 D(x): 0.6058 D(G(z)): 0.6061 / 0.3917\n",
            "[0/200][72/391] Loss_D: 1.5077 Loss_G: 0.5279 D(x): 0.3913 D(G(z)): 0.3910 / 0.6118\n",
            "[0/200][73/391] Loss_D: 1.5117 Loss_G: 0.9926 D(x): 0.6121 D(G(z)): 0.6124 / 0.3844\n",
            "[0/200][74/391] Loss_D: 1.5140 Loss_G: 0.5112 D(x): 0.3840 D(G(z)): 0.3836 / 0.6219\n",
            "[0/200][75/391] Loss_D: 1.5214 Loss_G: 1.0329 D(x): 0.6223 D(G(z)): 0.6226 / 0.3691\n",
            "[0/200][76/391] Loss_D: 1.5296 Loss_G: 0.4838 D(x): 0.3687 D(G(z)): 0.3683 / 0.6391\n",
            "[0/200][77/391] Loss_D: 1.5403 Loss_G: 1.0725 D(x): 0.6395 D(G(z)): 0.6398 / 0.3547\n",
            "[0/200][78/391] Loss_D: 1.5465 Loss_G: 0.4723 D(x): 0.3542 D(G(z)): 0.3538 / 0.6463\n",
            "[0/200][79/391] Loss_D: 1.5489 Loss_G: 1.0673 D(x): 0.6467 D(G(z)): 0.6470 / 0.3565\n",
            "[0/200][80/391] Loss_D: 1.5438 Loss_G: 0.4888 D(x): 0.3560 D(G(z)): 0.3555 / 0.6355\n",
            "[0/200][81/391] Loss_D: 1.5347 Loss_G: 1.0144 D(x): 0.6358 D(G(z)): 0.6361 / 0.3757\n",
            "[0/200][82/391] Loss_D: 1.5209 Loss_G: 0.5258 D(x): 0.3753 D(G(z)): 0.3749 / 0.6123\n",
            "[0/200][83/391] Loss_D: 1.5095 Loss_G: 0.9540 D(x): 0.6126 D(G(z)): 0.6128 / 0.3990\n",
            "[0/200][84/391] Loss_D: 1.4981 Loss_G: 0.5558 D(x): 0.3986 D(G(z)): 0.3983 / 0.5941\n",
            "[0/200][85/391] Loss_D: 1.4930 Loss_G: 0.9267 D(x): 0.5943 D(G(z)): 0.5945 / 0.4099\n",
            "[0/200][86/391] Loss_D: 1.4888 Loss_G: 0.5662 D(x): 0.4096 D(G(z)): 0.4093 / 0.5877\n",
            "[0/200][87/391] Loss_D: 1.4875 Loss_G: 0.9169 D(x): 0.5879 D(G(z)): 0.5882 / 0.4138\n",
            "[0/200][88/391] Loss_D: 1.4852 Loss_G: 0.5693 D(x): 0.4135 D(G(z)): 0.4133 / 0.5857\n",
            "[0/200][89/391] Loss_D: 1.4854 Loss_G: 0.9163 D(x): 0.5859 D(G(z)): 0.5862 / 0.4139\n",
            "[0/200][90/391] Loss_D: 1.4845 Loss_G: 0.5657 D(x): 0.4136 D(G(z)): 0.4134 / 0.5876\n",
            "[0/200][91/391] Loss_D: 1.4861 Loss_G: 0.9257 D(x): 0.5878 D(G(z)): 0.5881 / 0.4099\n",
            "[0/200][92/391] Loss_D: 1.4868 Loss_G: 0.5558 D(x): 0.4096 D(G(z)): 0.4094 / 0.5933\n",
            "[0/200][93/391] Loss_D: 1.4898 Loss_G: 0.9425 D(x): 0.5935 D(G(z)): 0.5938 / 0.4029\n",
            "[0/200][94/391] Loss_D: 1.4915 Loss_G: 0.5416 D(x): 0.4026 D(G(z)): 0.4024 / 0.6015\n",
            "[0/200][95/391] Loss_D: 1.4959 Loss_G: 0.9645 D(x): 0.6018 D(G(z)): 0.6021 / 0.3940\n",
            "[0/200][96/391] Loss_D: 1.4985 Loss_G: 0.5260 D(x): 0.3938 D(G(z)): 0.3935 / 0.6108\n",
            "[0/200][97/391] Loss_D: 1.5037 Loss_G: 0.9895 D(x): 0.6111 D(G(z)): 0.6114 / 0.3842\n",
            "[0/200][98/391] Loss_D: 1.5071 Loss_G: 0.5087 D(x): 0.3839 D(G(z)): 0.3836 / 0.6213\n",
            "[0/200][99/391] Loss_D: 1.5137 Loss_G: 1.0218 D(x): 0.6217 D(G(z)): 0.6220 / 0.3719\n",
            "[0/200][100/391] Loss_D: 1.5194 Loss_G: 0.4889 D(x): 0.3716 D(G(z)): 0.3712 / 0.6336\n",
            "[0/200][101/391] Loss_D: 1.5267 Loss_G: 1.0451 D(x): 0.6340 D(G(z)): 0.6343 / 0.3633\n",
            "[0/200][102/391] Loss_D: 1.5290 Loss_G: 0.4848 D(x): 0.3629 D(G(z)): 0.3625 / 0.6361\n",
            "[0/200][103/391] Loss_D: 1.5293 Loss_G: 1.0377 D(x): 0.6364 D(G(z)): 0.6367 / 0.3660\n",
            "[0/200][104/391] Loss_D: 1.5258 Loss_G: 0.4953 D(x): 0.3656 D(G(z)): 0.3652 / 0.6294\n",
            "[0/200][105/391] Loss_D: 1.5213 Loss_G: 1.0098 D(x): 0.6297 D(G(z)): 0.6300 / 0.3762\n",
            "[0/200][106/391] Loss_D: 1.5139 Loss_G: 0.5154 D(x): 0.3759 D(G(z)): 0.3756 / 0.6167\n",
            "[0/200][107/391] Loss_D: 1.5074 Loss_G: 0.9735 D(x): 0.6170 D(G(z)): 0.6173 / 0.3901\n",
            "[0/200][108/391] Loss_D: 1.4997 Loss_G: 0.5399 D(x): 0.3897 D(G(z)): 0.3894 / 0.6017\n",
            "[0/200][109/391] Loss_D: 1.4929 Loss_G: 0.9362 D(x): 0.6019 D(G(z)): 0.6020 / 0.4048\n",
            "[0/200][110/391] Loss_D: 1.4866 Loss_G: 0.5588 D(x): 0.4044 D(G(z)): 0.4041 / 0.5902\n",
            "[0/200][111/391] Loss_D: 1.4832 Loss_G: 0.9143 D(x): 0.5904 D(G(z)): 0.5906 / 0.4136\n",
            "[0/200][112/391] Loss_D: 1.4794 Loss_G: 0.5690 D(x): 0.4133 D(G(z)): 0.4131 / 0.5841\n",
            "[0/200][113/391] Loss_D: 1.4782 Loss_G: 0.9056 D(x): 0.5843 D(G(z)): 0.5845 / 0.4171\n",
            "[0/200][114/391] Loss_D: 1.4763 Loss_G: 0.5718 D(x): 0.4168 D(G(z)): 0.4166 / 0.5823\n",
            "[0/200][115/391] Loss_D: 1.4762 Loss_G: 0.9036 D(x): 0.5825 D(G(z)): 0.5827 / 0.4178\n",
            "[0/200][116/391] Loss_D: 1.4751 Loss_G: 0.5705 D(x): 0.4176 D(G(z)): 0.4174 / 0.5828\n",
            "[0/200][117/391] Loss_D: 1.4761 Loss_G: 0.9077 D(x): 0.5831 D(G(z)): 0.5833 / 0.4159\n",
            "[0/200][118/391] Loss_D: 1.4758 Loss_G: 0.5651 D(x): 0.4157 D(G(z)): 0.4155 / 0.5858\n",
            "[0/200][119/391] Loss_D: 1.4775 Loss_G: 0.9179 D(x): 0.5861 D(G(z)): 0.5863 / 0.4116\n",
            "[0/200][120/391] Loss_D: 1.4782 Loss_G: 0.5555 D(x): 0.4114 D(G(z)): 0.4112 / 0.5912\n",
            "[0/200][121/391] Loss_D: 1.4807 Loss_G: 0.9393 D(x): 0.5915 D(G(z)): 0.5917 / 0.4027\n",
            "[0/200][122/391] Loss_D: 1.4843 Loss_G: 0.5330 D(x): 0.4024 D(G(z)): 0.4021 / 0.6045\n",
            "[0/200][123/391] Loss_D: 1.4910 Loss_G: 0.9777 D(x): 0.6048 D(G(z)): 0.6050 / 0.3874\n",
            "[0/200][124/391] Loss_D: 1.4972 Loss_G: 0.5080 D(x): 0.3871 D(G(z)): 0.3868 / 0.6196\n",
            "[0/200][125/391] Loss_D: 1.5050 Loss_G: 1.0142 D(x): 0.6199 D(G(z)): 0.6202 / 0.3735\n",
            "[0/200][126/391] Loss_D: 1.5110 Loss_G: 0.4903 D(x): 0.3731 D(G(z)): 0.3727 / 0.6306\n",
            "[0/200][127/391] Loss_D: 1.5163 Loss_G: 1.0295 D(x): 0.6309 D(G(z)): 0.6311 / 0.3677\n",
            "[0/200][128/391] Loss_D: 1.5170 Loss_G: 0.4922 D(x): 0.3674 D(G(z)): 0.3671 / 0.6293\n",
            "[0/200][129/391] Loss_D: 1.5146 Loss_G: 1.0067 D(x): 0.6296 D(G(z)): 0.6299 / 0.3762\n",
            "[0/200][130/391] Loss_D: 1.5074 Loss_G: 0.5132 D(x): 0.3759 D(G(z)): 0.3756 / 0.6161\n",
            "[0/200][131/391] Loss_D: 1.5003 Loss_G: 0.9635 D(x): 0.6163 D(G(z)): 0.6166 / 0.3927\n",
            "[0/200][132/391] Loss_D: 1.4909 Loss_G: 0.5422 D(x): 0.3924 D(G(z)): 0.3922 / 0.5984\n",
            "[0/200][133/391] Loss_D: 1.4839 Loss_G: 0.9206 D(x): 0.5986 D(G(z)): 0.5989 / 0.4098\n",
            "[0/200][134/391] Loss_D: 1.4763 Loss_G: 0.5687 D(x): 0.4096 D(G(z)): 0.4094 / 0.5826\n",
            "[0/200][135/391] Loss_D: 1.4714 Loss_G: 0.8872 D(x): 0.5828 D(G(z)): 0.5830 / 0.4236\n",
            "[0/200][136/391] Loss_D: 1.4664 Loss_G: 0.5881 D(x): 0.4235 D(G(z)): 0.4233 / 0.5712\n",
            "[0/200][137/391] Loss_D: 1.4637 Loss_G: 0.8662 D(x): 0.5715 D(G(z)): 0.5717 / 0.4325\n",
            "[0/200][138/391] Loss_D: 1.4606 Loss_G: 0.5995 D(x): 0.4323 D(G(z)): 0.4322 / 0.5645\n",
            "[0/200][139/391] Loss_D: 1.4592 Loss_G: 0.8554 D(x): 0.5647 D(G(z)): 0.5649 / 0.4370\n",
            "[0/200][140/391] Loss_D: 1.4574 Loss_G: 0.6035 D(x): 0.4369 D(G(z)): 0.4367 / 0.5621\n",
            "[0/200][141/391] Loss_D: 1.4571 Loss_G: 0.8585 D(x): 0.5622 D(G(z)): 0.5624 / 0.4356\n",
            "[0/200][142/391] Loss_D: 1.4576 Loss_G: 0.5907 D(x): 0.4354 D(G(z)): 0.4352 / 0.5692\n",
            "[0/200][143/391] Loss_D: 1.4602 Loss_G: 0.8833 D(x): 0.5693 D(G(z)): 0.5694 / 0.4248\n",
            "[0/200][144/391] Loss_D: 1.4630 Loss_G: 0.5669 D(x): 0.4245 D(G(z)): 0.4243 / 0.5827\n",
            "[0/200][145/391] Loss_D: 1.4681 Loss_G: 0.9198 D(x): 0.5828 D(G(z)): 0.5830 / 0.4094\n",
            "[0/200][146/391] Loss_D: 1.4729 Loss_G: 0.5402 D(x): 0.4091 D(G(z)): 0.4089 / 0.5983\n",
            "[0/200][147/391] Loss_D: 1.4792 Loss_G: 0.9524 D(x): 0.5985 D(G(z)): 0.5986 / 0.3961\n",
            "[0/200][148/391] Loss_D: 1.4829 Loss_G: 0.5252 D(x): 0.3958 D(G(z)): 0.3955 / 0.6071\n",
            "[0/200][149/391] Loss_D: 1.4861 Loss_G: 0.9633 D(x): 0.6073 D(G(z)): 0.6074 / 0.3917\n",
            "[0/200][150/391] Loss_D: 1.4863 Loss_G: 0.5214 D(x): 0.3913 D(G(z)): 0.3910 / 0.6093\n",
            "[0/200][151/391] Loss_D: 1.4877 Loss_G: 0.9656 D(x): 0.6095 D(G(z)): 0.6097 / 0.3907\n",
            "[0/200][152/391] Loss_D: 1.4869 Loss_G: 0.5215 D(x): 0.3905 D(G(z)): 0.3902 / 0.6091\n",
            "[0/200][153/391] Loss_D: 1.4874 Loss_G: 0.9662 D(x): 0.6094 D(G(z)): 0.6096 / 0.3904\n",
            "[0/200][154/391] Loss_D: 1.4869 Loss_G: 0.5208 D(x): 0.3902 D(G(z)): 0.3900 / 0.6094\n",
            "[0/200][155/391] Loss_D: 1.4875 Loss_G: 0.9644 D(x): 0.6097 D(G(z)): 0.6100 / 0.3911\n",
            "[0/200][156/391] Loss_D: 1.4859 Loss_G: 0.5234 D(x): 0.3908 D(G(z)): 0.3907 / 0.6077\n",
            "[0/200][157/391] Loss_D: 1.4855 Loss_G: 0.9596 D(x): 0.6080 D(G(z)): 0.6083 / 0.3929\n",
            "[0/200][158/391] Loss_D: 1.4839 Loss_G: 0.5301 D(x): 0.3927 D(G(z)): 0.3924 / 0.6036\n",
            "[0/200][159/391] Loss_D: 1.4812 Loss_G: 0.9462 D(x): 0.6038 D(G(z)): 0.6040 / 0.3981\n",
            "[0/200][160/391] Loss_D: 1.4788 Loss_G: 0.5349 D(x): 0.3978 D(G(z)): 0.3976 / 0.6005\n",
            "[0/200][161/391] Loss_D: 1.4782 Loss_G: 0.9398 D(x): 0.6008 D(G(z)): 0.6009 / 0.4006\n",
            "[0/200][162/391] Loss_D: 1.4764 Loss_G: 0.5362 D(x): 0.4004 D(G(z)): 0.4002 / 0.5996\n",
            "[0/200][163/391] Loss_D: 1.4772 Loss_G: 0.9422 D(x): 0.5999 D(G(z)): 0.6001 / 0.3995\n",
            "[0/200][164/391] Loss_D: 1.4769 Loss_G: 0.5341 D(x): 0.3993 D(G(z)): 0.3992 / 0.6008\n",
            "[0/200][165/391] Loss_D: 1.4777 Loss_G: 0.9425 D(x): 0.6010 D(G(z)): 0.6012 / 0.3993\n",
            "[0/200][166/391] Loss_D: 1.4766 Loss_G: 0.5353 D(x): 0.3991 D(G(z)): 0.3989 / 0.6000\n",
            "[0/200][167/391] Loss_D: 1.4764 Loss_G: 0.9370 D(x): 0.6002 D(G(z)): 0.6003 / 0.4015\n",
            "[0/200][168/391] Loss_D: 1.4744 Loss_G: 0.5406 D(x): 0.4012 D(G(z)): 0.4010 / 0.5966\n",
            "[0/200][169/391] Loss_D: 1.4732 Loss_G: 0.9256 D(x): 0.5968 D(G(z)): 0.5970 / 0.4060\n",
            "[0/200][170/391] Loss_D: 1.4704 Loss_G: 0.5481 D(x): 0.4057 D(G(z)): 0.4055 / 0.5921\n",
            "[0/200][171/391] Loss_D: 1.4692 Loss_G: 0.9183 D(x): 0.5923 D(G(z)): 0.5924 / 0.4088\n",
            "[0/200][172/391] Loss_D: 1.4676 Loss_G: 0.5529 D(x): 0.4086 D(G(z)): 0.4083 / 0.5891\n",
            "[0/200][173/391] Loss_D: 1.4663 Loss_G: 0.9091 D(x): 0.5892 D(G(z)): 0.5893 / 0.4125\n",
            "[0/200][174/391] Loss_D: 1.4644 Loss_G: 0.5607 D(x): 0.4122 D(G(z)): 0.4120 / 0.5843\n",
            "[0/200][175/391] Loss_D: 1.4624 Loss_G: 0.9028 D(x): 0.5845 D(G(z)): 0.5847 / 0.4150\n",
            "[0/200][176/391] Loss_D: 1.4621 Loss_G: 0.5566 D(x): 0.4148 D(G(z)): 0.4146 / 0.5866\n",
            "[0/200][177/391] Loss_D: 1.4636 Loss_G: 0.9103 D(x): 0.5868 D(G(z)): 0.5869 / 0.4118\n",
            "[0/200][178/391] Loss_D: 1.4640 Loss_G: 0.5519 D(x): 0.4116 D(G(z)): 0.4114 / 0.5892\n",
            "[0/200][179/391] Loss_D: 1.4651 Loss_G: 0.9140 D(x): 0.5894 D(G(z)): 0.5895 / 0.4102\n",
            "[0/200][180/391] Loss_D: 1.4647 Loss_G: 0.5514 D(x): 0.4100 D(G(z)): 0.4098 / 0.5894\n",
            "[0/200][181/391] Loss_D: 1.4646 Loss_G: 0.9090 D(x): 0.5895 D(G(z)): 0.5896 / 0.4122\n",
            "[0/200][182/391] Loss_D: 1.4628 Loss_G: 0.5575 D(x): 0.4119 D(G(z)): 0.4118 / 0.5857\n",
            "[0/200][183/391] Loss_D: 1.4615 Loss_G: 0.9000 D(x): 0.5858 D(G(z)): 0.5860 / 0.4158\n",
            "[0/200][184/391] Loss_D: 1.4598 Loss_G: 0.5623 D(x): 0.4156 D(G(z)): 0.4154 / 0.5827\n",
            "[0/200][185/391] Loss_D: 1.4591 Loss_G: 0.8934 D(x): 0.5829 D(G(z)): 0.5830 / 0.4185\n",
            "[0/200][186/391] Loss_D: 1.4576 Loss_G: 0.5661 D(x): 0.4183 D(G(z)): 0.4181 / 0.5804\n",
            "[0/200][187/391] Loss_D: 1.4570 Loss_G: 0.8884 D(x): 0.5806 D(G(z)): 0.5807 / 0.4205\n",
            "[0/200][188/391] Loss_D: 1.4558 Loss_G: 0.5691 D(x): 0.4203 D(G(z)): 0.4202 / 0.5785\n",
            "[0/200][189/391] Loss_D: 1.4554 Loss_G: 0.8830 D(x): 0.5787 D(G(z)): 0.5788 / 0.4226\n",
            "[0/200][190/391] Loss_D: 1.4539 Loss_G: 0.5736 D(x): 0.4225 D(G(z)): 0.4224 / 0.5758\n",
            "[0/200][191/391] Loss_D: 1.4532 Loss_G: 0.8764 D(x): 0.5760 D(G(z)): 0.5761 / 0.4253\n",
            "[0/200][192/391] Loss_D: 1.4518 Loss_G: 0.5773 D(x): 0.4252 D(G(z)): 0.4251 / 0.5735\n",
            "[0/200][193/391] Loss_D: 1.4513 Loss_G: 0.8718 D(x): 0.5737 D(G(z)): 0.5738 / 0.4272\n",
            "[0/200][194/391] Loss_D: 1.4502 Loss_G: 0.5793 D(x): 0.4270 D(G(z)): 0.4269 / 0.5722\n",
            "[0/200][195/391] Loss_D: 1.4499 Loss_G: 0.8656 D(x): 0.5723 D(G(z)): 0.5725 / 0.4297\n",
            "[0/200][196/391] Loss_D: 1.4481 Loss_G: 0.5847 D(x): 0.4296 D(G(z)): 0.4294 / 0.5690\n",
            "[0/200][197/391] Loss_D: 1.4474 Loss_G: 0.8624 D(x): 0.5691 D(G(z)): 0.5692 / 0.4310\n",
            "[0/200][198/391] Loss_D: 1.4469 Loss_G: 0.5801 D(x): 0.4308 D(G(z)): 0.4306 / 0.5715\n",
            "[0/200][199/391] Loss_D: 1.4484 Loss_G: 0.8768 D(x): 0.5716 D(G(z)): 0.5716 / 0.4247\n",
            "[0/200][200/391] Loss_D: 1.4501 Loss_G: 0.5638 D(x): 0.4245 D(G(z)): 0.4243 / 0.5808\n",
            "[0/200][201/391] Loss_D: 1.4538 Loss_G: 0.9045 D(x): 0.5809 D(G(z)): 0.5810 / 0.4131\n",
            "[0/200][202/391] Loss_D: 1.4575 Loss_G: 0.5420 D(x): 0.4128 D(G(z)): 0.4126 / 0.5934\n",
            "[0/200][203/391] Loss_D: 1.4626 Loss_G: 0.9374 D(x): 0.5936 D(G(z)): 0.5937 / 0.3996\n",
            "[0/200][204/391] Loss_D: 1.4676 Loss_G: 0.5196 D(x): 0.3994 D(G(z)): 0.3991 / 0.6068\n",
            "[0/200][205/391] Loss_D: 1.4734 Loss_G: 0.9742 D(x): 0.6069 D(G(z)): 0.6070 / 0.3851\n",
            "[0/200][206/391] Loss_D: 1.4803 Loss_G: 0.4893 D(x): 0.3848 D(G(z)): 0.3845 / 0.6254\n",
            "[0/200][207/391] Loss_D: 1.4916 Loss_G: 1.0291 D(x): 0.6255 D(G(z)): 0.6257 / 0.3645\n",
            "[0/200][208/391] Loss_D: 1.5022 Loss_G: 0.4628 D(x): 0.3641 D(G(z)): 0.3638 / 0.6421\n",
            "[0/200][209/391] Loss_D: 1.5111 Loss_G: 1.0506 D(x): 0.6423 D(G(z)): 0.6425 / 0.3567\n",
            "[0/200][210/391] Loss_D: 1.5116 Loss_G: 0.4673 D(x): 0.3564 D(G(z)): 0.3561 / 0.6392\n",
            "[0/200][211/391] Loss_D: 1.5075 Loss_G: 1.0166 D(x): 0.6395 D(G(z)): 0.6397 / 0.3691\n",
            "[0/200][212/391] Loss_D: 1.4970 Loss_G: 0.4966 D(x): 0.3688 D(G(z)): 0.3685 / 0.6208\n",
            "[0/200][213/391] Loss_D: 1.4868 Loss_G: 0.9598 D(x): 0.6210 D(G(z)): 0.6212 / 0.3907\n",
            "[0/200][214/391] Loss_D: 1.4750 Loss_G: 0.5349 D(x): 0.3905 D(G(z)): 0.3903 / 0.5974\n",
            "[0/200][215/391] Loss_D: 1.4651 Loss_G: 0.9026 D(x): 0.5976 D(G(z)): 0.5978 / 0.4136\n",
            "[0/200][216/391] Loss_D: 1.4560 Loss_G: 0.5712 D(x): 0.4134 D(G(z)): 0.4132 / 0.5761\n",
            "[0/200][217/391] Loss_D: 1.4493 Loss_G: 0.8551 D(x): 0.5762 D(G(z)): 0.5763 / 0.4336\n",
            "[0/200][218/391] Loss_D: 1.4431 Loss_G: 0.6016 D(x): 0.4335 D(G(z)): 0.4334 / 0.5587\n",
            "[0/200][219/391] Loss_D: 1.4393 Loss_G: 0.8235 D(x): 0.5588 D(G(z)): 0.5589 / 0.4475\n",
            "[0/200][220/391] Loss_D: 1.4360 Loss_G: 0.6210 D(x): 0.4473 D(G(z)): 0.4472 / 0.5478\n",
            "[0/200][221/391] Loss_D: 1.4341 Loss_G: 0.8045 D(x): 0.5479 D(G(z)): 0.5480 / 0.4559\n",
            "[0/200][222/391] Loss_D: 1.4322 Loss_G: 0.6331 D(x): 0.4558 D(G(z)): 0.4558 / 0.5411\n",
            "[0/200][223/391] Loss_D: 1.4312 Loss_G: 0.7928 D(x): 0.5412 D(G(z)): 0.5412 / 0.4612\n",
            "[0/200][224/391] Loss_D: 1.4300 Loss_G: 0.6404 D(x): 0.4611 D(G(z)): 0.4611 / 0.5371\n",
            "[0/200][225/391] Loss_D: 1.4294 Loss_G: 0.7862 D(x): 0.5371 D(G(z)): 0.5372 / 0.4641\n",
            "[0/200][226/391] Loss_D: 1.4286 Loss_G: 0.6437 D(x): 0.4641 D(G(z)): 0.4640 / 0.5352\n",
            "[0/200][227/391] Loss_D: 1.4283 Loss_G: 0.7838 D(x): 0.5352 D(G(z)): 0.5353 / 0.4651\n",
            "[0/200][228/391] Loss_D: 1.4278 Loss_G: 0.6437 D(x): 0.4650 D(G(z)): 0.4650 / 0.5350\n",
            "[0/200][229/391] Loss_D: 1.4278 Loss_G: 0.7850 D(x): 0.5351 D(G(z)): 0.5351 / 0.4644\n",
            "[0/200][230/391] Loss_D: 1.4275 Loss_G: 0.6407 D(x): 0.4644 D(G(z)): 0.4643 / 0.5365\n",
            "[0/200][231/391] Loss_D: 1.4277 Loss_G: 0.7897 D(x): 0.5366 D(G(z)): 0.5366 / 0.4621\n",
            "[0/200][232/391] Loss_D: 1.4276 Loss_G: 0.6345 D(x): 0.4621 D(G(z)): 0.4620 / 0.5397\n",
            "[0/200][233/391] Loss_D: 1.4282 Loss_G: 0.7984 D(x): 0.5397 D(G(z)): 0.5398 / 0.4580\n",
            "[0/200][234/391] Loss_D: 1.4285 Loss_G: 0.6253 D(x): 0.4580 D(G(z)): 0.4579 / 0.5446\n",
            "[0/200][235/391] Loss_D: 1.4295 Loss_G: 0.8113 D(x): 0.5447 D(G(z)): 0.5447 / 0.4521\n",
            "[0/200][236/391] Loss_D: 1.4302 Loss_G: 0.6119 D(x): 0.4520 D(G(z)): 0.4519 / 0.5518\n",
            "[0/200][237/391] Loss_D: 1.4319 Loss_G: 0.8300 D(x): 0.5519 D(G(z)): 0.5520 / 0.4436\n",
            "[0/200][238/391] Loss_D: 1.4334 Loss_G: 0.5942 D(x): 0.4435 D(G(z)): 0.4434 / 0.5615\n",
            "[0/200][239/391] Loss_D: 1.4360 Loss_G: 0.8548 D(x): 0.5616 D(G(z)): 0.5617 / 0.4327\n",
            "[0/200][240/391] Loss_D: 1.4385 Loss_G: 0.5721 D(x): 0.4325 D(G(z)): 0.4324 / 0.5740\n",
            "[0/200][241/391] Loss_D: 1.4425 Loss_G: 0.8870 D(x): 0.5741 D(G(z)): 0.5742 / 0.4189\n",
            "[0/200][242/391] Loss_D: 1.4465 Loss_G: 0.5475 D(x): 0.4187 D(G(z)): 0.4186 / 0.5882\n",
            "[0/200][243/391] Loss_D: 1.4518 Loss_G: 0.9209 D(x): 0.5883 D(G(z)): 0.5884 / 0.4049\n",
            "[0/200][244/391] Loss_D: 1.4565 Loss_G: 0.5251 D(x): 0.4047 D(G(z)): 0.4045 / 0.6014\n",
            "[0/200][245/391] Loss_D: 1.4619 Loss_G: 0.9492 D(x): 0.6015 D(G(z)): 0.6016 / 0.3935\n",
            "[0/200][246/391] Loss_D: 1.4659 Loss_G: 0.5111 D(x): 0.3933 D(G(z)): 0.3931 / 0.6098\n",
            "[0/200][247/391] Loss_D: 1.4692 Loss_G: 0.9645 D(x): 0.6099 D(G(z)): 0.6100 / 0.3876\n",
            "[0/200][248/391] Loss_D: 1.4712 Loss_G: 0.5050 D(x): 0.3873 D(G(z)): 0.3871 / 0.6135\n",
            "[0/200][249/391] Loss_D: 1.4726 Loss_G: 0.9641 D(x): 0.6137 D(G(z)): 0.6138 / 0.3877\n",
            "[0/200][250/391] Loss_D: 1.4711 Loss_G: 0.5059 D(x): 0.3875 D(G(z)): 0.3874 / 0.6130\n",
            "[0/200][251/391] Loss_D: 1.4722 Loss_G: 0.9702 D(x): 0.6132 D(G(z)): 0.6133 / 0.3853\n",
            "[0/200][252/391] Loss_D: 1.4733 Loss_G: 0.5035 D(x): 0.3851 D(G(z)): 0.3849 / 0.6144\n",
            "[0/200][253/391] Loss_D: 1.4734 Loss_G: 0.9653 D(x): 0.6146 D(G(z)): 0.6147 / 0.3872\n",
            "[0/200][254/391] Loss_D: 1.4714 Loss_G: 0.5123 D(x): 0.3870 D(G(z)): 0.3869 / 0.6090\n",
            "[0/200][255/391] Loss_D: 1.4683 Loss_G: 0.9421 D(x): 0.6092 D(G(z)): 0.6094 / 0.3963\n",
            "[0/200][256/391] Loss_D: 1.4630 Loss_G: 0.5328 D(x): 0.3961 D(G(z)): 0.3960 / 0.5966\n",
            "[0/200][257/391] Loss_D: 1.4575 Loss_G: 0.9117 D(x): 0.5968 D(G(z)): 0.5969 / 0.4085\n",
            "[0/200][258/391] Loss_D: 1.4530 Loss_G: 0.5491 D(x): 0.4084 D(G(z)): 0.4082 / 0.5870\n",
            "[0/200][259/391] Loss_D: 1.4500 Loss_G: 0.8906 D(x): 0.5871 D(G(z)): 0.5872 / 0.4172\n",
            "[0/200][260/391] Loss_D: 1.4466 Loss_G: 0.5633 D(x): 0.4170 D(G(z)): 0.4169 / 0.5786\n",
            "[0/200][261/391] Loss_D: 1.4440 Loss_G: 0.8703 D(x): 0.5787 D(G(z)): 0.5788 / 0.4257\n",
            "[0/200][262/391] Loss_D: 1.4409 Loss_G: 0.5786 D(x): 0.4256 D(G(z)): 0.4255 / 0.5698\n",
            "[0/200][263/391] Loss_D: 1.4384 Loss_G: 0.8489 D(x): 0.5699 D(G(z)): 0.5700 / 0.4348\n",
            "[0/200][264/391] Loss_D: 1.4354 Loss_G: 0.5946 D(x): 0.4347 D(G(z)): 0.4346 / 0.5606\n",
            "[0/200][265/391] Loss_D: 1.4332 Loss_G: 0.8290 D(x): 0.5607 D(G(z)): 0.5608 / 0.4435\n",
            "[0/200][266/391] Loss_D: 1.4308 Loss_G: 0.6084 D(x): 0.4434 D(G(z)): 0.4433 / 0.5528\n",
            "[0/200][267/391] Loss_D: 1.4292 Loss_G: 0.8136 D(x): 0.5529 D(G(z)): 0.5530 / 0.4503\n",
            "[0/200][268/391] Loss_D: 1.4275 Loss_G: 0.6188 D(x): 0.4502 D(G(z)): 0.4501 / 0.5470\n",
            "[0/200][269/391] Loss_D: 1.4264 Loss_G: 0.8026 D(x): 0.5471 D(G(z)): 0.5472 / 0.4551\n",
            "[0/200][270/391] Loss_D: 1.4252 Loss_G: 0.6259 D(x): 0.4551 D(G(z)): 0.4550 / 0.5431\n",
            "[0/200][271/391] Loss_D: 1.4246 Loss_G: 0.7957 D(x): 0.5431 D(G(z)): 0.5432 / 0.4582\n",
            "[0/200][272/391] Loss_D: 1.4238 Loss_G: 0.6298 D(x): 0.4582 D(G(z)): 0.4581 / 0.5408\n",
            "[0/200][273/391] Loss_D: 1.4234 Loss_G: 0.7927 D(x): 0.5409 D(G(z)): 0.5410 / 0.4595\n",
            "[0/200][274/391] Loss_D: 1.4229 Loss_G: 0.6305 D(x): 0.4594 D(G(z)): 0.4594 / 0.5404\n",
            "[0/200][275/391] Loss_D: 1.4228 Loss_G: 0.7928 D(x): 0.5404 D(G(z)): 0.5405 / 0.4594\n",
            "[0/200][276/391] Loss_D: 1.4226 Loss_G: 0.6286 D(x): 0.4593 D(G(z)): 0.4592 / 0.5413\n",
            "[0/200][277/391] Loss_D: 1.4228 Loss_G: 0.7961 D(x): 0.5413 D(G(z)): 0.5414 / 0.4578\n",
            "[0/200][278/391] Loss_D: 1.4227 Loss_G: 0.6242 D(x): 0.4577 D(G(z)): 0.4576 / 0.5436\n",
            "[0/200][279/391] Loss_D: 1.4232 Loss_G: 0.8027 D(x): 0.5436 D(G(z)): 0.5437 / 0.4547\n",
            "[0/200][280/391] Loss_D: 1.4234 Loss_G: 0.6169 D(x): 0.4546 D(G(z)): 0.4545 / 0.5474\n",
            "[0/200][281/391] Loss_D: 1.4242 Loss_G: 0.8125 D(x): 0.5475 D(G(z)): 0.5475 / 0.4501\n",
            "[0/200][282/391] Loss_D: 1.4248 Loss_G: 0.6068 D(x): 0.4500 D(G(z)): 0.4499 / 0.5529\n",
            "[0/200][283/391] Loss_D: 1.4261 Loss_G: 0.8265 D(x): 0.5530 D(G(z)): 0.5530 / 0.4438\n",
            "[0/200][284/391] Loss_D: 1.4272 Loss_G: 0.5940 D(x): 0.4437 D(G(z)): 0.4436 / 0.5599\n",
            "[0/200][285/391] Loss_D: 1.4290 Loss_G: 0.8441 D(x): 0.5600 D(G(z)): 0.5600 / 0.4360\n",
            "[0/200][286/391] Loss_D: 1.4307 Loss_G: 0.5777 D(x): 0.4359 D(G(z)): 0.4358 / 0.5691\n",
            "[0/200][287/391] Loss_D: 1.4336 Loss_G: 0.8681 D(x): 0.5691 D(G(z)): 0.5692 / 0.4257\n",
            "[0/200][288/391] Loss_D: 1.4364 Loss_G: 0.5585 D(x): 0.4255 D(G(z)): 0.4254 / 0.5800\n",
            "[0/200][289/391] Loss_D: 1.4402 Loss_G: 0.8985 D(x): 0.5801 D(G(z)): 0.5802 / 0.4128\n",
            "[0/200][290/391] Loss_D: 1.4447 Loss_G: 0.5349 D(x): 0.4127 D(G(z)): 0.4125 / 0.5938\n",
            "[0/200][291/391] Loss_D: 1.4499 Loss_G: 0.9303 D(x): 0.5939 D(G(z)): 0.5940 / 0.3999\n",
            "[0/200][292/391] Loss_D: 1.4546 Loss_G: 0.5150 D(x): 0.3997 D(G(z)): 0.3995 / 0.6057\n",
            "[0/200][293/391] Loss_D: 1.4598 Loss_G: 0.9563 D(x): 0.6059 D(G(z)): 0.6060 / 0.3896\n",
            "[0/200][294/391] Loss_D: 1.4636 Loss_G: 0.5031 D(x): 0.3894 D(G(z)): 0.3892 / 0.6129\n",
            "[0/200][295/391] Loss_D: 1.4664 Loss_G: 0.9667 D(x): 0.6131 D(G(z)): 0.6132 / 0.3856\n",
            "[0/200][296/391] Loss_D: 1.4673 Loss_G: 0.5018 D(x): 0.3854 D(G(z)): 0.3852 / 0.6137\n",
            "[0/200][297/391] Loss_D: 1.4673 Loss_G: 0.9591 D(x): 0.6139 D(G(z)): 0.6141 / 0.3885\n",
            "[0/200][298/391] Loss_D: 1.4645 Loss_G: 0.5103 D(x): 0.3883 D(G(z)): 0.3882 / 0.6085\n",
            "[0/200][299/391] Loss_D: 1.4623 Loss_G: 0.9435 D(x): 0.6087 D(G(z)): 0.6089 / 0.3946\n",
            "[0/200][300/391] Loss_D: 1.4589 Loss_G: 0.5237 D(x): 0.3945 D(G(z)): 0.3943 / 0.6004\n",
            "[0/200][301/391] Loss_D: 1.4549 Loss_G: 0.9169 D(x): 0.6005 D(G(z)): 0.6007 / 0.4052\n",
            "[0/200][302/391] Loss_D: 1.4499 Loss_G: 0.5430 D(x): 0.4051 D(G(z)): 0.4049 / 0.5888\n",
            "[0/200][303/391] Loss_D: 1.4457 Loss_G: 0.8897 D(x): 0.5890 D(G(z)): 0.5891 / 0.4163\n",
            "[0/200][304/391] Loss_D: 1.4415 Loss_G: 0.5612 D(x): 0.4162 D(G(z)): 0.4161 / 0.5782\n",
            "[0/200][305/391] Loss_D: 1.4381 Loss_G: 0.8681 D(x): 0.5783 D(G(z)): 0.5784 / 0.4254\n",
            "[0/200][306/391] Loss_D: 1.4354 Loss_G: 0.5728 D(x): 0.4253 D(G(z)): 0.4252 / 0.5714\n",
            "[0/200][307/391] Loss_D: 1.4337 Loss_G: 0.8538 D(x): 0.5716 D(G(z)): 0.5717 / 0.4315\n",
            "[0/200][308/391] Loss_D: 1.4317 Loss_G: 0.5834 D(x): 0.4314 D(G(z)): 0.4313 / 0.5654\n",
            "[0/200][309/391] Loss_D: 1.4301 Loss_G: 0.8403 D(x): 0.5655 D(G(z)): 0.5656 / 0.4373\n",
            "[0/200][310/391] Loss_D: 1.4283 Loss_G: 0.5930 D(x): 0.4372 D(G(z)): 0.4372 / 0.5599\n",
            "[0/200][311/391] Loss_D: 1.4270 Loss_G: 0.8281 D(x): 0.5600 D(G(z)): 0.5601 / 0.4426\n",
            "[0/200][312/391] Loss_D: 1.4254 Loss_G: 0.6015 D(x): 0.4425 D(G(z)): 0.4425 / 0.5551\n",
            "[0/200][313/391] Loss_D: 1.4244 Loss_G: 0.8195 D(x): 0.5551 D(G(z)): 0.5552 / 0.4464\n",
            "[0/200][314/391] Loss_D: 1.4235 Loss_G: 0.6071 D(x): 0.4463 D(G(z)): 0.4463 / 0.5519\n",
            "[0/200][315/391] Loss_D: 1.4228 Loss_G: 0.8125 D(x): 0.5520 D(G(z)): 0.5521 / 0.4494\n",
            "[0/200][316/391] Loss_D: 1.4219 Loss_G: 0.6117 D(x): 0.4494 D(G(z)): 0.4493 / 0.5493\n",
            "[0/200][317/391] Loss_D: 1.4214 Loss_G: 0.8076 D(x): 0.5494 D(G(z)): 0.5494 / 0.4515\n",
            "[0/200][318/391] Loss_D: 1.4207 Loss_G: 0.6144 D(x): 0.4515 D(G(z)): 0.4514 / 0.5477\n",
            "[0/200][319/391] Loss_D: 1.4205 Loss_G: 0.8050 D(x): 0.5478 D(G(z)): 0.5479 / 0.4527\n",
            "[0/200][320/391] Loss_D: 1.4200 Loss_G: 0.6154 D(x): 0.4526 D(G(z)): 0.4526 / 0.5471\n",
            "[0/200][321/391] Loss_D: 1.4199 Loss_G: 0.8043 D(x): 0.5471 D(G(z)): 0.5472 / 0.4529\n",
            "[0/200][322/391] Loss_D: 1.4196 Loss_G: 0.6150 D(x): 0.4528 D(G(z)): 0.4528 / 0.5472\n",
            "[0/200][323/391] Loss_D: 1.4196 Loss_G: 0.8056 D(x): 0.5473 D(G(z)): 0.5473 / 0.4522\n",
            "[0/200][324/391] Loss_D: 1.4196 Loss_G: 0.6128 D(x): 0.4522 D(G(z)): 0.4521 / 0.5484\n",
            "[0/200][325/391] Loss_D: 1.4198 Loss_G: 0.8087 D(x): 0.5484 D(G(z)): 0.5485 / 0.4508\n",
            "[0/200][326/391] Loss_D: 1.4199 Loss_G: 0.6095 D(x): 0.4507 D(G(z)): 0.4507 / 0.5501\n",
            "[0/200][327/391] Loss_D: 1.4203 Loss_G: 0.8126 D(x): 0.5502 D(G(z)): 0.5502 / 0.4490\n",
            "[0/200][328/391] Loss_D: 1.4203 Loss_G: 0.6059 D(x): 0.4489 D(G(z)): 0.4488 / 0.5520\n",
            "[0/200][329/391] Loss_D: 1.4208 Loss_G: 0.8172 D(x): 0.5521 D(G(z)): 0.5521 / 0.4469\n",
            "[0/200][330/391] Loss_D: 1.4210 Loss_G: 0.6014 D(x): 0.4468 D(G(z)): 0.4467 / 0.5545\n",
            "[0/200][331/391] Loss_D: 1.4216 Loss_G: 0.8234 D(x): 0.5545 D(G(z)): 0.5546 / 0.4441\n",
            "[0/200][332/391] Loss_D: 1.4220 Loss_G: 0.5955 D(x): 0.4440 D(G(z)): 0.4439 / 0.5576\n",
            "[0/200][333/391] Loss_D: 1.4228 Loss_G: 0.8314 D(x): 0.5577 D(G(z)): 0.5578 / 0.4405\n",
            "[0/200][334/391] Loss_D: 1.4235 Loss_G: 0.5884 D(x): 0.4404 D(G(z)): 0.4403 / 0.5615\n",
            "[0/200][335/391] Loss_D: 1.4245 Loss_G: 0.8406 D(x): 0.5616 D(G(z)): 0.5617 / 0.4364\n",
            "[0/200][336/391] Loss_D: 1.4253 Loss_G: 0.5809 D(x): 0.4363 D(G(z)): 0.4362 / 0.5657\n",
            "[0/200][337/391] Loss_D: 1.4265 Loss_G: 0.8508 D(x): 0.5658 D(G(z)): 0.5659 / 0.4319\n",
            "[0/200][338/391] Loss_D: 1.4275 Loss_G: 0.5726 D(x): 0.4318 D(G(z)): 0.4317 / 0.5704\n",
            "[0/200][339/391] Loss_D: 1.4289 Loss_G: 0.8610 D(x): 0.5705 D(G(z)): 0.5705 / 0.4275\n",
            "[0/200][340/391] Loss_D: 1.4299 Loss_G: 0.5656 D(x): 0.4274 D(G(z)): 0.4273 / 0.5744\n",
            "[0/200][341/391] Loss_D: 1.4312 Loss_G: 0.8696 D(x): 0.5745 D(G(z)): 0.5746 / 0.4238\n",
            "[0/200][342/391] Loss_D: 1.4320 Loss_G: 0.5608 D(x): 0.4237 D(G(z)): 0.4237 / 0.5771\n",
            "[0/200][343/391] Loss_D: 1.4328 Loss_G: 0.8752 D(x): 0.5772 D(G(z)): 0.5773 / 0.4214\n",
            "[0/200][344/391] Loss_D: 1.4333 Loss_G: 0.5562 D(x): 0.4213 D(G(z)): 0.4212 / 0.5797\n",
            "[0/200][345/391] Loss_D: 1.4342 Loss_G: 0.8835 D(x): 0.5798 D(G(z)): 0.5799 / 0.4179\n",
            "[0/200][346/391] Loss_D: 1.4355 Loss_G: 0.5469 D(x): 0.4178 D(G(z)): 0.4177 / 0.5851\n",
            "[0/200][347/391] Loss_D: 1.4379 Loss_G: 0.8968 D(x): 0.5852 D(G(z)): 0.5853 / 0.4124\n",
            "[0/200][348/391] Loss_D: 1.4393 Loss_G: 0.5381 D(x): 0.4122 D(G(z)): 0.4121 / 0.5903\n",
            "[0/200][349/391] Loss_D: 1.4416 Loss_G: 0.9112 D(x): 0.5904 D(G(z)): 0.5905 / 0.4064\n",
            "[0/200][350/391] Loss_D: 1.4436 Loss_G: 0.5280 D(x): 0.4063 D(G(z)): 0.4062 / 0.5962\n",
            "[0/200][351/391] Loss_D: 1.4460 Loss_G: 0.9226 D(x): 0.5963 D(G(z)): 0.5964 / 0.4018\n",
            "[0/200][352/391] Loss_D: 1.4472 Loss_G: 0.5241 D(x): 0.4017 D(G(z)): 0.4016 / 0.5985\n",
            "[0/200][353/391] Loss_D: 1.4478 Loss_G: 0.9224 D(x): 0.5986 D(G(z)): 0.5988 / 0.4019\n",
            "[0/200][354/391] Loss_D: 1.4471 Loss_G: 0.5286 D(x): 0.4018 D(G(z)): 0.4017 / 0.5958\n",
            "[0/200][355/391] Loss_D: 1.4456 Loss_G: 0.9096 D(x): 0.5959 D(G(z)): 0.5960 / 0.4071\n",
            "[0/200][356/391] Loss_D: 1.4430 Loss_G: 0.5372 D(x): 0.4069 D(G(z)): 0.4068 / 0.5907\n",
            "[0/200][357/391] Loss_D: 1.4415 Loss_G: 0.8988 D(x): 0.5908 D(G(z)): 0.5909 / 0.4115\n",
            "[0/200][358/391] Loss_D: 1.4396 Loss_G: 0.5451 D(x): 0.4113 D(G(z)): 0.4112 / 0.5860\n",
            "[0/200][359/391] Loss_D: 1.4379 Loss_G: 0.8853 D(x): 0.5861 D(G(z)): 0.5862 / 0.4170\n",
            "[0/200][360/391] Loss_D: 1.4355 Loss_G: 0.5561 D(x): 0.4169 D(G(z)): 0.4168 / 0.5796\n",
            "[0/200][361/391] Loss_D: 1.4334 Loss_G: 0.8692 D(x): 0.5797 D(G(z)): 0.5797 / 0.4237\n",
            "[0/200][362/391] Loss_D: 1.4309 Loss_G: 0.5686 D(x): 0.4236 D(G(z)): 0.4235 / 0.5723\n",
            "[0/200][363/391] Loss_D: 1.4286 Loss_G: 0.8501 D(x): 0.5724 D(G(z)): 0.5724 / 0.4319\n",
            "[0/200][364/391] Loss_D: 1.4260 Loss_G: 0.5832 D(x): 0.4318 D(G(z)): 0.4317 / 0.5640\n",
            "[0/200][365/391] Loss_D: 1.4238 Loss_G: 0.8358 D(x): 0.5640 D(G(z)): 0.5641 / 0.4381\n",
            "[0/200][366/391] Loss_D: 1.4225 Loss_G: 0.5902 D(x): 0.4380 D(G(z)): 0.4379 / 0.5600\n",
            "[0/200][367/391] Loss_D: 1.4216 Loss_G: 0.8285 D(x): 0.5600 D(G(z)): 0.5600 / 0.4412\n",
            "[0/200][368/391] Loss_D: 1.4208 Loss_G: 0.5917 D(x): 0.4411 D(G(z)): 0.4410 / 0.5591\n",
            "[0/200][369/391] Loss_D: 1.4211 Loss_G: 0.8314 D(x): 0.5592 D(G(z)): 0.5592 / 0.4399\n",
            "[0/200][370/391] Loss_D: 1.4213 Loss_G: 0.5876 D(x): 0.4398 D(G(z)): 0.4398 / 0.5614\n",
            "[0/200][371/391] Loss_D: 1.4220 Loss_G: 0.8370 D(x): 0.5614 D(G(z)): 0.5615 / 0.4374\n",
            "[0/200][372/391] Loss_D: 1.4223 Loss_G: 0.5835 D(x): 0.4373 D(G(z)): 0.4373 / 0.5636\n",
            "[0/200][373/391] Loss_D: 1.4229 Loss_G: 0.8415 D(x): 0.5637 D(G(z)): 0.5637 / 0.4354\n",
            "[0/200][374/391] Loss_D: 1.4232 Loss_G: 0.5803 D(x): 0.4353 D(G(z)): 0.4353 / 0.5653\n",
            "[0/200][375/391] Loss_D: 1.4236 Loss_G: 0.8445 D(x): 0.5654 D(G(z)): 0.5655 / 0.4341\n",
            "[0/200][376/391] Loss_D: 1.4237 Loss_G: 0.5785 D(x): 0.4340 D(G(z)): 0.4339 / 0.5663\n",
            "[0/200][377/391] Loss_D: 1.4240 Loss_G: 0.8454 D(x): 0.5663 D(G(z)): 0.5664 / 0.4337\n",
            "[0/200][378/391] Loss_D: 1.4237 Loss_G: 0.5786 D(x): 0.4336 D(G(z)): 0.4335 / 0.5662\n",
            "[0/200][379/391] Loss_D: 1.4237 Loss_G: 0.8442 D(x): 0.5663 D(G(z)): 0.5663 / 0.4341\n",
            "[0/200][380/391] Loss_D: 1.4233 Loss_G: 0.5801 D(x): 0.4340 D(G(z)): 0.4340 / 0.5653\n",
            "[0/200][381/391] Loss_D: 1.4231 Loss_G: 0.8411 D(x): 0.5654 D(G(z)): 0.5654 / 0.4355\n",
            "[0/200][382/391] Loss_D: 1.4224 Loss_G: 0.5829 D(x): 0.4354 D(G(z)): 0.4353 / 0.5637\n",
            "[0/200][383/391] Loss_D: 1.4221 Loss_G: 0.8365 D(x): 0.5637 D(G(z)): 0.5638 / 0.4374\n",
            "[0/200][384/391] Loss_D: 1.4213 Loss_G: 0.5869 D(x): 0.4373 D(G(z)): 0.4372 / 0.5614\n",
            "[0/200][385/391] Loss_D: 1.4207 Loss_G: 0.8299 D(x): 0.5615 D(G(z)): 0.5615 / 0.4403\n",
            "[0/200][386/391] Loss_D: 1.4197 Loss_G: 0.5929 D(x): 0.4402 D(G(z)): 0.4402 / 0.5580\n",
            "[0/200][387/391] Loss_D: 1.4189 Loss_G: 0.8221 D(x): 0.5580 D(G(z)): 0.5581 / 0.4437\n",
            "[0/200][388/391] Loss_D: 1.4179 Loss_G: 0.5984 D(x): 0.4436 D(G(z)): 0.4436 / 0.5548\n",
            "[0/200][389/391] Loss_D: 1.4173 Loss_G: 0.8162 D(x): 0.5549 D(G(z)): 0.5550 / 0.4463\n",
            "[0/200][390/391] Loss_D: 1.4166 Loss_G: 0.6022 D(x): 0.4462 D(G(z)): 0.4462 / 0.5527\n",
            "[1/200][0/391] Loss_D: 1.4161 Loss_G: 0.8121 D(x): 0.5527 D(G(z)): 0.5528 / 0.4481\n",
            "[1/200][1/391] Loss_D: 1.4156 Loss_G: 0.6046 D(x): 0.4480 D(G(z)): 0.4479 / 0.5513\n",
            "[1/200][2/391] Loss_D: 1.4154 Loss_G: 0.8094 D(x): 0.5514 D(G(z)): 0.5514 / 0.4492\n",
            "[1/200][3/391] Loss_D: 1.4149 Loss_G: 0.6065 D(x): 0.4492 D(G(z)): 0.4491 / 0.5502\n",
            "[1/200][4/391] Loss_D: 1.4148 Loss_G: 0.8100 D(x): 0.5503 D(G(z)): 0.5503 / 0.4489\n",
            "[1/200][5/391] Loss_D: 1.4149 Loss_G: 0.6037 D(x): 0.4489 D(G(z)): 0.4489 / 0.5517\n",
            "[1/200][6/391] Loss_D: 1.4153 Loss_G: 0.8133 D(x): 0.5518 D(G(z)): 0.5519 / 0.4474\n",
            "[1/200][7/391] Loss_D: 1.4154 Loss_G: 0.6004 D(x): 0.4473 D(G(z)): 0.4473 / 0.5535\n",
            "[1/200][8/391] Loss_D: 1.4159 Loss_G: 0.8180 D(x): 0.5536 D(G(z)): 0.5537 / 0.4453\n",
            "[1/200][9/391] Loss_D: 1.4162 Loss_G: 0.5961 D(x): 0.4452 D(G(z)): 0.4452 / 0.5559\n",
            "[1/200][10/391] Loss_D: 1.4168 Loss_G: 0.8234 D(x): 0.5559 D(G(z)): 0.5560 / 0.4428\n",
            "[1/200][11/391] Loss_D: 1.4171 Loss_G: 0.5904 D(x): 0.4428 D(G(z)): 0.4427 / 0.5590\n",
            "[1/200][12/391] Loss_D: 1.4181 Loss_G: 0.8323 D(x): 0.5591 D(G(z)): 0.5591 / 0.4389\n",
            "[1/200][13/391] Loss_D: 1.4189 Loss_G: 0.5827 D(x): 0.4388 D(G(z)): 0.4388 / 0.5633\n",
            "[1/200][14/391] Loss_D: 1.4200 Loss_G: 0.8422 D(x): 0.5633 D(G(z)): 0.5634 / 0.4345\n",
            "[1/200][15/391] Loss_D: 1.4209 Loss_G: 0.5749 D(x): 0.4345 D(G(z)): 0.4344 / 0.5676\n",
            "[1/200][16/391] Loss_D: 1.4222 Loss_G: 0.8523 D(x): 0.5677 D(G(z)): 0.5677 / 0.4302\n",
            "[1/200][17/391] Loss_D: 1.4232 Loss_G: 0.5672 D(x): 0.4301 D(G(z)): 0.4300 / 0.5720\n",
            "[1/200][18/391] Loss_D: 1.4246 Loss_G: 0.8619 D(x): 0.5721 D(G(z)): 0.5721 / 0.4260\n",
            "[1/200][19/391] Loss_D: 1.4255 Loss_G: 0.5604 D(x): 0.4259 D(G(z)): 0.4259 / 0.5759\n",
            "[1/200][20/391] Loss_D: 1.4268 Loss_G: 0.8725 D(x): 0.5759 D(G(z)): 0.5760 / 0.4215\n",
            "[1/200][21/391] Loss_D: 1.4283 Loss_G: 0.5519 D(x): 0.4214 D(G(z)): 0.4213 / 0.5807\n",
            "[1/200][22/391] Loss_D: 1.4299 Loss_G: 0.8828 D(x): 0.5808 D(G(z)): 0.5809 / 0.4171\n",
            "[1/200][23/391] Loss_D: 1.4310 Loss_G: 0.5456 D(x): 0.4171 D(G(z)): 0.4170 / 0.5844\n",
            "[1/200][24/391] Loss_D: 1.4323 Loss_G: 0.8881 D(x): 0.5845 D(G(z)): 0.5846 / 0.4149\n",
            "[1/200][25/391] Loss_D: 1.4325 Loss_G: 0.5437 D(x): 0.4148 D(G(z)): 0.4148 / 0.5855\n",
            "[1/200][26/391] Loss_D: 1.4330 Loss_G: 0.8909 D(x): 0.5856 D(G(z)): 0.5857 / 0.4138\n",
            "[1/200][27/391] Loss_D: 1.4332 Loss_G: 0.5420 D(x): 0.4137 D(G(z)): 0.4136 / 0.5865\n",
            "[1/200][28/391] Loss_D: 1.4337 Loss_G: 0.8909 D(x): 0.5866 D(G(z)): 0.5867 / 0.4137\n",
            "[1/200][29/391] Loss_D: 1.4332 Loss_G: 0.5437 D(x): 0.4136 D(G(z)): 0.4135 / 0.5854\n",
            "[1/200][30/391] Loss_D: 1.4328 Loss_G: 0.8865 D(x): 0.5855 D(G(z)): 0.5856 / 0.4156\n",
            "[1/200][31/391] Loss_D: 1.4318 Loss_G: 0.5472 D(x): 0.4155 D(G(z)): 0.4154 / 0.5834\n",
            "[1/200][32/391] Loss_D: 1.4313 Loss_G: 0.8803 D(x): 0.5835 D(G(z)): 0.5836 / 0.4181\n",
            "[1/200][33/391] Loss_D: 1.4300 Loss_G: 0.5530 D(x): 0.4180 D(G(z)): 0.4179 / 0.5800\n",
            "[1/200][34/391] Loss_D: 1.4290 Loss_G: 0.8718 D(x): 0.5801 D(G(z)): 0.5801 / 0.4217\n",
            "[1/200][35/391] Loss_D: 1.4277 Loss_G: 0.5593 D(x): 0.4216 D(G(z)): 0.4215 / 0.5763\n",
            "[1/200][36/391] Loss_D: 1.4266 Loss_G: 0.8610 D(x): 0.5764 D(G(z)): 0.5765 / 0.4263\n",
            "[1/200][37/391] Loss_D: 1.4248 Loss_G: 0.5684 D(x): 0.4262 D(G(z)): 0.4261 / 0.5711\n",
            "[1/200][38/391] Loss_D: 1.4233 Loss_G: 0.8481 D(x): 0.5711 D(G(z)): 0.5712 / 0.4317\n",
            "[1/200][39/391] Loss_D: 1.4215 Loss_G: 0.5786 D(x): 0.4317 D(G(z)): 0.4316 / 0.5653\n",
            "[1/200][40/391] Loss_D: 1.4199 Loss_G: 0.8343 D(x): 0.5653 D(G(z)): 0.5654 / 0.4377\n",
            "[1/200][41/391] Loss_D: 1.4182 Loss_G: 0.5888 D(x): 0.4376 D(G(z)): 0.4376 / 0.5595\n",
            "[1/200][42/391] Loss_D: 1.4168 Loss_G: 0.8217 D(x): 0.5595 D(G(z)): 0.5596 / 0.4433\n",
            "[1/200][43/391] Loss_D: 1.4153 Loss_G: 0.5982 D(x): 0.4432 D(G(z)): 0.4431 / 0.5542\n",
            "[1/200][44/391] Loss_D: 1.4142 Loss_G: 0.8113 D(x): 0.5543 D(G(z)): 0.5543 / 0.4479\n",
            "[1/200][45/391] Loss_D: 1.4132 Loss_G: 0.6054 D(x): 0.4478 D(G(z)): 0.4478 / 0.5502\n",
            "[1/200][46/391] Loss_D: 1.4124 Loss_G: 0.8028 D(x): 0.5502 D(G(z)): 0.5503 / 0.4516\n",
            "[1/200][47/391] Loss_D: 1.4115 Loss_G: 0.6116 D(x): 0.4516 D(G(z)): 0.4515 / 0.5468\n",
            "[1/200][48/391] Loss_D: 1.4109 Loss_G: 0.7961 D(x): 0.5468 D(G(z)): 0.5468 / 0.4546\n",
            "[1/200][49/391] Loss_D: 1.4102 Loss_G: 0.6163 D(x): 0.4546 D(G(z)): 0.4546 / 0.5442\n",
            "[1/200][50/391] Loss_D: 1.4098 Loss_G: 0.7912 D(x): 0.5442 D(G(z)): 0.5442 / 0.4568\n",
            "[1/200][51/391] Loss_D: 1.4093 Loss_G: 0.6196 D(x): 0.4568 D(G(z)): 0.4568 / 0.5423\n",
            "[1/200][52/391] Loss_D: 1.4090 Loss_G: 0.7880 D(x): 0.5424 D(G(z)): 0.5424 / 0.4583\n",
            "[1/200][53/391] Loss_D: 1.4086 Loss_G: 0.6215 D(x): 0.4582 D(G(z)): 0.4582 / 0.5413\n",
            "[1/200][54/391] Loss_D: 1.4085 Loss_G: 0.7867 D(x): 0.5413 D(G(z)): 0.5414 / 0.4589\n",
            "[1/200][55/391] Loss_D: 1.4083 Loss_G: 0.6186 D(x): 0.4588 D(G(z)): 0.4588 / 0.5428\n",
            "[1/200][56/391] Loss_D: 1.4090 Loss_G: 0.7930 D(x): 0.5429 D(G(z)): 0.5429 / 0.4560\n",
            "[1/200][57/391] Loss_D: 1.4093 Loss_G: 0.6112 D(x): 0.4559 D(G(z)): 0.4559 / 0.5468\n",
            "[1/200][58/391] Loss_D: 1.4104 Loss_G: 0.8102 D(x): 0.5469 D(G(z)): 0.5470 / 0.4481\n",
            "[1/200][59/391] Loss_D: 1.4122 Loss_G: 0.5919 D(x): 0.4481 D(G(z)): 0.4481 / 0.5575\n",
            "[1/200][60/391] Loss_D: 1.4148 Loss_G: 0.8369 D(x): 0.5575 D(G(z)): 0.5576 / 0.4363\n",
            "[1/200][61/391] Loss_D: 1.4177 Loss_G: 0.5694 D(x): 0.4363 D(G(z)): 0.4362 / 0.5701\n",
            "[1/200][62/391] Loss_D: 1.4213 Loss_G: 0.8676 D(x): 0.5702 D(G(z)): 0.5702 / 0.4231\n",
            "[1/200][63/391] Loss_D: 1.4252 Loss_G: 0.5453 D(x): 0.4230 D(G(z)): 0.4229 / 0.5840\n",
            "[1/200][64/391] Loss_D: 1.4301 Loss_G: 0.9010 D(x): 0.5841 D(G(z)): 0.5842 / 0.4092\n",
            "[1/200][65/391] Loss_D: 1.4347 Loss_G: 0.5236 D(x): 0.4091 D(G(z)): 0.4090 / 0.5968\n",
            "[1/200][66/391] Loss_D: 1.4396 Loss_G: 0.9264 D(x): 0.5969 D(G(z)): 0.5970 / 0.3990\n",
            "[1/200][67/391] Loss_D: 1.4428 Loss_G: 0.5121 D(x): 0.3988 D(G(z)): 0.3987 / 0.6037\n",
            "[1/200][68/391] Loss_D: 1.4453 Loss_G: 0.9342 D(x): 0.6038 D(G(z)): 0.6038 / 0.3959\n",
            "[1/200][69/391] Loss_D: 1.4455 Loss_G: 0.5139 D(x): 0.3957 D(G(z)): 0.3956 / 0.6026\n",
            "[1/200][70/391] Loss_D: 1.4443 Loss_G: 0.9219 D(x): 0.6026 D(G(z)): 0.6027 / 0.4008\n",
            "[1/200][71/391] Loss_D: 1.4414 Loss_G: 0.5268 D(x): 0.4006 D(G(z)): 0.4005 / 0.5949\n",
            "[1/200][72/391] Loss_D: 1.4380 Loss_G: 0.8996 D(x): 0.5949 D(G(z)): 0.5950 / 0.4098\n",
            "[1/200][73/391] Loss_D: 1.4343 Loss_G: 0.5431 D(x): 0.4097 D(G(z)): 0.4096 / 0.5853\n",
            "[1/200][74/391] Loss_D: 1.4309 Loss_G: 0.8758 D(x): 0.5854 D(G(z)): 0.5854 / 0.4197\n",
            "[1/200][75/391] Loss_D: 1.4273 Loss_G: 0.5601 D(x): 0.4195 D(G(z)): 0.4194 / 0.5754\n",
            "[1/200][76/391] Loss_D: 1.4243 Loss_G: 0.8522 D(x): 0.5755 D(G(z)): 0.5755 / 0.4296\n",
            "[1/200][77/391] Loss_D: 1.4211 Loss_G: 0.5775 D(x): 0.4295 D(G(z)): 0.4295 / 0.5654\n",
            "[1/200][78/391] Loss_D: 1.4185 Loss_G: 0.8300 D(x): 0.5655 D(G(z)): 0.5655 / 0.4393\n",
            "[1/200][79/391] Loss_D: 1.4158 Loss_G: 0.5936 D(x): 0.4392 D(G(z)): 0.4391 / 0.5564\n",
            "[1/200][80/391] Loss_D: 1.4138 Loss_G: 0.8111 D(x): 0.5564 D(G(z)): 0.5565 / 0.4476\n",
            "[1/200][81/391] Loss_D: 1.4119 Loss_G: 0.6073 D(x): 0.4476 D(G(z)): 0.4475 / 0.5488\n",
            "[1/200][82/391] Loss_D: 1.4104 Loss_G: 0.7959 D(x): 0.5488 D(G(z)): 0.5489 / 0.4545\n",
            "[1/200][83/391] Loss_D: 1.4090 Loss_G: 0.6184 D(x): 0.4544 D(G(z)): 0.4544 / 0.5427\n",
            "[1/200][84/391] Loss_D: 1.4080 Loss_G: 0.7841 D(x): 0.5427 D(G(z)): 0.5428 / 0.4598\n",
            "[1/200][85/391] Loss_D: 1.4070 Loss_G: 0.6269 D(x): 0.4598 D(G(z)): 0.4597 / 0.5380\n",
            "[1/200][86/391] Loss_D: 1.4064 Loss_G: 0.7754 D(x): 0.5381 D(G(z)): 0.5381 / 0.4638\n",
            "[1/200][87/391] Loss_D: 1.4056 Loss_G: 0.6332 D(x): 0.4638 D(G(z)): 0.4637 / 0.5346\n",
            "[1/200][88/391] Loss_D: 1.4052 Loss_G: 0.7692 D(x): 0.5347 D(G(z)): 0.5347 / 0.4666\n",
            "[1/200][89/391] Loss_D: 1.4047 Loss_G: 0.6375 D(x): 0.4666 D(G(z)): 0.4666 / 0.5323\n",
            "[1/200][90/391] Loss_D: 1.4044 Loss_G: 0.7651 D(x): 0.5323 D(G(z)): 0.5324 / 0.4685\n",
            "[1/200][91/391] Loss_D: 1.4040 Loss_G: 0.6400 D(x): 0.4685 D(G(z)): 0.4684 / 0.5309\n",
            "[1/200][92/391] Loss_D: 1.4039 Loss_G: 0.7631 D(x): 0.5310 D(G(z)): 0.5310 / 0.4694\n",
            "[1/200][93/391] Loss_D: 1.4036 Loss_G: 0.6409 D(x): 0.4694 D(G(z)): 0.4694 / 0.5304\n",
            "[1/200][94/391] Loss_D: 1.4036 Loss_G: 0.7627 D(x): 0.5304 D(G(z)): 0.5304 / 0.4695\n",
            "[1/200][95/391] Loss_D: 1.4035 Loss_G: 0.6403 D(x): 0.4695 D(G(z)): 0.4695 / 0.5307\n",
            "[1/200][96/391] Loss_D: 1.4035 Loss_G: 0.7639 D(x): 0.5307 D(G(z)): 0.5307 / 0.4690\n",
            "[1/200][97/391] Loss_D: 1.4034 Loss_G: 0.6386 D(x): 0.4689 D(G(z)): 0.4689 / 0.5315\n",
            "[1/200][98/391] Loss_D: 1.4036 Loss_G: 0.7664 D(x): 0.5316 D(G(z)): 0.5316 / 0.4677\n",
            "[1/200][99/391] Loss_D: 1.4036 Loss_G: 0.6355 D(x): 0.4677 D(G(z)): 0.4677 / 0.5331\n",
            "[1/200][100/391] Loss_D: 1.4039 Loss_G: 0.7705 D(x): 0.5332 D(G(z)): 0.5332 / 0.4658\n",
            "[1/200][101/391] Loss_D: 1.4040 Loss_G: 0.6311 D(x): 0.4658 D(G(z)): 0.4657 / 0.5355\n",
            "[1/200][102/391] Loss_D: 1.4044 Loss_G: 0.7763 D(x): 0.5355 D(G(z)): 0.5355 / 0.4631\n",
            "[1/200][103/391] Loss_D: 1.4046 Loss_G: 0.6253 D(x): 0.4631 D(G(z)): 0.4630 / 0.5386\n",
            "[1/200][104/391] Loss_D: 1.4052 Loss_G: 0.7839 D(x): 0.5386 D(G(z)): 0.5386 / 0.4595\n",
            "[1/200][105/391] Loss_D: 1.4056 Loss_G: 0.6178 D(x): 0.4595 D(G(z)): 0.4595 / 0.5425\n",
            "[1/200][106/391] Loss_D: 1.4064 Loss_G: 0.7929 D(x): 0.5426 D(G(z)): 0.5426 / 0.4554\n",
            "[1/200][107/391] Loss_D: 1.4069 Loss_G: 0.6090 D(x): 0.4553 D(G(z)): 0.4553 / 0.5473\n",
            "[1/200][108/391] Loss_D: 1.4080 Loss_G: 0.8057 D(x): 0.5474 D(G(z)): 0.5474 / 0.4496\n",
            "[1/200][109/391] Loss_D: 1.4090 Loss_G: 0.5972 D(x): 0.4496 D(G(z)): 0.4495 / 0.5538\n",
            "[1/200][110/391] Loss_D: 1.4105 Loss_G: 0.8215 D(x): 0.5538 D(G(z)): 0.5539 / 0.4425\n",
            "[1/200][111/391] Loss_D: 1.4120 Loss_G: 0.5836 D(x): 0.4425 D(G(z)): 0.4424 / 0.5613\n",
            "[1/200][112/391] Loss_D: 1.4140 Loss_G: 0.8395 D(x): 0.5614 D(G(z)): 0.5615 / 0.4346\n",
            "[1/200][113/391] Loss_D: 1.4159 Loss_G: 0.5680 D(x): 0.4345 D(G(z)): 0.4345 / 0.5702\n",
            "[1/200][114/391] Loss_D: 1.4187 Loss_G: 0.8595 D(x): 0.5703 D(G(z)): 0.5703 / 0.4260\n",
            "[1/200][115/391] Loss_D: 1.4207 Loss_G: 0.5527 D(x): 0.4259 D(G(z)): 0.4258 / 0.5789\n",
            "[1/200][116/391] Loss_D: 1.4240 Loss_G: 0.8857 D(x): 0.5790 D(G(z)): 0.5791 / 0.4150\n",
            "[1/200][117/391] Loss_D: 1.4279 Loss_G: 0.5296 D(x): 0.4149 D(G(z)): 0.4148 / 0.5925\n",
            "[1/200][118/391] Loss_D: 1.4338 Loss_G: 0.9219 D(x): 0.5926 D(G(z)): 0.5927 / 0.4002\n",
            "[1/200][119/391] Loss_D: 1.4392 Loss_G: 0.5075 D(x): 0.4002 D(G(z)): 0.4001 / 0.6057\n",
            "[1/200][120/391] Loss_D: 1.4447 Loss_G: 0.9474 D(x): 0.6058 D(G(z)): 0.6059 / 0.3901\n",
            "[1/200][121/391] Loss_D: 1.4481 Loss_G: 0.4984 D(x): 0.3900 D(G(z)): 0.3900 / 0.6112\n",
            "[1/200][122/391] Loss_D: 1.4497 Loss_G: 0.9901 D(x): 0.6114 D(G(z)): 0.6115 / 0.3739\n",
            "[1/200][123/391] Loss_D: 1.4647 Loss_G: 0.4548 D(x): 0.3738 D(G(z)): 0.3736 / 0.6386\n",
            "[1/200][124/391] Loss_D: 1.4794 Loss_G: 1.0514 D(x): 0.6387 D(G(z)): 0.6388 / 0.3518\n",
            "[1/200][125/391] Loss_D: 1.4915 Loss_G: 0.4355 D(x): 0.3516 D(G(z)): 0.3515 / 0.6512\n",
            "[1/200][126/391] Loss_D: 1.4960 Loss_G: 1.0522 D(x): 0.6514 D(G(z)): 0.6515 / 0.3515\n",
            "[1/200][127/391] Loss_D: 1.4922 Loss_G: 0.4550 D(x): 0.3514 D(G(z)): 0.3512 / 0.6387\n",
            "[1/200][128/391] Loss_D: 1.4802 Loss_G: 0.9908 D(x): 0.6388 D(G(z)): 0.6389 / 0.3739\n",
            "[1/200][129/391] Loss_D: 1.4659 Loss_G: 0.4960 D(x): 0.3738 D(G(z)): 0.3736 / 0.6132\n",
            "[1/200][130/391] Loss_D: 1.4531 Loss_G: 0.9283 D(x): 0.6133 D(G(z)): 0.6134 / 0.3980\n",
            "[1/200][131/391] Loss_D: 1.4428 Loss_G: 0.5333 D(x): 0.3980 D(G(z)): 0.3979 / 0.5908\n",
            "[1/200][132/391] Loss_D: 1.4340 Loss_G: 0.8767 D(x): 0.5909 D(G(z)): 0.5910 / 0.4191\n",
            "[1/200][133/391] Loss_D: 1.4269 Loss_G: 0.5669 D(x): 0.4191 D(G(z)): 0.4190 / 0.5712\n",
            "[1/200][134/391] Loss_D: 1.4209 Loss_G: 0.8341 D(x): 0.5713 D(G(z)): 0.5714 / 0.4373\n",
            "[1/200][135/391] Loss_D: 1.4161 Loss_G: 0.5956 D(x): 0.4373 D(G(z)): 0.4372 / 0.5550\n",
            "[1/200][136/391] Loss_D: 1.4124 Loss_G: 0.8010 D(x): 0.5551 D(G(z)): 0.5551 / 0.4520\n",
            "[1/200][137/391] Loss_D: 1.4093 Loss_G: 0.6197 D(x): 0.4519 D(G(z)): 0.4519 / 0.5418\n",
            "[1/200][138/391] Loss_D: 1.4070 Loss_G: 0.7756 D(x): 0.5418 D(G(z)): 0.5418 / 0.4636\n",
            "[1/200][139/391] Loss_D: 1.4052 Loss_G: 0.6380 D(x): 0.4635 D(G(z)): 0.4635 / 0.5319\n",
            "[1/200][140/391] Loss_D: 1.4038 Loss_G: 0.7580 D(x): 0.5319 D(G(z)): 0.5319 / 0.4717\n",
            "[1/200][141/391] Loss_D: 1.4028 Loss_G: 0.6507 D(x): 0.4717 D(G(z)): 0.4717 / 0.5251\n",
            "[1/200][142/391] Loss_D: 1.4021 Loss_G: 0.7458 D(x): 0.5251 D(G(z)): 0.5252 / 0.4775\n",
            "[1/200][143/391] Loss_D: 1.4015 Loss_G: 0.6598 D(x): 0.4775 D(G(z)): 0.4775 / 0.5203\n",
            "[1/200][144/391] Loss_D: 1.4010 Loss_G: 0.7374 D(x): 0.5204 D(G(z)): 0.5204 / 0.4815\n",
            "[1/200][145/391] Loss_D: 1.4006 Loss_G: 0.6661 D(x): 0.4815 D(G(z)): 0.4814 / 0.5170\n",
            "[1/200][146/391] Loss_D: 1.4003 Loss_G: 0.7315 D(x): 0.5170 D(G(z)): 0.5170 / 0.4842\n",
            "[1/200][147/391] Loss_D: 1.4000 Loss_G: 0.6704 D(x): 0.4842 D(G(z)): 0.4842 / 0.5147\n",
            "[1/200][148/391] Loss_D: 1.3998 Loss_G: 0.7275 D(x): 0.5147 D(G(z)): 0.5147 / 0.4861\n",
            "[1/200][149/391] Loss_D: 1.3996 Loss_G: 0.6734 D(x): 0.4861 D(G(z)): 0.4861 / 0.5132\n",
            "[1/200][150/391] Loss_D: 1.3994 Loss_G: 0.7248 D(x): 0.5132 D(G(z)): 0.5132 / 0.4874\n",
            "[1/200][151/391] Loss_D: 1.3992 Loss_G: 0.6752 D(x): 0.4874 D(G(z)): 0.4874 / 0.5122\n",
            "[1/200][152/391] Loss_D: 1.3991 Loss_G: 0.7232 D(x): 0.5122 D(G(z)): 0.5122 / 0.4882\n",
            "[1/200][153/391] Loss_D: 1.3990 Loss_G: 0.6762 D(x): 0.4882 D(G(z)): 0.4881 / 0.5116\n",
            "[1/200][154/391] Loss_D: 1.3989 Loss_G: 0.7223 D(x): 0.5116 D(G(z)): 0.5116 / 0.4885\n",
            "[1/200][155/391] Loss_D: 1.3988 Loss_G: 0.6765 D(x): 0.4885 D(G(z)): 0.4885 / 0.5114\n",
            "[1/200][156/391] Loss_D: 1.3987 Loss_G: 0.7221 D(x): 0.5114 D(G(z)): 0.5114 / 0.4886\n",
            "[1/200][157/391] Loss_D: 1.3986 Loss_G: 0.6762 D(x): 0.4886 D(G(z)): 0.4886 / 0.5115\n",
            "[1/200][158/391] Loss_D: 1.3985 Loss_G: 0.7227 D(x): 0.5115 D(G(z)): 0.5115 / 0.4883\n",
            "[1/200][159/391] Loss_D: 1.3985 Loss_G: 0.6753 D(x): 0.4883 D(G(z)): 0.4883 / 0.5120\n",
            "[1/200][160/391] Loss_D: 1.3984 Loss_G: 0.7238 D(x): 0.5120 D(G(z)): 0.5120 / 0.4877\n",
            "[1/200][161/391] Loss_D: 1.3984 Loss_G: 0.6736 D(x): 0.4877 D(G(z)): 0.4877 / 0.5128\n",
            "[1/200][162/391] Loss_D: 1.3984 Loss_G: 0.7259 D(x): 0.5128 D(G(z)): 0.5128 / 0.4867\n",
            "[1/200][163/391] Loss_D: 1.3983 Loss_G: 0.6711 D(x): 0.4866 D(G(z)): 0.4866 / 0.5140\n",
            "[1/200][164/391] Loss_D: 1.3984 Loss_G: 0.7288 D(x): 0.5140 D(G(z)): 0.5140 / 0.4852\n",
            "[1/200][165/391] Loss_D: 1.3984 Loss_G: 0.6678 D(x): 0.4852 D(G(z)): 0.4852 / 0.5157\n",
            "[1/200][166/391] Loss_D: 1.3984 Loss_G: 0.7328 D(x): 0.5157 D(G(z)): 0.5157 / 0.4832\n",
            "[1/200][167/391] Loss_D: 1.3985 Loss_G: 0.6633 D(x): 0.4832 D(G(z)): 0.4832 / 0.5180\n",
            "[1/200][168/391] Loss_D: 1.3986 Loss_G: 0.7382 D(x): 0.5180 D(G(z)): 0.5180 / 0.4806\n",
            "[1/200][169/391] Loss_D: 1.3987 Loss_G: 0.6573 D(x): 0.4806 D(G(z)): 0.4805 / 0.5211\n",
            "[1/200][170/391] Loss_D: 1.3990 Loss_G: 0.7455 D(x): 0.5211 D(G(z)): 0.5211 / 0.4771\n",
            "[1/200][171/391] Loss_D: 1.3992 Loss_G: 0.6492 D(x): 0.4770 D(G(z)): 0.4770 / 0.5253\n",
            "[1/200][172/391] Loss_D: 1.3996 Loss_G: 0.7558 D(x): 0.5253 D(G(z)): 0.5253 / 0.4722\n",
            "[1/200][173/391] Loss_D: 1.4001 Loss_G: 0.6387 D(x): 0.4721 D(G(z)): 0.4721 / 0.5308\n",
            "[1/200][174/391] Loss_D: 1.4008 Loss_G: 0.7693 D(x): 0.5308 D(G(z)): 0.5308 / 0.4658\n",
            "[1/200][175/391] Loss_D: 1.4015 Loss_G: 0.6251 D(x): 0.4658 D(G(z)): 0.4658 / 0.5380\n",
            "[1/200][176/391] Loss_D: 1.4027 Loss_G: 0.7871 D(x): 0.5381 D(G(z)): 0.5381 / 0.4576\n",
            "[1/200][177/391] Loss_D: 1.4040 Loss_G: 0.6078 D(x): 0.4575 D(G(z)): 0.4575 / 0.5474\n",
            "[1/200][178/391] Loss_D: 1.4058 Loss_G: 0.8103 D(x): 0.5474 D(G(z)): 0.5475 / 0.4471\n",
            "[1/200][179/391] Loss_D: 1.4079 Loss_G: 0.5867 D(x): 0.4470 D(G(z)): 0.4470 / 0.5590\n",
            "[1/200][180/391] Loss_D: 1.4108 Loss_G: 0.8389 D(x): 0.5591 D(G(z)): 0.5591 / 0.4344\n",
            "[1/200][181/391] Loss_D: 1.4139 Loss_G: 0.5626 D(x): 0.4344 D(G(z)): 0.4343 / 0.5726\n",
            "[1/200][182/391] Loss_D: 1.4180 Loss_G: 0.8721 D(x): 0.5727 D(G(z)): 0.5727 / 0.4202\n",
            "[1/200][183/391] Loss_D: 1.4223 Loss_G: 0.5382 D(x): 0.4201 D(G(z)): 0.4201 / 0.5868\n",
            "[1/200][184/391] Loss_D: 1.4273 Loss_G: 0.9053 D(x): 0.5868 D(G(z)): 0.5869 / 0.4065\n",
            "[1/200][185/391] Loss_D: 1.4321 Loss_G: 0.5176 D(x): 0.4065 D(G(z)): 0.4064 / 0.5990\n",
            "[1/200][186/391] Loss_D: 1.4367 Loss_G: 0.9297 D(x): 0.5991 D(G(z)): 0.5991 / 0.3967\n",
            "[1/200][187/391] Loss_D: 1.4402 Loss_G: 0.5068 D(x): 0.3966 D(G(z)): 0.3966 / 0.6055\n",
            "[1/200][188/391] Loss_D: 1.4423 Loss_G: 0.9366 D(x): 0.6055 D(G(z)): 0.6056 / 0.3940\n",
            "[1/200][189/391] Loss_D: 1.4426 Loss_G: 0.5083 D(x): 0.3939 D(G(z)): 0.3938 / 0.6046\n",
            "[1/200][190/391] Loss_D: 1.4415 Loss_G: 0.9259 D(x): 0.6046 D(G(z)): 0.6047 / 0.3982\n",
            "[1/200][191/391] Loss_D: 1.4389 Loss_G: 0.5189 D(x): 0.3982 D(G(z)): 0.3981 / 0.5982\n",
            "[1/200][192/391] Loss_D: 1.4361 Loss_G: 0.9070 D(x): 0.5983 D(G(z)): 0.5983 / 0.4058\n",
            "[1/200][193/391] Loss_D: 1.4328 Loss_G: 0.5321 D(x): 0.4058 D(G(z)): 0.4057 / 0.5904\n",
            "[1/200][194/391] Loss_D: 1.4300 Loss_G: 0.8880 D(x): 0.5905 D(G(z)): 0.5905 / 0.4136\n",
            "[1/200][195/391] Loss_D: 1.4270 Loss_G: 0.5459 D(x): 0.4136 D(G(z)): 0.4135 / 0.5823\n",
            "[1/200][196/391] Loss_D: 1.4242 Loss_G: 0.8690 D(x): 0.5823 D(G(z)): 0.5824 / 0.4216\n",
            "[1/200][197/391] Loss_D: 1.4216 Loss_G: 0.5596 D(x): 0.4215 D(G(z)): 0.4215 / 0.5744\n",
            "[1/200][198/391] Loss_D: 1.4191 Loss_G: 0.8497 D(x): 0.5744 D(G(z)): 0.5745 / 0.4298\n",
            "[1/200][199/391] Loss_D: 1.4165 Loss_G: 0.5742 D(x): 0.4297 D(G(z)): 0.4296 / 0.5660\n",
            "[1/200][200/391] Loss_D: 1.4143 Loss_G: 0.8303 D(x): 0.5661 D(G(z)): 0.5661 / 0.4382\n",
            "[1/200][201/391] Loss_D: 1.4120 Loss_G: 0.5890 D(x): 0.4381 D(G(z)): 0.4381 / 0.5577\n",
            "[1/200][202/391] Loss_D: 1.4100 Loss_G: 0.8122 D(x): 0.5577 D(G(z)): 0.5578 / 0.4462\n",
            "[1/200][203/391] Loss_D: 1.4081 Loss_G: 0.6026 D(x): 0.4461 D(G(z)): 0.4461 / 0.5502\n",
            "[1/200][204/391] Loss_D: 1.4066 Loss_G: 0.7966 D(x): 0.5502 D(G(z)): 0.5502 / 0.4532\n",
            "[1/200][205/391] Loss_D: 1.4052 Loss_G: 0.6142 D(x): 0.4531 D(G(z)): 0.4531 / 0.5438\n",
            "[1/200][206/391] Loss_D: 1.4041 Loss_G: 0.7842 D(x): 0.5438 D(G(z)): 0.5438 / 0.4588\n",
            "[1/200][207/391] Loss_D: 1.4031 Loss_G: 0.6229 D(x): 0.4587 D(G(z)): 0.4587 / 0.5391\n",
            "[1/200][208/391] Loss_D: 1.4024 Loss_G: 0.7754 D(x): 0.5391 D(G(z)): 0.5391 / 0.4628\n",
            "[1/200][209/391] Loss_D: 1.4017 Loss_G: 0.6293 D(x): 0.4628 D(G(z)): 0.4627 / 0.5356\n",
            "[1/200][210/391] Loss_D: 1.4012 Loss_G: 0.7690 D(x): 0.5356 D(G(z)): 0.5356 / 0.4658\n",
            "[1/200][211/391] Loss_D: 1.4007 Loss_G: 0.6338 D(x): 0.4657 D(G(z)): 0.4657 / 0.5331\n",
            "[1/200][212/391] Loss_D: 1.4004 Loss_G: 0.7645 D(x): 0.5331 D(G(z)): 0.5332 / 0.4678\n",
            "[1/200][213/391] Loss_D: 1.4001 Loss_G: 0.6370 D(x): 0.4678 D(G(z)): 0.4678 / 0.5314\n",
            "[1/200][214/391] Loss_D: 1.3999 Loss_G: 0.7615 D(x): 0.5314 D(G(z)): 0.5314 / 0.4692\n",
            "[1/200][215/391] Loss_D: 1.3996 Loss_G: 0.6684 D(x): 0.4692 D(G(z)): 0.4692 / 0.5151\n",
            "[1/200][216/391] Loss_D: 1.3970 Loss_G: 0.7053 D(x): 0.5150 D(G(z)): 0.5150 / 0.4965\n",
            "[1/200][217/391] Loss_D: 1.3965 Loss_G: 0.7007 D(x): 0.4964 D(G(z)): 0.4963 / 0.4989\n",
            "[1/200][218/391] Loss_D: 1.3966 Loss_G: 0.6907 D(x): 0.4988 D(G(z)): 0.4987 / 0.5039\n",
            "[1/200][219/391] Loss_D: 1.3968 Loss_G: 0.7096 D(x): 0.5038 D(G(z)): 0.5038 / 0.4944\n",
            "[1/200][220/391] Loss_D: 1.3968 Loss_G: 0.6843 D(x): 0.4944 D(G(z)): 0.4943 / 0.5071\n",
            "[1/200][221/391] Loss_D: 1.3969 Loss_G: 0.7148 D(x): 0.5070 D(G(z)): 0.5070 / 0.4918\n",
            "[1/200][222/391] Loss_D: 1.3969 Loss_G: 0.6788 D(x): 0.4918 D(G(z)): 0.4917 / 0.5098\n",
            "[1/200][223/391] Loss_D: 1.3970 Loss_G: 0.7223 D(x): 0.5098 D(G(z)): 0.5098 / 0.4881\n",
            "[1/200][224/391] Loss_D: 1.3971 Loss_G: 0.6697 D(x): 0.4881 D(G(z)): 0.4881 / 0.5145\n",
            "[1/200][225/391] Loss_D: 1.3973 Loss_G: 0.7342 D(x): 0.5145 D(G(z)): 0.5145 / 0.4823\n",
            "[1/200][226/391] Loss_D: 1.3976 Loss_G: 0.6555 D(x): 0.4823 D(G(z)): 0.4822 / 0.5218\n",
            "[1/200][227/391] Loss_D: 1.3982 Loss_G: 0.7533 D(x): 0.5218 D(G(z)): 0.5218 / 0.4732\n",
            "[1/200][228/391] Loss_D: 1.3991 Loss_G: 0.6339 D(x): 0.4731 D(G(z)): 0.4731 / 0.5331\n",
            "[1/200][229/391] Loss_D: 1.4006 Loss_G: 0.7834 D(x): 0.5332 D(G(z)): 0.5332 / 0.4591\n",
            "[1/200][230/391] Loss_D: 1.4027 Loss_G: 0.6019 D(x): 0.4591 D(G(z)): 0.4590 / 0.5504\n",
            "[1/200][231/391] Loss_D: 1.4063 Loss_G: 0.8297 D(x): 0.5505 D(G(z)): 0.5505 / 0.4383\n",
            "[1/200][232/391] Loss_D: 1.4112 Loss_G: 0.5604 D(x): 0.4383 D(G(z)): 0.4382 / 0.5737\n",
            "[1/200][233/391] Loss_D: 1.4180 Loss_G: 0.8864 D(x): 0.5738 D(G(z)): 0.5739 / 0.4141\n",
            "[1/200][234/391] Loss_D: 1.4258 Loss_G: 0.5197 D(x): 0.4141 D(G(z)): 0.4140 / 0.5975\n",
            "[1/200][235/391] Loss_D: 1.4348 Loss_G: 0.9414 D(x): 0.5976 D(G(z)): 0.5977 / 0.3920\n",
            "[1/200][236/391] Loss_D: 1.4436 Loss_G: 0.4893 D(x): 0.3919 D(G(z)): 0.3918 / 0.6160\n",
            "[1/200][237/391] Loss_D: 1.4513 Loss_G: 0.9756 D(x): 0.6161 D(G(z)): 0.6161 / 0.3788\n",
            "[1/200][238/391] Loss_D: 1.4564 Loss_G: 0.4783 D(x): 0.3786 D(G(z)): 0.3785 / 0.6227\n",
            "[1/200][239/391] Loss_D: 1.4582 Loss_G: 0.9744 D(x): 0.6228 D(G(z)): 0.6229 / 0.3792\n",
            "[1/200][240/391] Loss_D: 1.4560 Loss_G: 0.4899 D(x): 0.3791 D(G(z)): 0.3790 / 0.6156\n",
            "[1/200][241/391] Loss_D: 1.4510 Loss_G: 0.9452 D(x): 0.6157 D(G(z)): 0.6158 / 0.3905\n",
            "[1/200][242/391] Loss_D: 1.4451 Loss_G: 0.5119 D(x): 0.3904 D(G(z)): 0.3903 / 0.6022\n",
            "[1/200][243/391] Loss_D: 1.4389 Loss_G: 0.9076 D(x): 0.6023 D(G(z)): 0.6024 / 0.4054\n",
            "[1/200][244/391] Loss_D: 1.4324 Loss_G: 0.5386 D(x): 0.4054 D(G(z)): 0.4053 / 0.5864\n",
            "[1/200][245/391] Loss_D: 1.4264 Loss_G: 0.8679 D(x): 0.5864 D(G(z)): 0.5865 / 0.4219\n",
            "[1/200][246/391] Loss_D: 1.4207 Loss_G: 0.5668 D(x): 0.4218 D(G(z)): 0.4218 / 0.5701\n",
            "[1/200][247/391] Loss_D: 1.4159 Loss_G: 0.8317 D(x): 0.5701 D(G(z)): 0.5702 / 0.4374\n",
            "[1/200][248/391] Loss_D: 1.4117 Loss_G: 0.5923 D(x): 0.4374 D(G(z)): 0.4373 / 0.5557\n",
            "[1/200][249/391] Loss_D: 1.4084 Loss_G: 0.8023 D(x): 0.5557 D(G(z)): 0.5558 / 0.4504\n",
            "[1/200][250/391] Loss_D: 1.4057 Loss_G: 0.6131 D(x): 0.4504 D(G(z)): 0.4504 / 0.5442\n",
            "[1/200][251/391] Loss_D: 1.4037 Loss_G: 0.7804 D(x): 0.5443 D(G(z)): 0.5443 / 0.4604\n",
            "[1/200][252/391] Loss_D: 1.4020 Loss_G: 0.6290 D(x): 0.4604 D(G(z)): 0.4603 / 0.5356\n",
            "[1/200][253/391] Loss_D: 1.4008 Loss_G: 0.7644 D(x): 0.5356 D(G(z)): 0.5357 / 0.4678\n",
            "[1/200][254/391] Loss_D: 1.3997 Loss_G: 0.6406 D(x): 0.4678 D(G(z)): 0.4678 / 0.5294\n",
            "[1/200][255/391] Loss_D: 1.3990 Loss_G: 0.7535 D(x): 0.5294 D(G(z)): 0.5295 / 0.4729\n",
            "[1/200][256/391] Loss_D: 1.3984 Loss_G: 0.6486 D(x): 0.4729 D(G(z)): 0.4729 / 0.5252\n",
            "[1/200][257/391] Loss_D: 1.3979 Loss_G: 0.7459 D(x): 0.5252 D(G(z)): 0.5252 / 0.4764\n",
            "[1/200][258/391] Loss_D: 1.3975 Loss_G: 0.6542 D(x): 0.4764 D(G(z)): 0.4764 / 0.5222\n",
            "[1/200][259/391] Loss_D: 1.3972 Loss_G: 0.7406 D(x): 0.5222 D(G(z)): 0.5222 / 0.4789\n",
            "[1/200][260/391] Loss_D: 1.3969 Loss_G: 0.6581 D(x): 0.4789 D(G(z)): 0.4789 / 0.5201\n",
            "[1/200][261/391] Loss_D: 1.3968 Loss_G: 0.7370 D(x): 0.5201 D(G(z)): 0.5201 / 0.4807\n",
            "[1/200][262/391] Loss_D: 1.3965 Loss_G: 0.6608 D(x): 0.4807 D(G(z)): 0.4806 / 0.5187\n",
            "[1/200][263/391] Loss_D: 1.3964 Loss_G: 0.7346 D(x): 0.5187 D(G(z)): 0.5187 / 0.4818\n",
            "[1/200][264/391] Loss_D: 1.3963 Loss_G: 0.6624 D(x): 0.4818 D(G(z)): 0.4818 / 0.5178\n",
            "[1/200][265/391] Loss_D: 1.3962 Loss_G: 0.7332 D(x): 0.5178 D(G(z)): 0.5178 / 0.4824\n",
            "[1/200][266/391] Loss_D: 1.3960 Loss_G: 0.6632 D(x): 0.4824 D(G(z)): 0.4824 / 0.5174\n",
            "[1/200][267/391] Loss_D: 1.3960 Loss_G: 0.7327 D(x): 0.5174 D(G(z)): 0.5174 / 0.4826\n",
            "[1/200][268/391] Loss_D: 1.3959 Loss_G: 0.6631 D(x): 0.4826 D(G(z)): 0.4826 / 0.5174\n",
            "[1/200][269/391] Loss_D: 1.3959 Loss_G: 0.7332 D(x): 0.5174 D(G(z)): 0.5174 / 0.4824\n",
            "[1/200][270/391] Loss_D: 1.3958 Loss_G: 0.6620 D(x): 0.4824 D(G(z)): 0.4823 / 0.5180\n",
            "[1/200][271/391] Loss_D: 1.3959 Loss_G: 0.7348 D(x): 0.5180 D(G(z)): 0.5180 / 0.4816\n",
            "[1/200][272/391] Loss_D: 1.3959 Loss_G: 0.6599 D(x): 0.4816 D(G(z)): 0.4816 / 0.5190\n",
            "[1/200][273/391] Loss_D: 1.3959 Loss_G: 0.7374 D(x): 0.5190 D(G(z)): 0.5190 / 0.4803\n",
            "[1/200][274/391] Loss_D: 1.3959 Loss_G: 0.6570 D(x): 0.4803 D(G(z)): 0.4803 / 0.5205\n",
            "[1/200][275/391] Loss_D: 1.3961 Loss_G: 0.7410 D(x): 0.5205 D(G(z)): 0.5205 / 0.4785\n",
            "[1/200][276/391] Loss_D: 1.3961 Loss_G: 0.6530 D(x): 0.4785 D(G(z)): 0.4785 / 0.5226\n",
            "[1/200][277/391] Loss_D: 1.3963 Loss_G: 0.7460 D(x): 0.5226 D(G(z)): 0.5226 / 0.4762\n",
            "[1/200][278/391] Loss_D: 1.3965 Loss_G: 0.6478 D(x): 0.4761 D(G(z)): 0.4761 / 0.5253\n",
            "[1/200][279/391] Loss_D: 1.3968 Loss_G: 0.7524 D(x): 0.5253 D(G(z)): 0.5253 / 0.4731\n",
            "[1/200][280/391] Loss_D: 1.3970 Loss_G: 0.6411 D(x): 0.4731 D(G(z)): 0.4730 / 0.5288\n",
            "[1/200][281/391] Loss_D: 1.3974 Loss_G: 0.7607 D(x): 0.5288 D(G(z)): 0.5288 / 0.4692\n",
            "[1/200][282/391] Loss_D: 1.3979 Loss_G: 0.6328 D(x): 0.4691 D(G(z)): 0.4691 / 0.5331\n",
            "[1/200][283/391] Loss_D: 1.3985 Loss_G: 0.7712 D(x): 0.5332 D(G(z)): 0.5332 / 0.4643\n",
            "[1/200][284/391] Loss_D: 1.3991 Loss_G: 0.6225 D(x): 0.4642 D(G(z)): 0.4642 / 0.5386\n",
            "[1/200][285/391] Loss_D: 1.4000 Loss_G: 0.7843 D(x): 0.5387 D(G(z)): 0.5387 / 0.4582\n",
            "[1/200][286/391] Loss_D: 1.4009 Loss_G: 0.6102 D(x): 0.4581 D(G(z)): 0.4581 / 0.5453\n",
            "[1/200][287/391] Loss_D: 1.4022 Loss_G: 0.8005 D(x): 0.5453 D(G(z)): 0.5454 / 0.4508\n",
            "[1/200][288/391] Loss_D: 1.4036 Loss_G: 0.5950 D(x): 0.4508 D(G(z)): 0.4508 / 0.5536\n",
            "[1/200][289/391] Loss_D: 1.4055 Loss_G: 0.8216 D(x): 0.5537 D(G(z)): 0.5537 / 0.4414\n",
            "[1/200][290/391] Loss_D: 1.4076 Loss_G: 0.5766 D(x): 0.4414 D(G(z)): 0.4413 / 0.5639\n",
            "[1/200][291/391] Loss_D: 1.4104 Loss_G: 0.8467 D(x): 0.5640 D(G(z)): 0.5640 / 0.4304\n",
            "[1/200][292/391] Loss_D: 1.4133 Loss_G: 0.5570 D(x): 0.4304 D(G(z)): 0.4303 / 0.5751\n",
            "[1/200][293/391] Loss_D: 1.4167 Loss_G: 0.8724 D(x): 0.5751 D(G(z)): 0.5752 / 0.4195\n",
            "[1/200][294/391] Loss_D: 1.4200 Loss_G: 0.5396 D(x): 0.4195 D(G(z)): 0.4194 / 0.5852\n",
            "[1/200][295/391] Loss_D: 1.4233 Loss_G: 0.8929 D(x): 0.5852 D(G(z)): 0.5853 / 0.4110\n",
            "[1/200][296/391] Loss_D: 1.4259 Loss_G: 0.5282 D(x): 0.4110 D(G(z)): 0.4109 / 0.5919\n",
            "[1/200][297/391] Loss_D: 1.4282 Loss_G: 0.9054 D(x): 0.5919 D(G(z)): 0.5920 / 0.4059\n",
            "[1/200][298/391] Loss_D: 1.4298 Loss_G: 0.5231 D(x): 0.4058 D(G(z)): 0.4058 / 0.5949\n",
            "[1/200][299/391] Loss_D: 1.4305 Loss_G: 0.9086 D(x): 0.5949 D(G(z)): 0.5949 / 0.4046\n",
            "[1/200][300/391] Loss_D: 1.4309 Loss_G: 0.5243 D(x): 0.4045 D(G(z)): 0.4044 / 0.5942\n",
            "[1/200][301/391] Loss_D: 1.4301 Loss_G: 0.9008 D(x): 0.5942 D(G(z)): 0.5943 / 0.4078\n",
            "[1/200][302/391] Loss_D: 1.4285 Loss_G: 0.5284 D(x): 0.4077 D(G(z)): 0.4076 / 0.5918\n",
            "[1/200][303/391] Loss_D: 1.4284 Loss_G: 0.9006 D(x): 0.5919 D(G(z)): 0.5919 / 0.4079\n",
            "[1/200][304/391] Loss_D: 1.4285 Loss_G: 0.5313 D(x): 0.4078 D(G(z)): 0.4078 / 0.5901\n",
            "[1/200][305/391] Loss_D: 1.4274 Loss_G: 0.8962 D(x): 0.5902 D(G(z)): 0.5903 / 0.4097\n",
            "[1/200][306/391] Loss_D: 1.4273 Loss_G: 0.5311 D(x): 0.4097 D(G(z)): 0.4096 / 0.5903\n",
            "[1/200][307/391] Loss_D: 1.4275 Loss_G: 0.8978 D(x): 0.5903 D(G(z)): 0.5904 / 0.4091\n",
            "[1/200][308/391] Loss_D: 1.4279 Loss_G: 0.5312 D(x): 0.4090 D(G(z)): 0.4090 / 0.5902\n",
            "[1/200][309/391] Loss_D: 1.4276 Loss_G: 0.8924 D(x): 0.5903 D(G(z)): 0.5904 / 0.4113\n",
            "[1/200][310/391] Loss_D: 1.4263 Loss_G: 0.5387 D(x): 0.4113 D(G(z)): 0.4112 / 0.5859\n",
            "[1/200][311/391] Loss_D: 1.4244 Loss_G: 0.8770 D(x): 0.5859 D(G(z)): 0.5860 / 0.4177\n",
            "[1/200][312/391] Loss_D: 1.4218 Loss_G: 0.5521 D(x): 0.4176 D(G(z)): 0.4176 / 0.5781\n",
            "[1/200][313/391] Loss_D: 1.4191 Loss_G: 0.8566 D(x): 0.5781 D(G(z)): 0.5782 / 0.4263\n",
            "[1/200][314/391] Loss_D: 1.4162 Loss_G: 0.5681 D(x): 0.4263 D(G(z)): 0.4262 / 0.5689\n",
            "[1/200][315/391] Loss_D: 1.4135 Loss_G: 0.8342 D(x): 0.5689 D(G(z)): 0.5690 / 0.4359\n",
            "[1/200][316/391] Loss_D: 1.4108 Loss_G: 0.5849 D(x): 0.4359 D(G(z)): 0.4359 / 0.5594\n",
            "[1/200][317/391] Loss_D: 1.4085 Loss_G: 0.8142 D(x): 0.5594 D(G(z)): 0.5595 / 0.4447\n",
            "[1/200][318/391] Loss_D: 1.4064 Loss_G: 0.5995 D(x): 0.4447 D(G(z)): 0.4447 / 0.5512\n",
            "[1/200][319/391] Loss_D: 1.4047 Loss_G: 0.7968 D(x): 0.5512 D(G(z)): 0.5513 / 0.4525\n",
            "[1/200][320/391] Loss_D: 1.4031 Loss_G: 0.6122 D(x): 0.4525 D(G(z)): 0.4525 / 0.5442\n",
            "[1/200][321/391] Loss_D: 1.4020 Loss_G: 0.7835 D(x): 0.5443 D(G(z)): 0.5443 / 0.4586\n",
            "[1/200][322/391] Loss_D: 1.4009 Loss_G: 0.6221 D(x): 0.4586 D(G(z)): 0.4585 / 0.5389\n",
            "[1/200][323/391] Loss_D: 1.4001 Loss_G: 0.7730 D(x): 0.5389 D(G(z)): 0.5389 / 0.4634\n",
            "[1/200][324/391] Loss_D: 1.3993 Loss_G: 0.6300 D(x): 0.4634 D(G(z)): 0.4633 / 0.5346\n",
            "[1/200][325/391] Loss_D: 1.3987 Loss_G: 0.7649 D(x): 0.5346 D(G(z)): 0.5346 / 0.4671\n",
            "[1/200][326/391] Loss_D: 1.3981 Loss_G: 0.6361 D(x): 0.4671 D(G(z)): 0.4671 / 0.5313\n",
            "[1/200][327/391] Loss_D: 1.3977 Loss_G: 0.7587 D(x): 0.5313 D(G(z)): 0.5313 / 0.4700\n",
            "[1/200][328/391] Loss_D: 1.3973 Loss_G: 0.6409 D(x): 0.4700 D(G(z)): 0.4700 / 0.5288\n",
            "[1/200][329/391] Loss_D: 1.3970 Loss_G: 0.7540 D(x): 0.5288 D(G(z)): 0.5288 / 0.4722\n",
            "[1/200][330/391] Loss_D: 1.3967 Loss_G: 0.6443 D(x): 0.4722 D(G(z)): 0.4722 / 0.5269\n",
            "[1/200][331/391] Loss_D: 1.3965 Loss_G: 0.7507 D(x): 0.5270 D(G(z)): 0.5270 / 0.4738\n",
            "[1/200][332/391] Loss_D: 1.3963 Loss_G: 0.6466 D(x): 0.4737 D(G(z)): 0.4737 / 0.5257\n",
            "[1/200][333/391] Loss_D: 1.3961 Loss_G: 0.7485 D(x): 0.5257 D(G(z)): 0.5257 / 0.4748\n",
            "[1/200][334/391] Loss_D: 1.3960 Loss_G: 0.6480 D(x): 0.4747 D(G(z)): 0.4747 / 0.5249\n",
            "[1/200][335/391] Loss_D: 1.3959 Loss_G: 0.7475 D(x): 0.5249 D(G(z)): 0.5250 / 0.4752\n",
            "[1/200][336/391] Loss_D: 1.3958 Loss_G: 0.6484 D(x): 0.4752 D(G(z)): 0.4752 / 0.5247\n",
            "[1/200][337/391] Loss_D: 1.3958 Loss_G: 0.7474 D(x): 0.5247 D(G(z)): 0.5247 / 0.4752\n",
            "[1/200][338/391] Loss_D: 1.3957 Loss_G: 0.6480 D(x): 0.4752 D(G(z)): 0.4752 / 0.5249\n",
            "[1/200][339/391] Loss_D: 1.3957 Loss_G: 0.7480 D(x): 0.5249 D(G(z)): 0.5249 / 0.4749\n",
            "[1/200][340/391] Loss_D: 1.3957 Loss_G: 0.6471 D(x): 0.4749 D(G(z)): 0.4749 / 0.5253\n",
            "[1/200][341/391] Loss_D: 1.3957 Loss_G: 0.7493 D(x): 0.5253 D(G(z)): 0.5254 / 0.4743\n",
            "[1/200][342/391] Loss_D: 1.3957 Loss_G: 0.6455 D(x): 0.4743 D(G(z)): 0.4743 / 0.5262\n",
            "[1/200][343/391] Loss_D: 1.3958 Loss_G: 0.7516 D(x): 0.5262 D(G(z)): 0.5262 / 0.4732\n",
            "[1/200][344/391] Loss_D: 1.3959 Loss_G: 0.6430 D(x): 0.4732 D(G(z)): 0.4732 / 0.5275\n",
            "[1/200][345/391] Loss_D: 1.3960 Loss_G: 0.7548 D(x): 0.5275 D(G(z)): 0.5275 / 0.4717\n",
            "[1/200][346/391] Loss_D: 1.3961 Loss_G: 0.6395 D(x): 0.4716 D(G(z)): 0.4716 / 0.5293\n",
            "[1/200][347/391] Loss_D: 1.3964 Loss_G: 0.7591 D(x): 0.5293 D(G(z)): 0.5293 / 0.4696\n",
            "[1/200][348/391] Loss_D: 1.3966 Loss_G: 0.6351 D(x): 0.4696 D(G(z)): 0.4696 / 0.5316\n",
            "[1/200][349/391] Loss_D: 1.3969 Loss_G: 0.7647 D(x): 0.5316 D(G(z)): 0.5317 / 0.4670\n",
            "[1/200][350/391] Loss_D: 1.3972 Loss_G: 0.6295 D(x): 0.4670 D(G(z)): 0.4670 / 0.5346\n",
            "[1/200][351/391] Loss_D: 1.3976 Loss_G: 0.7719 D(x): 0.5346 D(G(z)): 0.5346 / 0.4636\n",
            "[1/200][352/391] Loss_D: 1.3980 Loss_G: 0.6224 D(x): 0.4636 D(G(z)): 0.4636 / 0.5384\n",
            "[1/200][353/391] Loss_D: 1.3986 Loss_G: 0.7808 D(x): 0.5384 D(G(z)): 0.5384 / 0.4595\n",
            "[1/200][354/391] Loss_D: 1.3992 Loss_G: 0.6144 D(x): 0.4595 D(G(z)): 0.4595 / 0.5427\n",
            "[1/200][355/391] Loss_D: 1.4000 Loss_G: 0.7906 D(x): 0.5427 D(G(z)): 0.5427 / 0.4550\n",
            "[1/200][356/391] Loss_D: 1.4007 Loss_G: 0.6057 D(x): 0.4550 D(G(z)): 0.4549 / 0.5474\n",
            "[1/200][357/391] Loss_D: 1.4017 Loss_G: 0.8015 D(x): 0.5474 D(G(z)): 0.5475 / 0.4501\n",
            "[1/200][358/391] Loss_D: 1.4026 Loss_G: 0.5964 D(x): 0.4500 D(G(z)): 0.4500 / 0.5525\n",
            "[1/200][359/391] Loss_D: 1.4037 Loss_G: 0.8132 D(x): 0.5526 D(G(z)): 0.5526 / 0.4448\n",
            "[1/200][360/391] Loss_D: 1.4048 Loss_G: 0.5867 D(x): 0.4448 D(G(z)): 0.4447 / 0.5579\n",
            "[1/200][361/391] Loss_D: 1.4061 Loss_G: 0.8258 D(x): 0.5579 D(G(z)): 0.5579 / 0.4393\n",
            "[1/200][362/391] Loss_D: 1.4074 Loss_G: 0.5765 D(x): 0.4392 D(G(z)): 0.4392 / 0.5636\n",
            "[1/200][363/391] Loss_D: 1.4089 Loss_G: 0.8388 D(x): 0.5636 D(G(z)): 0.5637 / 0.4336\n",
            "[1/200][364/391] Loss_D: 1.4103 Loss_G: 0.5669 D(x): 0.4335 D(G(z)): 0.4335 / 0.5690\n",
            "[1/200][365/391] Loss_D: 1.4118 Loss_G: 0.8493 D(x): 0.5691 D(G(z)): 0.5691 / 0.4290\n",
            "[1/200][366/391] Loss_D: 1.4128 Loss_G: 0.5605 D(x): 0.4290 D(G(z)): 0.4289 / 0.5727\n",
            "[1/200][367/391] Loss_D: 1.4139 Loss_G: 0.8580 D(x): 0.5727 D(G(z)): 0.5727 / 0.4253\n",
            "[1/200][368/391] Loss_D: 1.4150 Loss_G: 0.5534 D(x): 0.4253 D(G(z)): 0.4252 / 0.5768\n",
            "[1/200][369/391] Loss_D: 1.4164 Loss_G: 0.8694 D(x): 0.5768 D(G(z)): 0.5768 / 0.4205\n",
            "[1/200][370/391] Loss_D: 1.4181 Loss_G: 0.5449 D(x): 0.4205 D(G(z)): 0.4204 / 0.5817\n",
            "[1/200][371/391] Loss_D: 1.4197 Loss_G: 0.8789 D(x): 0.5817 D(G(z)): 0.5818 / 0.4165\n",
            "[1/200][372/391] Loss_D: 1.4208 Loss_G: 0.5404 D(x): 0.4165 D(G(z)): 0.4165 / 0.5844\n",
            "[1/200][373/391] Loss_D: 1.4216 Loss_G: 0.8826 D(x): 0.5844 D(G(z)): 0.5845 / 0.4150\n",
            "[1/200][374/391] Loss_D: 1.4219 Loss_G: 0.5398 D(x): 0.4150 D(G(z)): 0.4149 / 0.5847\n",
            "[1/200][375/391] Loss_D: 1.4218 Loss_G: 0.8803 D(x): 0.5847 D(G(z)): 0.5848 / 0.4160\n",
            "[1/200][376/391] Loss_D: 1.4213 Loss_G: 0.5428 D(x): 0.4159 D(G(z)): 0.4159 / 0.5829\n",
            "[1/200][377/391] Loss_D: 1.4206 Loss_G: 0.8738 D(x): 0.5830 D(G(z)): 0.5830 / 0.4187\n",
            "[1/200][378/391] Loss_D: 1.4194 Loss_G: 0.5473 D(x): 0.4187 D(G(z)): 0.4186 / 0.5803\n",
            "[1/200][379/391] Loss_D: 1.4189 Loss_G: 0.8690 D(x): 0.5804 D(G(z)): 0.5804 / 0.4207\n",
            "[1/200][380/391] Loss_D: 1.4181 Loss_G: 0.5516 D(x): 0.4207 D(G(z)): 0.4206 / 0.5778\n",
            "[1/200][381/391] Loss_D: 1.4172 Loss_G: 0.8611 D(x): 0.5779 D(G(z)): 0.5779 / 0.4240\n",
            "[1/200][382/391] Loss_D: 1.4159 Loss_G: 0.5589 D(x): 0.4240 D(G(z)): 0.4239 / 0.5736\n",
            "[1/200][383/391] Loss_D: 1.4146 Loss_G: 0.8492 D(x): 0.5737 D(G(z)): 0.5737 / 0.4291\n",
            "[1/200][384/391] Loss_D: 1.4129 Loss_G: 0.5688 D(x): 0.4291 D(G(z)): 0.4290 / 0.5680\n",
            "[1/200][385/391] Loss_D: 1.4113 Loss_G: 0.8359 D(x): 0.5680 D(G(z)): 0.5681 / 0.4348\n",
            "[1/200][386/391] Loss_D: 1.4096 Loss_G: 0.5790 D(x): 0.4348 D(G(z)): 0.4348 / 0.5622\n",
            "[1/200][387/391] Loss_D: 1.4081 Loss_G: 0.8229 D(x): 0.5622 D(G(z)): 0.5622 / 0.4405\n",
            "[1/200][388/391] Loss_D: 1.4067 Loss_G: 0.5886 D(x): 0.4405 D(G(z)): 0.4404 / 0.5568\n",
            "[1/200][389/391] Loss_D: 1.4055 Loss_G: 0.8111 D(x): 0.5568 D(G(z)): 0.5569 / 0.4457\n",
            "[1/200][390/391] Loss_D: 1.4043 Loss_G: 0.5977 D(x): 0.4457 D(G(z)): 0.4457 / 0.5518\n",
            "[2/200][0/391] Loss_D: 1.4032 Loss_G: 0.8001 D(x): 0.5518 D(G(z)): 0.5518 / 0.4507\n",
            "[2/200][1/391] Loss_D: 1.4022 Loss_G: 0.6063 D(x): 0.4506 D(G(z)): 0.4506 / 0.5470\n",
            "[2/200][2/391] Loss_D: 1.4013 Loss_G: 0.7900 D(x): 0.5470 D(G(z)): 0.5471 / 0.4552\n",
            "[2/200][3/391] Loss_D: 1.4004 Loss_G: 0.6143 D(x): 0.4552 D(G(z)): 0.4552 / 0.5426\n",
            "[2/200][4/391] Loss_D: 1.3996 Loss_G: 0.7809 D(x): 0.5426 D(G(z)): 0.5427 / 0.4594\n",
            "[2/200][5/391] Loss_D: 1.3989 Loss_G: 0.6214 D(x): 0.4593 D(G(z)): 0.4593 / 0.5388\n",
            "[2/200][6/391] Loss_D: 1.3983 Loss_G: 0.7732 D(x): 0.5388 D(G(z)): 0.5388 / 0.4629\n",
            "[2/200][7/391] Loss_D: 1.3977 Loss_G: 0.6272 D(x): 0.4629 D(G(z)): 0.4629 / 0.5356\n",
            "[2/200][8/391] Loss_D: 1.3973 Loss_G: 0.7674 D(x): 0.5357 D(G(z)): 0.5357 / 0.4656\n",
            "[2/200][9/391] Loss_D: 1.3969 Loss_G: 0.6317 D(x): 0.4656 D(G(z)): 0.4656 / 0.5332\n",
            "[2/200][10/391] Loss_D: 1.3966 Loss_G: 0.7623 D(x): 0.5333 D(G(z)): 0.5333 / 0.4679\n",
            "[2/200][11/391] Loss_D: 1.3962 Loss_G: 0.6360 D(x): 0.4679 D(G(z)): 0.4679 / 0.5309\n",
            "[2/200][12/391] Loss_D: 1.3959 Loss_G: 0.7577 D(x): 0.5309 D(G(z)): 0.5309 / 0.4701\n",
            "[2/200][13/391] Loss_D: 1.3956 Loss_G: 0.6396 D(x): 0.4701 D(G(z)): 0.4701 / 0.5290\n",
            "[2/200][14/391] Loss_D: 1.3954 Loss_G: 0.7541 D(x): 0.5290 D(G(z)): 0.5290 / 0.4718\n",
            "[2/200][15/391] Loss_D: 1.3952 Loss_G: 0.6423 D(x): 0.4718 D(G(z)): 0.4717 / 0.5276\n",
            "[2/200][16/391] Loss_D: 1.3950 Loss_G: 0.7517 D(x): 0.5276 D(G(z)): 0.5276 / 0.4729\n",
            "[2/200][17/391] Loss_D: 1.3949 Loss_G: 0.6439 D(x): 0.4729 D(G(z)): 0.4729 / 0.5267\n",
            "[2/200][18/391] Loss_D: 1.3948 Loss_G: 0.7503 D(x): 0.5267 D(G(z)): 0.5267 / 0.4736\n",
            "[2/200][19/391] Loss_D: 1.3947 Loss_G: 0.6447 D(x): 0.4735 D(G(z)): 0.4735 / 0.5263\n",
            "[2/200][20/391] Loss_D: 1.3946 Loss_G: 0.7498 D(x): 0.5263 D(G(z)): 0.5263 / 0.4738\n",
            "[2/200][21/391] Loss_D: 1.3946 Loss_G: 0.6446 D(x): 0.4737 D(G(z)): 0.4737 / 0.5263\n",
            "[2/200][22/391] Loss_D: 1.3946 Loss_G: 0.7503 D(x): 0.5263 D(G(z)): 0.5263 / 0.4735\n",
            "[2/200][23/391] Loss_D: 1.3946 Loss_G: 0.6437 D(x): 0.4735 D(G(z)): 0.4735 / 0.5268\n",
            "[2/200][24/391] Loss_D: 1.3946 Loss_G: 0.7517 D(x): 0.5268 D(G(z)): 0.5268 / 0.4729\n",
            "[2/200][25/391] Loss_D: 1.3947 Loss_G: 0.6419 D(x): 0.4728 D(G(z)): 0.4728 / 0.5277\n",
            "[2/200][26/391] Loss_D: 1.3948 Loss_G: 0.7543 D(x): 0.5277 D(G(z)): 0.5277 / 0.4716\n",
            "[2/200][27/391] Loss_D: 1.3949 Loss_G: 0.6392 D(x): 0.4716 D(G(z)): 0.4716 / 0.5291\n",
            "[2/200][28/391] Loss_D: 1.3950 Loss_G: 0.7576 D(x): 0.5291 D(G(z)): 0.5291 / 0.4700\n",
            "[2/200][29/391] Loss_D: 1.3952 Loss_G: 0.6357 D(x): 0.4700 D(G(z)): 0.4700 / 0.5310\n",
            "[2/200][30/391] Loss_D: 1.3954 Loss_G: 0.7620 D(x): 0.5310 D(G(z)): 0.5310 / 0.4679\n",
            "[2/200][31/391] Loss_D: 1.3957 Loss_G: 0.6313 D(x): 0.4679 D(G(z)): 0.4679 / 0.5333\n",
            "[2/200][32/391] Loss_D: 1.3960 Loss_G: 0.7677 D(x): 0.5333 D(G(z)): 0.5333 / 0.4653\n",
            "[2/200][33/391] Loss_D: 1.3963 Loss_G: 0.6258 D(x): 0.4653 D(G(z)): 0.4653 / 0.5362\n",
            "[2/200][34/391] Loss_D: 1.3968 Loss_G: 0.7748 D(x): 0.5362 D(G(z)): 0.5362 / 0.4620\n",
            "[2/200][35/391] Loss_D: 1.3972 Loss_G: 0.6187 D(x): 0.4620 D(G(z)): 0.4619 / 0.5400\n",
            "[2/200][36/391] Loss_D: 1.3979 Loss_G: 0.7841 D(x): 0.5401 D(G(z)): 0.5401 / 0.4577\n",
            "[2/200][37/391] Loss_D: 1.3986 Loss_G: 0.6100 D(x): 0.4577 D(G(z)): 0.4576 / 0.5448\n",
            "[2/200][38/391] Loss_D: 1.3995 Loss_G: 0.7952 D(x): 0.5448 D(G(z)): 0.5448 / 0.4526\n",
            "[2/200][39/391] Loss_D: 1.4004 Loss_G: 0.6001 D(x): 0.4526 D(G(z)): 0.4526 / 0.5502\n",
            "[2/200][40/391] Loss_D: 1.4015 Loss_G: 0.8080 D(x): 0.5502 D(G(z)): 0.5502 / 0.4469\n",
            "[2/200][41/391] Loss_D: 1.4027 Loss_G: 0.5891 D(x): 0.4468 D(G(z)): 0.4468 / 0.5563\n",
            "[2/200][42/391] Loss_D: 1.4042 Loss_G: 0.8223 D(x): 0.5563 D(G(z)): 0.5563 / 0.4405\n",
            "[2/200][43/391] Loss_D: 1.4056 Loss_G: 0.5776 D(x): 0.4405 D(G(z)): 0.4405 / 0.5627\n",
            "[2/200][44/391] Loss_D: 1.4072 Loss_G: 0.8369 D(x): 0.5627 D(G(z)): 0.5627 / 0.4342\n",
            "[2/200][45/391] Loss_D: 1.4088 Loss_G: 0.5665 D(x): 0.4341 D(G(z)): 0.4341 / 0.5689\n",
            "[2/200][46/391] Loss_D: 1.4106 Loss_G: 0.8506 D(x): 0.5690 D(G(z)): 0.5690 / 0.4282\n",
            "[2/200][47/391] Loss_D: 1.4121 Loss_G: 0.5563 D(x): 0.4282 D(G(z)): 0.4282 / 0.5748\n",
            "[2/200][48/391] Loss_D: 1.4141 Loss_G: 0.8654 D(x): 0.5748 D(G(z)): 0.5749 / 0.4219\n",
            "[2/200][49/391] Loss_D: 1.4160 Loss_G: 0.5453 D(x): 0.4219 D(G(z)): 0.4219 / 0.5811\n",
            "[2/200][50/391] Loss_D: 1.4181 Loss_G: 0.8822 D(x): 0.5812 D(G(z)): 0.5812 / 0.4149\n",
            "[2/200][51/391] Loss_D: 1.4207 Loss_G: 0.5304 D(x): 0.4149 D(G(z)): 0.4148 / 0.5898\n",
            "[2/200][52/391] Loss_D: 1.4243 Loss_G: 0.9049 D(x): 0.5899 D(G(z)): 0.5899 / 0.4056\n",
            "[2/200][53/391] Loss_D: 1.4276 Loss_G: 0.5164 D(x): 0.4056 D(G(z)): 0.4055 / 0.5982\n",
            "[2/200][54/391] Loss_D: 1.4308 Loss_G: 0.9258 D(x): 0.5982 D(G(z)): 0.5982 / 0.3973\n",
            "[2/200][55/391] Loss_D: 1.4346 Loss_G: 0.5017 D(x): 0.3972 D(G(z)): 0.3971 / 0.6071\n",
            "[2/200][56/391] Loss_D: 1.4386 Loss_G: 0.9429 D(x): 0.6071 D(G(z)): 0.6072 / 0.3905\n",
            "[2/200][57/391] Loss_D: 1.4407 Loss_G: 0.4975 D(x): 0.3905 D(G(z)): 0.3904 / 0.6097\n",
            "[2/200][58/391] Loss_D: 1.4411 Loss_G: 0.9395 D(x): 0.6097 D(G(z)): 0.6098 / 0.3919\n",
            "[2/200][59/391] Loss_D: 1.4396 Loss_G: 0.5060 D(x): 0.3918 D(G(z)): 0.3918 / 0.6045\n",
            "[2/200][60/391] Loss_D: 1.4365 Loss_G: 0.9186 D(x): 0.6045 D(G(z)): 0.6046 / 0.4002\n",
            "[2/200][61/391] Loss_D: 1.4325 Loss_G: 0.5244 D(x): 0.4002 D(G(z)): 0.4001 / 0.5935\n",
            "[2/200][62/391] Loss_D: 1.4275 Loss_G: 0.8865 D(x): 0.5936 D(G(z)): 0.5936 / 0.4133\n",
            "[2/200][63/391] Loss_D: 1.4224 Loss_G: 0.5486 D(x): 0.4132 D(G(z)): 0.4132 / 0.5794\n",
            "[2/200][64/391] Loss_D: 1.4175 Loss_G: 0.8540 D(x): 0.5794 D(G(z)): 0.5795 / 0.4269\n",
            "[2/200][65/391] Loss_D: 1.4135 Loss_G: 0.5693 D(x): 0.4269 D(G(z)): 0.4269 / 0.5675\n",
            "[2/200][66/391] Loss_D: 1.4103 Loss_G: 0.8289 D(x): 0.5675 D(G(z)): 0.5676 / 0.4377\n",
            "[2/200][67/391] Loss_D: 1.4075 Loss_G: 0.5866 D(x): 0.4377 D(G(z)): 0.4377 / 0.5578\n",
            "[2/200][68/391] Loss_D: 1.4053 Loss_G: 0.8089 D(x): 0.5578 D(G(z)): 0.5578 / 0.4466\n",
            "[2/200][69/391] Loss_D: 1.4033 Loss_G: 0.6018 D(x): 0.4466 D(G(z)): 0.4465 / 0.5493\n",
            "[2/200][70/391] Loss_D: 1.4016 Loss_G: 0.7911 D(x): 0.5493 D(G(z)): 0.5493 / 0.4546\n",
            "[2/200][71/391] Loss_D: 1.4000 Loss_G: 0.6153 D(x): 0.4546 D(G(z)): 0.4545 / 0.5419\n",
            "[2/200][72/391] Loss_D: 1.3988 Loss_G: 0.7769 D(x): 0.5420 D(G(z)): 0.5420 / 0.4610\n",
            "[2/200][73/391] Loss_D: 1.3977 Loss_G: 0.6257 D(x): 0.4610 D(G(z)): 0.4610 / 0.5363\n",
            "[2/200][74/391] Loss_D: 1.3969 Loss_G: 0.7662 D(x): 0.5363 D(G(z)): 0.5364 / 0.4660\n",
            "[2/200][75/391] Loss_D: 1.3962 Loss_G: 0.6338 D(x): 0.4660 D(G(z)): 0.4660 / 0.5319\n",
            "[2/200][76/391] Loss_D: 1.3957 Loss_G: 0.7579 D(x): 0.5320 D(G(z)): 0.5320 / 0.4699\n",
            "[2/200][77/391] Loss_D: 1.3951 Loss_G: 0.6403 D(x): 0.4699 D(G(z)): 0.4699 / 0.5285\n",
            "[2/200][78/391] Loss_D: 1.3948 Loss_G: 0.7515 D(x): 0.5285 D(G(z)): 0.5285 / 0.4729\n",
            "[2/200][79/391] Loss_D: 1.3944 Loss_G: 0.6452 D(x): 0.4729 D(G(z)): 0.4729 / 0.5259\n",
            "[2/200][80/391] Loss_D: 1.3941 Loss_G: 0.7466 D(x): 0.5259 D(G(z)): 0.5259 / 0.4752\n",
            "[2/200][81/391] Loss_D: 1.3938 Loss_G: 0.6490 D(x): 0.4752 D(G(z)): 0.4752 / 0.5239\n",
            "[2/200][82/391] Loss_D: 1.3937 Loss_G: 0.7430 D(x): 0.5239 D(G(z)): 0.5239 / 0.4769\n",
            "[2/200][83/391] Loss_D: 1.3934 Loss_G: 0.6516 D(x): 0.4769 D(G(z)): 0.4768 / 0.5225\n",
            "[2/200][84/391] Loss_D: 1.3933 Loss_G: 0.7405 D(x): 0.5225 D(G(z)): 0.5225 / 0.4780\n",
            "[2/200][85/391] Loss_D: 1.3932 Loss_G: 0.6535 D(x): 0.4780 D(G(z)): 0.4780 / 0.5215\n",
            "[2/200][86/391] Loss_D: 1.3931 Loss_G: 0.7389 D(x): 0.5215 D(G(z)): 0.5215 / 0.4788\n",
            "[2/200][87/391] Loss_D: 1.3930 Loss_G: 0.6545 D(x): 0.4788 D(G(z)): 0.4788 / 0.5210\n",
            "[2/200][88/391] Loss_D: 1.3929 Loss_G: 0.7381 D(x): 0.5210 D(G(z)): 0.5210 / 0.4792\n",
            "[2/200][89/391] Loss_D: 1.3929 Loss_G: 0.6549 D(x): 0.4792 D(G(z)): 0.4792 / 0.5208\n",
            "[2/200][90/391] Loss_D: 1.3928 Loss_G: 0.7380 D(x): 0.5208 D(G(z)): 0.5208 / 0.4792\n",
            "[2/200][91/391] Loss_D: 1.3928 Loss_G: 0.6545 D(x): 0.4792 D(G(z)): 0.4792 / 0.5209\n",
            "[2/200][92/391] Loss_D: 1.3928 Loss_G: 0.7388 D(x): 0.5209 D(G(z)): 0.5210 / 0.4788\n",
            "[2/200][93/391] Loss_D: 1.3928 Loss_G: 0.6534 D(x): 0.4788 D(G(z)): 0.4788 / 0.5215\n",
            "[2/200][94/391] Loss_D: 1.3928 Loss_G: 0.7402 D(x): 0.5215 D(G(z)): 0.5215 / 0.4781\n",
            "[2/200][95/391] Loss_D: 1.3929 Loss_G: 0.6517 D(x): 0.4781 D(G(z)): 0.4781 / 0.5224\n",
            "[2/200][96/391] Loss_D: 1.3930 Loss_G: 0.7425 D(x): 0.5224 D(G(z)): 0.5224 / 0.4770\n",
            "[2/200][97/391] Loss_D: 1.3930 Loss_G: 0.6492 D(x): 0.4770 D(G(z)): 0.4770 / 0.5237\n",
            "[2/200][98/391] Loss_D: 1.3932 Loss_G: 0.7456 D(x): 0.5237 D(G(z)): 0.5237 / 0.4755\n",
            "[2/200][99/391] Loss_D: 1.3932 Loss_G: 0.6458 D(x): 0.4755 D(G(z)): 0.4755 / 0.5254\n",
            "[2/200][100/391] Loss_D: 1.3934 Loss_G: 0.7498 D(x): 0.5254 D(G(z)): 0.5254 / 0.4736\n",
            "[2/200][101/391] Loss_D: 1.3936 Loss_G: 0.6416 D(x): 0.4735 D(G(z)): 0.4735 / 0.5276\n",
            "[2/200][102/391] Loss_D: 1.3939 Loss_G: 0.7550 D(x): 0.5276 D(G(z)): 0.5276 / 0.4711\n",
            "[2/200][103/391] Loss_D: 1.3941 Loss_G: 0.6364 D(x): 0.4711 D(G(z)): 0.4710 / 0.5304\n",
            "[2/200][104/391] Loss_D: 1.3945 Loss_G: 0.7615 D(x): 0.5304 D(G(z)): 0.5304 / 0.4680\n",
            "[2/200][105/391] Loss_D: 1.3949 Loss_G: 0.6299 D(x): 0.4680 D(G(z)): 0.4680 / 0.5338\n",
            "[2/200][106/391] Loss_D: 1.3954 Loss_G: 0.7697 D(x): 0.5339 D(G(z)): 0.5339 / 0.4642\n",
            "[2/200][107/391] Loss_D: 1.3959 Loss_G: 0.6221 D(x): 0.4641 D(G(z)): 0.4641 / 0.5380\n",
            "[2/200][108/391] Loss_D: 1.3965 Loss_G: 0.7795 D(x): 0.5380 D(G(z)): 0.5380 / 0.4597\n",
            "[2/200][109/391] Loss_D: 1.3972 Loss_G: 0.6131 D(x): 0.4596 D(G(z)): 0.4596 / 0.5429\n",
            "[2/200][110/391] Loss_D: 1.3981 Loss_G: 0.7909 D(x): 0.5429 D(G(z)): 0.5429 / 0.4544\n",
            "[2/200][111/391] Loss_D: 1.3990 Loss_G: 0.6028 D(x): 0.4544 D(G(z)): 0.4544 / 0.5485\n",
            "[2/200][112/391] Loss_D: 1.4001 Loss_G: 0.8039 D(x): 0.5485 D(G(z)): 0.5485 / 0.4486\n",
            "[2/200][113/391] Loss_D: 1.4013 Loss_G: 0.5918 D(x): 0.4485 D(G(z)): 0.4485 / 0.5546\n",
            "[2/200][114/391] Loss_D: 1.4027 Loss_G: 0.8180 D(x): 0.5546 D(G(z)): 0.5546 / 0.4423\n",
            "[2/200][115/391] Loss_D: 1.4041 Loss_G: 0.5804 D(x): 0.4423 D(G(z)): 0.4422 / 0.5609\n",
            "[2/200][116/391] Loss_D: 1.4056 Loss_G: 0.8324 D(x): 0.5609 D(G(z)): 0.5609 / 0.4360\n",
            "[2/200][117/391] Loss_D: 1.4072 Loss_G: 0.5697 D(x): 0.4359 D(G(z)): 0.4359 / 0.5670\n",
            "[2/200][118/391] Loss_D: 1.4088 Loss_G: 0.8448 D(x): 0.5670 D(G(z)): 0.5670 / 0.4306\n",
            "[2/200][119/391] Loss_D: 1.4101 Loss_G: 0.5621 D(x): 0.4306 D(G(z)): 0.4305 / 0.5713\n",
            "[2/200][120/391] Loss_D: 1.4112 Loss_G: 0.8520 D(x): 0.5713 D(G(z)): 0.5713 / 0.4275\n",
            "[2/200][121/391] Loss_D: 1.4119 Loss_G: 0.5572 D(x): 0.4275 D(G(z)): 0.4274 / 0.5741\n",
            "[2/200][122/391] Loss_D: 1.4129 Loss_G: 0.8602 D(x): 0.5741 D(G(z)): 0.5741 / 0.4240\n",
            "[2/200][123/391] Loss_D: 1.4141 Loss_G: 0.5511 D(x): 0.4240 D(G(z)): 0.4239 / 0.5776\n",
            "[2/200][124/391] Loss_D: 1.4152 Loss_G: 0.8678 D(x): 0.5776 D(G(z)): 0.5776 / 0.4208\n",
            "[2/200][125/391] Loss_D: 1.4161 Loss_G: 0.5459 D(x): 0.4208 D(G(z)): 0.4207 / 0.5806\n",
            "[2/200][126/391] Loss_D: 1.4171 Loss_G: 0.8731 D(x): 0.5806 D(G(z)): 0.5807 / 0.4186\n",
            "[2/200][127/391] Loss_D: 1.4176 Loss_G: 0.5443 D(x): 0.4186 D(G(z)): 0.4185 / 0.5815\n",
            "[2/200][128/391] Loss_D: 1.4178 Loss_G: 0.8725 D(x): 0.5816 D(G(z)): 0.5816 / 0.4188\n",
            "[2/200][129/391] Loss_D: 1.4175 Loss_G: 0.5469 D(x): 0.4188 D(G(z)): 0.4188 / 0.5801\n",
            "[2/200][130/391] Loss_D: 1.4168 Loss_G: 0.8700 D(x): 0.5801 D(G(z)): 0.5801 / 0.4199\n",
            "[2/200][131/391] Loss_D: 1.4168 Loss_G: 0.5463 D(x): 0.4199 D(G(z)): 0.4198 / 0.5804\n",
            "[2/200][132/391] Loss_D: 1.4170 Loss_G: 0.8698 D(x): 0.5804 D(G(z)): 0.5804 / 0.4200\n",
            "[2/200][133/391] Loss_D: 1.4167 Loss_G: 0.5487 D(x): 0.4199 D(G(z)): 0.4199 / 0.5790\n",
            "[2/200][134/391] Loss_D: 1.4161 Loss_G: 0.8638 D(x): 0.5790 D(G(z)): 0.5790 / 0.4225\n",
            "[2/200][135/391] Loss_D: 1.4151 Loss_G: 0.5546 D(x): 0.4225 D(G(z)): 0.4224 / 0.5756\n",
            "[2/200][136/391] Loss_D: 1.4140 Loss_G: 0.8537 D(x): 0.5756 D(G(z)): 0.5756 / 0.4268\n",
            "[2/200][137/391] Loss_D: 1.4124 Loss_G: 0.5630 D(x): 0.4268 D(G(z)): 0.4267 / 0.5707\n",
            "[2/200][138/391] Loss_D: 1.4111 Loss_G: 0.8418 D(x): 0.5708 D(G(z)): 0.5708 / 0.4319\n",
            "[2/200][139/391] Loss_D: 1.4095 Loss_G: 0.5725 D(x): 0.4319 D(G(z)): 0.4318 / 0.5653\n",
            "[2/200][140/391] Loss_D: 1.4080 Loss_G: 0.8290 D(x): 0.5654 D(G(z)): 0.5654 / 0.4375\n",
            "[2/200][141/391] Loss_D: 1.4065 Loss_G: 0.5826 D(x): 0.4374 D(G(z)): 0.4374 / 0.5597\n",
            "[2/200][142/391] Loss_D: 1.4051 Loss_G: 0.8161 D(x): 0.5597 D(G(z)): 0.5597 / 0.4431\n",
            "[2/200][143/391] Loss_D: 1.4037 Loss_G: 0.5926 D(x): 0.4431 D(G(z)): 0.4431 / 0.5541\n",
            "[2/200][144/391] Loss_D: 1.4025 Loss_G: 0.8111 D(x): 0.5541 D(G(z)): 0.5541 / 0.4453\n",
            "[2/200][145/391] Loss_D: 1.4027 Loss_G: 0.5920 D(x): 0.4453 D(G(z)): 0.4453 / 0.5545\n",
            "[2/200][146/391] Loss_D: 1.4027 Loss_G: 0.8106 D(x): 0.5545 D(G(z)): 0.5545 / 0.4456\n",
            "[2/200][147/391] Loss_D: 1.4026 Loss_G: 0.5924 D(x): 0.4456 D(G(z)): 0.4455 / 0.5542\n",
            "[2/200][148/391] Loss_D: 1.4026 Loss_G: 0.8096 D(x): 0.5542 D(G(z)): 0.5543 / 0.4460\n",
            "[2/200][149/391] Loss_D: 1.4024 Loss_G: 0.5933 D(x): 0.4460 D(G(z)): 0.4460 / 0.5537\n",
            "[2/200][150/391] Loss_D: 1.4023 Loss_G: 0.8087 D(x): 0.5538 D(G(z)): 0.5538 / 0.4464\n",
            "[2/200][151/391] Loss_D: 1.4022 Loss_G: 0.5941 D(x): 0.4464 D(G(z)): 0.4464 / 0.5533\n",
            "[2/200][152/391] Loss_D: 1.4021 Loss_G: 0.8073 D(x): 0.5533 D(G(z)): 0.5533 / 0.4470\n",
            "[2/200][153/391] Loss_D: 1.4019 Loss_G: 0.5953 D(x): 0.4470 D(G(z)): 0.4470 / 0.5526\n",
            "[2/200][154/391] Loss_D: 1.4018 Loss_G: 0.8053 D(x): 0.5526 D(G(z)): 0.5526 / 0.4479\n",
            "[2/200][155/391] Loss_D: 1.4015 Loss_G: 0.5971 D(x): 0.4479 D(G(z)): 0.4479 / 0.5516\n",
            "[2/200][156/391] Loss_D: 1.4013 Loss_G: 0.8031 D(x): 0.5516 D(G(z)): 0.5516 / 0.4489\n",
            "[2/200][157/391] Loss_D: 1.4010 Loss_G: 0.5988 D(x): 0.4489 D(G(z)): 0.4489 / 0.5506\n",
            "[2/200][158/391] Loss_D: 1.4009 Loss_G: 0.8010 D(x): 0.5506 D(G(z)): 0.5507 / 0.4498\n",
            "[2/200][159/391] Loss_D: 1.4006 Loss_G: 0.6005 D(x): 0.4498 D(G(z)): 0.4498 / 0.5497\n",
            "[2/200][160/391] Loss_D: 1.4005 Loss_G: 0.7991 D(x): 0.5497 D(G(z)): 0.5498 / 0.4507\n",
            "[2/200][161/391] Loss_D: 1.4003 Loss_G: 0.6020 D(x): 0.4507 D(G(z)): 0.4507 / 0.5489\n",
            "[2/200][162/391] Loss_D: 1.4001 Loss_G: 0.7972 D(x): 0.5489 D(G(z)): 0.5489 / 0.4515\n",
            "[2/200][163/391] Loss_D: 1.3999 Loss_G: 0.6034 D(x): 0.4515 D(G(z)): 0.4515 / 0.5481\n",
            "[2/200][164/391] Loss_D: 1.3997 Loss_G: 0.7954 D(x): 0.5481 D(G(z)): 0.5481 / 0.4523\n",
            "[2/200][165/391] Loss_D: 1.3995 Loss_G: 0.6047 D(x): 0.4523 D(G(z)): 0.4523 / 0.5473\n",
            "[2/200][166/391] Loss_D: 1.3994 Loss_G: 0.7939 D(x): 0.5474 D(G(z)): 0.5474 / 0.4530\n",
            "[2/200][167/391] Loss_D: 1.3992 Loss_G: 0.6059 D(x): 0.4530 D(G(z)): 0.4530 / 0.5467\n",
            "[2/200][168/391] Loss_D: 1.3992 Loss_G: 0.7926 D(x): 0.5467 D(G(z)): 0.5467 / 0.4536\n",
            "[2/200][169/391] Loss_D: 1.3990 Loss_G: 0.6069 D(x): 0.4536 D(G(z)): 0.4536 / 0.5462\n",
            "[2/200][170/391] Loss_D: 1.3989 Loss_G: 0.7913 D(x): 0.5462 D(G(z)): 0.5462 / 0.4542\n",
            "[2/200][171/391] Loss_D: 1.3988 Loss_G: 0.6081 D(x): 0.4541 D(G(z)): 0.4541 / 0.5455\n",
            "[2/200][172/391] Loss_D: 1.3986 Loss_G: 0.7896 D(x): 0.5455 D(G(z)): 0.5455 / 0.4549\n",
            "[2/200][173/391] Loss_D: 1.3984 Loss_G: 0.6095 D(x): 0.4549 D(G(z)): 0.4549 / 0.5447\n",
            "[2/200][174/391] Loss_D: 1.3983 Loss_G: 0.7880 D(x): 0.5447 D(G(z)): 0.5447 / 0.4557\n",
            "[2/200][175/391] Loss_D: 1.3981 Loss_G: 0.6107 D(x): 0.4557 D(G(z)): 0.4556 / 0.5440\n",
            "[2/200][176/391] Loss_D: 1.3981 Loss_G: 0.7868 D(x): 0.5440 D(G(z)): 0.5441 / 0.4562\n",
            "[2/200][177/391] Loss_D: 1.3979 Loss_G: 0.6107 D(x): 0.4562 D(G(z)): 0.4562 / 0.5440\n",
            "[2/200][178/391] Loss_D: 1.3980 Loss_G: 0.7884 D(x): 0.5441 D(G(z)): 0.5441 / 0.4554\n",
            "[2/200][179/391] Loss_D: 1.3982 Loss_G: 0.6086 D(x): 0.4554 D(G(z)): 0.4554 / 0.5452\n",
            "[2/200][180/391] Loss_D: 1.3984 Loss_G: 0.7913 D(x): 0.5452 D(G(z)): 0.5452 / 0.4541\n",
            "[2/200][181/391] Loss_D: 1.3986 Loss_G: 0.6060 D(x): 0.4541 D(G(z)): 0.4541 / 0.5466\n",
            "[2/200][182/391] Loss_D: 1.3989 Loss_G: 0.7945 D(x): 0.5466 D(G(z)): 0.5466 / 0.4527\n",
            "[2/200][183/391] Loss_D: 1.3991 Loss_G: 0.6033 D(x): 0.4527 D(G(z)): 0.4527 / 0.5480\n",
            "[2/200][184/391] Loss_D: 1.3994 Loss_G: 0.7981 D(x): 0.5480 D(G(z)): 0.5481 / 0.4511\n",
            "[2/200][185/391] Loss_D: 1.3997 Loss_G: 0.6002 D(x): 0.4510 D(G(z)): 0.4510 / 0.5497\n",
            "[2/200][186/391] Loss_D: 1.4001 Loss_G: 0.8016 D(x): 0.5497 D(G(z)): 0.5497 / 0.4495\n",
            "[2/200][187/391] Loss_D: 1.4004 Loss_G: 0.5973 D(x): 0.4495 D(G(z)): 0.4494 / 0.5513\n",
            "[2/200][188/391] Loss_D: 1.4007 Loss_G: 0.8052 D(x): 0.5514 D(G(z)): 0.5514 / 0.4478\n",
            "[2/200][189/391] Loss_D: 1.4010 Loss_G: 0.5943 D(x): 0.4478 D(G(z)): 0.4478 / 0.5530\n",
            "[2/200][190/391] Loss_D: 1.4014 Loss_G: 0.8087 D(x): 0.5530 D(G(z)): 0.5530 / 0.4463\n",
            "[2/200][191/391] Loss_D: 1.4017 Loss_G: 0.5916 D(x): 0.4463 D(G(z)): 0.4462 / 0.5545\n",
            "[2/200][192/391] Loss_D: 1.4020 Loss_G: 0.8121 D(x): 0.5545 D(G(z)): 0.5545 / 0.4447\n",
            "[2/200][193/391] Loss_D: 1.4023 Loss_G: 0.5890 D(x): 0.4447 D(G(z)): 0.4447 / 0.5559\n",
            "[2/200][194/391] Loss_D: 1.4027 Loss_G: 0.8144 D(x): 0.5559 D(G(z)): 0.5559 / 0.4438\n",
            "[2/200][195/391] Loss_D: 1.4028 Loss_G: 0.5880 D(x): 0.4437 D(G(z)): 0.4437 / 0.5565\n",
            "[2/200][196/391] Loss_D: 1.4029 Loss_G: 0.8151 D(x): 0.5565 D(G(z)): 0.5565 / 0.4434\n",
            "[2/200][197/391] Loss_D: 1.4029 Loss_G: 0.5878 D(x): 0.4434 D(G(z)): 0.4434 / 0.5566\n",
            "[2/200][198/391] Loss_D: 1.4030 Loss_G: 0.8148 D(x): 0.5566 D(G(z)): 0.5566 / 0.4436\n",
            "[2/200][199/391] Loss_D: 1.4028 Loss_G: 0.5885 D(x): 0.4435 D(G(z)): 0.4435 / 0.5562\n",
            "[2/200][200/391] Loss_D: 1.4028 Loss_G: 0.8134 D(x): 0.5562 D(G(z)): 0.5562 / 0.4442\n",
            "[2/200][201/391] Loss_D: 1.4025 Loss_G: 0.5899 D(x): 0.4441 D(G(z)): 0.4441 / 0.5554\n",
            "[2/200][202/391] Loss_D: 1.4024 Loss_G: 0.8128 D(x): 0.5554 D(G(z)): 0.5554 / 0.4444\n",
            "[2/200][203/391] Loss_D: 1.4024 Loss_G: 0.5902 D(x): 0.4444 D(G(z)): 0.4444 / 0.5552\n",
            "[2/200][204/391] Loss_D: 1.4023 Loss_G: 0.8122 D(x): 0.5552 D(G(z)): 0.5553 / 0.4447\n",
            "[2/200][205/391] Loss_D: 1.4023 Loss_G: 0.5902 D(x): 0.4447 D(G(z)): 0.4447 / 0.5552\n",
            "[2/200][206/391] Loss_D: 1.4024 Loss_G: 0.8121 D(x): 0.5553 D(G(z)): 0.5553 / 0.4447\n",
            "[2/200][207/391] Loss_D: 1.4023 Loss_G: 0.5902 D(x): 0.4447 D(G(z)): 0.4447 / 0.5552\n",
            "[2/200][208/391] Loss_D: 1.4023 Loss_G: 0.8120 D(x): 0.5553 D(G(z)): 0.5553 / 0.4448\n",
            "[2/200][209/391] Loss_D: 1.4022 Loss_G: 0.5905 D(x): 0.4448 D(G(z)): 0.4448 / 0.5551\n",
            "[2/200][210/391] Loss_D: 1.4022 Loss_G: 0.8113 D(x): 0.5551 D(G(z)): 0.5551 / 0.4451\n",
            "[2/200][211/391] Loss_D: 1.4021 Loss_G: 0.5912 D(x): 0.4451 D(G(z)): 0.4451 / 0.5547\n",
            "[2/200][212/391] Loss_D: 1.4020 Loss_G: 0.8106 D(x): 0.5547 D(G(z)): 0.5547 / 0.4454\n",
            "[2/200][213/391] Loss_D: 1.4019 Loss_G: 0.5911 D(x): 0.4454 D(G(z)): 0.4454 / 0.5547\n",
            "[2/200][214/391] Loss_D: 1.4020 Loss_G: 0.8113 D(x): 0.5548 D(G(z)): 0.5548 / 0.4451\n",
            "[2/200][215/391] Loss_D: 1.4021 Loss_G: 0.5905 D(x): 0.4451 D(G(z)): 0.4451 / 0.5551\n",
            "[2/200][216/391] Loss_D: 1.4022 Loss_G: 0.8120 D(x): 0.5551 D(G(z)): 0.5551 / 0.4448\n",
            "[2/200][217/391] Loss_D: 1.4022 Loss_G: 0.5901 D(x): 0.4448 D(G(z)): 0.4448 / 0.5553\n",
            "[2/200][218/391] Loss_D: 1.4023 Loss_G: 0.8123 D(x): 0.5553 D(G(z)): 0.5553 / 0.4447\n",
            "[2/200][219/391] Loss_D: 1.4022 Loss_G: 0.5900 D(x): 0.4446 D(G(z)): 0.4446 / 0.5553\n",
            "[2/200][220/391] Loss_D: 1.4022 Loss_G: 0.8121 D(x): 0.5553 D(G(z)): 0.5553 / 0.4447\n",
            "[2/200][221/391] Loss_D: 1.4022 Loss_G: 0.5903 D(x): 0.4447 D(G(z)): 0.4447 / 0.5551\n",
            "[2/200][222/391] Loss_D: 1.4022 Loss_G: 0.8114 D(x): 0.5552 D(G(z)): 0.5552 / 0.4450\n",
            "[2/200][223/391] Loss_D: 1.4020 Loss_G: 0.5911 D(x): 0.4450 D(G(z)): 0.4450 / 0.5547\n",
            "[2/200][224/391] Loss_D: 1.4019 Loss_G: 0.8101 D(x): 0.5547 D(G(z)): 0.5547 / 0.4456\n",
            "[2/200][225/391] Loss_D: 1.4017 Loss_G: 0.5925 D(x): 0.4456 D(G(z)): 0.4456 / 0.5539\n",
            "[2/200][226/391] Loss_D: 1.4016 Loss_G: 0.8077 D(x): 0.5539 D(G(z)): 0.5540 / 0.4467\n",
            "[2/200][227/391] Loss_D: 1.4013 Loss_G: 0.5947 D(x): 0.4467 D(G(z)): 0.4466 / 0.5527\n",
            "[2/200][228/391] Loss_D: 1.4010 Loss_G: 0.8048 D(x): 0.5527 D(G(z)): 0.5527 / 0.4480\n",
            "[2/200][229/391] Loss_D: 1.4007 Loss_G: 0.5972 D(x): 0.4480 D(G(z)): 0.4479 / 0.5513\n",
            "[2/200][230/391] Loss_D: 1.4004 Loss_G: 0.8014 D(x): 0.5513 D(G(z)): 0.5513 / 0.4495\n",
            "[2/200][231/391] Loss_D: 1.4000 Loss_G: 0.6001 D(x): 0.4495 D(G(z)): 0.4495 / 0.5497\n",
            "[2/200][232/391] Loss_D: 1.3997 Loss_G: 0.7979 D(x): 0.5497 D(G(z)): 0.5497 / 0.4511\n",
            "[2/200][233/391] Loss_D: 1.3994 Loss_G: 0.6020 D(x): 0.4511 D(G(z)): 0.4510 / 0.5487\n",
            "[2/200][234/391] Loss_D: 1.3993 Loss_G: 0.7973 D(x): 0.5487 D(G(z)): 0.5487 / 0.4513\n",
            "[2/200][235/391] Loss_D: 1.3993 Loss_G: 0.6017 D(x): 0.4513 D(G(z)): 0.4513 / 0.5488\n",
            "[2/200][236/391] Loss_D: 1.3994 Loss_G: 0.7981 D(x): 0.5489 D(G(z)): 0.5489 / 0.4509\n",
            "[2/200][237/391] Loss_D: 1.3994 Loss_G: 0.6009 D(x): 0.4509 D(G(z)): 0.4509 / 0.5493\n",
            "[2/200][238/391] Loss_D: 1.3995 Loss_G: 0.7995 D(x): 0.5493 D(G(z)): 0.5493 / 0.4503\n",
            "[2/200][239/391] Loss_D: 1.3996 Loss_G: 0.5993 D(x): 0.4503 D(G(z)): 0.4503 / 0.5501\n",
            "[2/200][240/391] Loss_D: 1.3999 Loss_G: 0.8019 D(x): 0.5501 D(G(z)): 0.5502 / 0.4493\n",
            "[2/200][241/391] Loss_D: 1.4000 Loss_G: 0.5972 D(x): 0.4492 D(G(z)): 0.4492 / 0.5513\n",
            "[2/200][242/391] Loss_D: 1.4003 Loss_G: 0.8041 D(x): 0.5513 D(G(z)): 0.5513 / 0.4483\n",
            "[2/200][243/391] Loss_D: 1.4004 Loss_G: 0.5956 D(x): 0.4482 D(G(z)): 0.4482 / 0.5521\n",
            "[2/200][244/391] Loss_D: 1.4006 Loss_G: 0.8057 D(x): 0.5522 D(G(z)): 0.5522 / 0.4475\n",
            "[2/200][245/391] Loss_D: 1.4007 Loss_G: 0.5943 D(x): 0.4475 D(G(z)): 0.4475 / 0.5529\n",
            "[2/200][246/391] Loss_D: 1.4009 Loss_G: 0.8074 D(x): 0.5529 D(G(z)): 0.5529 / 0.4468\n",
            "[2/200][247/391] Loss_D: 1.4010 Loss_G: 0.5932 D(x): 0.4467 D(G(z)): 0.4467 / 0.5535\n",
            "[2/200][248/391] Loss_D: 1.4012 Loss_G: 0.8087 D(x): 0.5535 D(G(z)): 0.5535 / 0.4462\n",
            "[2/200][249/391] Loss_D: 1.4013 Loss_G: 0.5923 D(x): 0.4462 D(G(z)): 0.4462 / 0.5540\n",
            "[2/200][250/391] Loss_D: 1.4014 Loss_G: 0.8092 D(x): 0.5540 D(G(z)): 0.5540 / 0.4459\n",
            "[2/200][251/391] Loss_D: 1.4014 Loss_G: 0.5919 D(x): 0.4459 D(G(z)): 0.4459 / 0.5542\n",
            "[2/200][252/391] Loss_D: 1.4015 Loss_G: 0.8100 D(x): 0.5542 D(G(z)): 0.5543 / 0.4456\n",
            "[2/200][253/391] Loss_D: 1.4015 Loss_G: 0.5914 D(x): 0.4456 D(G(z)): 0.4456 / 0.5545\n",
            "[2/200][254/391] Loss_D: 1.4016 Loss_G: 0.8101 D(x): 0.5545 D(G(z)): 0.5545 / 0.4456\n",
            "[2/200][255/391] Loss_D: 1.4015 Loss_G: 0.5917 D(x): 0.4456 D(G(z)): 0.4455 / 0.5543\n",
            "[2/200][256/391] Loss_D: 1.4015 Loss_G: 0.8094 D(x): 0.5543 D(G(z)): 0.5543 / 0.4459\n",
            "[2/200][257/391] Loss_D: 1.4014 Loss_G: 0.5924 D(x): 0.4459 D(G(z)): 0.4458 / 0.5539\n",
            "[2/200][258/391] Loss_D: 1.4013 Loss_G: 0.8090 D(x): 0.5539 D(G(z)): 0.5540 / 0.4461\n",
            "[2/200][259/391] Loss_D: 1.4013 Loss_G: 0.5926 D(x): 0.4460 D(G(z)): 0.4460 / 0.5538\n",
            "[2/200][260/391] Loss_D: 1.4012 Loss_G: 0.8084 D(x): 0.5538 D(G(z)): 0.5538 / 0.4463\n",
            "[2/200][261/391] Loss_D: 1.4011 Loss_G: 0.5930 D(x): 0.4463 D(G(z)): 0.4463 / 0.5536\n",
            "[2/200][262/391] Loss_D: 1.4011 Loss_G: 0.8079 D(x): 0.5536 D(G(z)): 0.5536 / 0.4465\n",
            "[2/200][263/391] Loss_D: 1.4010 Loss_G: 0.5934 D(x): 0.4465 D(G(z)): 0.4465 / 0.5533\n",
            "[2/200][264/391] Loss_D: 1.4010 Loss_G: 0.8074 D(x): 0.5533 D(G(z)): 0.5533 / 0.4467\n",
            "[2/200][265/391] Loss_D: 1.4009 Loss_G: 0.5936 D(x): 0.4467 D(G(z)): 0.4467 / 0.5532\n",
            "[2/200][266/391] Loss_D: 1.4009 Loss_G: 0.8071 D(x): 0.5532 D(G(z)): 0.5532 / 0.4469\n",
            "[2/200][267/391] Loss_D: 1.4009 Loss_G: 0.5939 D(x): 0.4468 D(G(z)): 0.4468 / 0.5530\n",
            "[2/200][268/391] Loss_D: 1.4008 Loss_G: 0.8066 D(x): 0.5531 D(G(z)): 0.5531 / 0.4471\n",
            "[2/200][269/391] Loss_D: 1.4008 Loss_G: 0.5943 D(x): 0.4471 D(G(z)): 0.4470 / 0.5528\n",
            "[2/200][270/391] Loss_D: 1.4008 Loss_G: 0.8063 D(x): 0.5529 D(G(z)): 0.5529 / 0.4472\n",
            "[2/200][271/391] Loss_D: 1.4007 Loss_G: 0.5946 D(x): 0.4472 D(G(z)): 0.4472 / 0.5526\n",
            "[2/200][272/391] Loss_D: 1.4006 Loss_G: 0.8054 D(x): 0.5526 D(G(z)): 0.5527 / 0.4476\n",
            "[2/200][273/391] Loss_D: 1.4005 Loss_G: 0.5952 D(x): 0.4476 D(G(z)): 0.4476 / 0.5523\n",
            "[2/200][274/391] Loss_D: 1.4005 Loss_G: 0.8056 D(x): 0.5523 D(G(z)): 0.5524 / 0.4475\n",
            "[2/200][275/391] Loss_D: 1.4005 Loss_G: 0.5948 D(x): 0.4475 D(G(z)): 0.4475 / 0.5526\n",
            "[2/200][276/391] Loss_D: 1.4006 Loss_G: 0.8063 D(x): 0.5526 D(G(z)): 0.5526 / 0.4472\n",
            "[2/200][277/391] Loss_D: 1.4006 Loss_G: 0.5937 D(x): 0.4472 D(G(z)): 0.4472 / 0.5531\n",
            "[2/200][278/391] Loss_D: 1.4008 Loss_G: 0.8079 D(x): 0.5532 D(G(z)): 0.5532 / 0.4465\n",
            "[2/200][279/391] Loss_D: 1.4009 Loss_G: 0.5923 D(x): 0.4465 D(G(z)): 0.4464 / 0.5539\n",
            "[2/200][280/391] Loss_D: 1.4012 Loss_G: 0.8102 D(x): 0.5540 D(G(z)): 0.5540 / 0.4455\n",
            "[2/200][281/391] Loss_D: 1.4014 Loss_G: 0.5897 D(x): 0.4455 D(G(z)): 0.4454 / 0.5554\n",
            "[2/200][282/391] Loss_D: 1.4018 Loss_G: 0.8144 D(x): 0.5554 D(G(z)): 0.5554 / 0.4436\n",
            "[2/200][283/391] Loss_D: 1.4022 Loss_G: 0.5859 D(x): 0.4436 D(G(z)): 0.4435 / 0.5575\n",
            "[2/200][284/391] Loss_D: 1.4028 Loss_G: 0.8191 D(x): 0.5575 D(G(z)): 0.5575 / 0.4415\n",
            "[2/200][285/391] Loss_D: 1.4032 Loss_G: 0.5829 D(x): 0.4415 D(G(z)): 0.4415 / 0.5592\n",
            "[2/200][286/391] Loss_D: 1.4036 Loss_G: 0.8217 D(x): 0.5592 D(G(z)): 0.5592 / 0.4404\n",
            "[2/200][287/391] Loss_D: 1.4037 Loss_G: 0.5815 D(x): 0.4404 D(G(z)): 0.4403 / 0.5599\n",
            "[2/200][288/391] Loss_D: 1.4039 Loss_G: 0.8224 D(x): 0.5599 D(G(z)): 0.5599 / 0.4401\n",
            "[2/200][289/391] Loss_D: 1.4039 Loss_G: 0.5800 D(x): 0.4401 D(G(z)): 0.4400 / 0.5608\n",
            "[2/200][290/391] Loss_D: 1.4044 Loss_G: 0.8257 D(x): 0.5608 D(G(z)): 0.5608 / 0.4386\n",
            "[2/200][291/391] Loss_D: 1.4046 Loss_G: 0.5777 D(x): 0.4386 D(G(z)): 0.4386 / 0.5621\n",
            "[2/200][292/391] Loss_D: 1.4050 Loss_G: 0.8286 D(x): 0.5621 D(G(z)): 0.5621 / 0.4373\n",
            "[2/200][293/391] Loss_D: 1.4052 Loss_G: 0.5762 D(x): 0.4373 D(G(z)): 0.4373 / 0.5629\n",
            "[2/200][294/391] Loss_D: 1.4054 Loss_G: 0.8296 D(x): 0.5629 D(G(z)): 0.5630 / 0.4369\n",
            "[2/200][295/391] Loss_D: 1.4055 Loss_G: 0.5759 D(x): 0.4369 D(G(z)): 0.4369 / 0.5631\n",
            "[2/200][296/391] Loss_D: 1.4055 Loss_G: 0.8291 D(x): 0.5631 D(G(z)): 0.5631 / 0.4371\n",
            "[2/200][297/391] Loss_D: 1.4053 Loss_G: 0.5773 D(x): 0.4371 D(G(z)): 0.4371 / 0.5623\n",
            "[2/200][298/391] Loss_D: 1.4051 Loss_G: 0.8259 D(x): 0.5623 D(G(z)): 0.5624 / 0.4385\n",
            "[2/200][299/391] Loss_D: 1.4046 Loss_G: 0.5808 D(x): 0.4385 D(G(z)): 0.4385 / 0.5603\n",
            "[2/200][300/391] Loss_D: 1.4041 Loss_G: 0.8201 D(x): 0.5603 D(G(z)): 0.5603 / 0.4411\n",
            "[2/200][301/391] Loss_D: 1.4034 Loss_G: 0.5858 D(x): 0.4410 D(G(z)): 0.4410 / 0.5575\n",
            "[2/200][302/391] Loss_D: 1.4028 Loss_G: 0.8138 D(x): 0.5576 D(G(z)): 0.5576 / 0.4438\n",
            "[2/200][303/391] Loss_D: 1.4021 Loss_G: 0.5908 D(x): 0.4438 D(G(z)): 0.4438 / 0.5547\n",
            "[2/200][304/391] Loss_D: 1.4015 Loss_G: 0.8074 D(x): 0.5547 D(G(z)): 0.5547 / 0.4467\n",
            "[2/200][305/391] Loss_D: 1.4008 Loss_G: 0.5960 D(x): 0.4467 D(G(z)): 0.4467 / 0.5518\n",
            "[2/200][306/391] Loss_D: 1.4002 Loss_G: 0.8009 D(x): 0.5518 D(G(z)): 0.5519 / 0.4496\n",
            "[2/200][307/391] Loss_D: 1.3996 Loss_G: 0.6012 D(x): 0.4496 D(G(z)): 0.4496 / 0.5490\n",
            "[2/200][308/391] Loss_D: 1.3990 Loss_G: 0.7947 D(x): 0.5490 D(G(z)): 0.5490 / 0.4524\n",
            "[2/200][309/391] Loss_D: 1.3984 Loss_G: 0.6062 D(x): 0.4524 D(G(z)): 0.4524 / 0.5463\n",
            "[2/200][310/391] Loss_D: 1.3979 Loss_G: 0.7890 D(x): 0.5463 D(G(z)): 0.5463 / 0.4550\n",
            "[2/200][311/391] Loss_D: 1.3974 Loss_G: 0.6106 D(x): 0.4550 D(G(z)): 0.4550 / 0.5438\n",
            "[2/200][312/391] Loss_D: 1.3970 Loss_G: 0.7845 D(x): 0.5439 D(G(z)): 0.5439 / 0.4570\n",
            "[2/200][313/391] Loss_D: 1.3967 Loss_G: 0.6136 D(x): 0.4570 D(G(z)): 0.4570 / 0.5422\n",
            "[2/200][314/391] Loss_D: 1.3965 Loss_G: 0.7815 D(x): 0.5422 D(G(z)): 0.5422 / 0.4584\n",
            "[2/200][315/391] Loss_D: 1.3962 Loss_G: 0.6158 D(x): 0.4584 D(G(z)): 0.4584 / 0.5410\n",
            "[2/200][316/391] Loss_D: 1.3960 Loss_G: 0.7793 D(x): 0.5410 D(G(z)): 0.5410 / 0.4594\n",
            "[2/200][317/391] Loss_D: 1.3958 Loss_G: 0.6170 D(x): 0.4594 D(G(z)): 0.4594 / 0.5404\n",
            "[2/200][318/391] Loss_D: 1.3958 Loss_G: 0.7783 D(x): 0.5404 D(G(z)): 0.5404 / 0.4598\n",
            "[2/200][319/391] Loss_D: 1.3957 Loss_G: 0.6176 D(x): 0.4598 D(G(z)): 0.4598 / 0.5400\n",
            "[2/200][320/391] Loss_D: 1.3957 Loss_G: 0.7779 D(x): 0.5401 D(G(z)): 0.5401 / 0.4600\n",
            "[2/200][321/391] Loss_D: 1.3956 Loss_G: 0.6178 D(x): 0.4600 D(G(z)): 0.4600 / 0.5399\n",
            "[2/200][322/391] Loss_D: 1.3956 Loss_G: 0.7778 D(x): 0.5399 D(G(z)): 0.5399 / 0.4601\n",
            "[2/200][323/391] Loss_D: 1.3956 Loss_G: 0.6178 D(x): 0.4601 D(G(z)): 0.4601 / 0.5399\n",
            "[2/200][324/391] Loss_D: 1.3956 Loss_G: 0.7779 D(x): 0.5399 D(G(z)): 0.5400 / 0.4600\n",
            "[2/200][325/391] Loss_D: 1.3956 Loss_G: 0.6175 D(x): 0.4600 D(G(z)): 0.4600 / 0.5400\n",
            "[2/200][326/391] Loss_D: 1.3956 Loss_G: 0.7783 D(x): 0.5401 D(G(z)): 0.5401 / 0.4598\n",
            "[2/200][327/391] Loss_D: 1.3956 Loss_G: 0.6170 D(x): 0.4598 D(G(z)): 0.4598 / 0.5403\n",
            "[2/200][328/391] Loss_D: 1.3957 Loss_G: 0.7792 D(x): 0.5404 D(G(z)): 0.5404 / 0.4594\n",
            "[2/200][329/391] Loss_D: 1.3958 Loss_G: 0.6161 D(x): 0.4594 D(G(z)): 0.4594 / 0.5408\n",
            "[2/200][330/391] Loss_D: 1.3959 Loss_G: 0.7804 D(x): 0.5408 D(G(z)): 0.5408 / 0.4589\n",
            "[2/200][331/391] Loss_D: 1.3959 Loss_G: 0.6149 D(x): 0.4589 D(G(z)): 0.4589 / 0.5415\n",
            "[2/200][332/391] Loss_D: 1.3961 Loss_G: 0.7820 D(x): 0.5415 D(G(z)): 0.5415 / 0.4581\n",
            "[2/200][333/391] Loss_D: 1.3961 Loss_G: 0.6134 D(x): 0.4581 D(G(z)): 0.4581 / 0.5423\n",
            "[2/200][334/391] Loss_D: 1.3963 Loss_G: 0.7840 D(x): 0.5423 D(G(z)): 0.5423 / 0.4572\n",
            "[2/200][335/391] Loss_D: 1.3964 Loss_G: 0.6115 D(x): 0.4572 D(G(z)): 0.4572 / 0.5433\n",
            "[2/200][336/391] Loss_D: 1.3966 Loss_G: 0.7862 D(x): 0.5433 D(G(z)): 0.5433 / 0.4562\n",
            "[2/200][337/391] Loss_D: 1.3968 Loss_G: 0.6097 D(x): 0.4562 D(G(z)): 0.4562 / 0.5443\n",
            "[2/200][338/391] Loss_D: 1.3970 Loss_G: 0.7884 D(x): 0.5443 D(G(z)): 0.5443 / 0.4552\n",
            "[2/200][339/391] Loss_D: 1.3971 Loss_G: 0.6078 D(x): 0.4552 D(G(z)): 0.4552 / 0.5453\n",
            "[2/200][340/391] Loss_D: 1.3973 Loss_G: 0.7909 D(x): 0.5453 D(G(z)): 0.5453 / 0.4541\n",
            "[2/200][341/391] Loss_D: 1.3975 Loss_G: 0.6056 D(x): 0.4541 D(G(z)): 0.4540 / 0.5465\n",
            "[2/200][342/391] Loss_D: 1.3977 Loss_G: 0.7934 D(x): 0.5465 D(G(z)): 0.5465 / 0.4529\n",
            "[2/200][343/391] Loss_D: 1.3979 Loss_G: 0.6028 D(x): 0.4529 D(G(z)): 0.4529 / 0.5480\n",
            "[2/200][344/391] Loss_D: 1.3983 Loss_G: 0.7963 D(x): 0.5480 D(G(z)): 0.5480 / 0.4516\n",
            "[2/200][345/391] Loss_D: 1.3984 Loss_G: 0.5995 D(x): 0.4516 D(G(z)): 0.4516 / 0.5498\n",
            "[2/200][346/391] Loss_D: 1.3991 Loss_G: 0.8039 D(x): 0.5499 D(G(z)): 0.5499 / 0.4482\n",
            "[2/200][347/391] Loss_D: 1.3998 Loss_G: 0.5918 D(x): 0.4482 D(G(z)): 0.4482 / 0.5541\n",
            "[2/200][348/391] Loss_D: 1.4008 Loss_G: 0.8144 D(x): 0.5541 D(G(z)): 0.5541 / 0.4435\n",
            "[2/200][349/391] Loss_D: 1.4019 Loss_G: 0.5833 D(x): 0.4435 D(G(z)): 0.4435 / 0.5588\n",
            "[2/200][350/391] Loss_D: 1.4030 Loss_G: 0.8247 D(x): 0.5588 D(G(z)): 0.5588 / 0.4389\n",
            "[2/200][351/391] Loss_D: 1.4040 Loss_G: 0.5755 D(x): 0.4389 D(G(z)): 0.4389 / 0.5632\n",
            "[2/200][352/391] Loss_D: 1.4052 Loss_G: 0.8340 D(x): 0.5632 D(G(z)): 0.5632 / 0.4349\n",
            "[2/200][353/391] Loss_D: 1.4061 Loss_G: 0.5678 D(x): 0.4349 D(G(z)): 0.4349 / 0.5675\n",
            "[2/200][354/391] Loss_D: 1.4075 Loss_G: 0.8455 D(x): 0.5676 D(G(z)): 0.5676 / 0.4299\n",
            "[2/200][355/391] Loss_D: 1.4088 Loss_G: 0.5594 D(x): 0.4299 D(G(z)): 0.4299 / 0.5723\n",
            "[2/200][356/391] Loss_D: 1.4102 Loss_G: 0.8555 D(x): 0.5723 D(G(z)): 0.5724 / 0.4257\n",
            "[2/200][357/391] Loss_D: 1.4114 Loss_G: 0.5533 D(x): 0.4256 D(G(z)): 0.4256 / 0.5758\n",
            "[2/200][358/391] Loss_D: 1.4124 Loss_G: 0.8614 D(x): 0.5759 D(G(z)): 0.5759 / 0.4231\n",
            "[2/200][359/391] Loss_D: 1.4130 Loss_G: 0.5509 D(x): 0.4231 D(G(z)): 0.4231 / 0.5772\n",
            "[2/200][360/391] Loss_D: 1.4133 Loss_G: 0.8622 D(x): 0.5773 D(G(z)): 0.5773 / 0.4228\n",
            "[2/200][361/391] Loss_D: 1.4132 Loss_G: 0.5521 D(x): 0.4228 D(G(z)): 0.4228 / 0.5765\n",
            "[2/200][362/391] Loss_D: 1.4128 Loss_G: 0.8580 D(x): 0.5765 D(G(z)): 0.5766 / 0.4246\n",
            "[2/200][363/391] Loss_D: 1.4121 Loss_G: 0.5568 D(x): 0.4246 D(G(z)): 0.4245 / 0.5739\n",
            "[2/200][364/391] Loss_D: 1.4112 Loss_G: 0.8501 D(x): 0.5739 D(G(z)): 0.5739 / 0.4280\n",
            "[2/200][365/391] Loss_D: 1.4100 Loss_G: 0.5638 D(x): 0.4280 D(G(z)): 0.4279 / 0.5699\n",
            "[2/200][366/391] Loss_D: 1.4089 Loss_G: 0.8399 D(x): 0.5699 D(G(z)): 0.5699 / 0.4323\n",
            "[2/200][367/391] Loss_D: 1.4076 Loss_G: 0.5715 D(x): 0.4323 D(G(z)): 0.4323 / 0.5655\n",
            "[2/200][368/391] Loss_D: 1.4065 Loss_G: 0.8300 D(x): 0.5655 D(G(z)): 0.5655 / 0.4367\n",
            "[2/200][369/391] Loss_D: 1.4053 Loss_G: 0.5786 D(x): 0.4366 D(G(z)): 0.4366 / 0.5615\n",
            "[2/200][370/391] Loss_D: 1.4044 Loss_G: 0.8214 D(x): 0.5615 D(G(z)): 0.5615 / 0.4404\n",
            "[2/200][371/391] Loss_D: 1.4034 Loss_G: 0.5850 D(x): 0.4404 D(G(z)): 0.4404 / 0.5579\n",
            "[2/200][372/391] Loss_D: 1.4026 Loss_G: 0.8143 D(x): 0.5579 D(G(z)): 0.5579 / 0.4436\n",
            "[2/200][373/391] Loss_D: 1.4019 Loss_G: 0.5900 D(x): 0.4435 D(G(z)): 0.4435 / 0.5551\n",
            "[2/200][374/391] Loss_D: 1.4014 Loss_G: 0.8086 D(x): 0.5551 D(G(z)): 0.5552 / 0.4461\n",
            "[2/200][375/391] Loss_D: 1.4008 Loss_G: 0.5946 D(x): 0.4461 D(G(z)): 0.4461 / 0.5526\n",
            "[2/200][376/391] Loss_D: 1.4002 Loss_G: 0.8028 D(x): 0.5526 D(G(z)): 0.5526 / 0.4487\n",
            "[2/200][377/391] Loss_D: 1.3996 Loss_G: 0.5992 D(x): 0.4487 D(G(z)): 0.4487 / 0.5500\n",
            "[2/200][378/391] Loss_D: 1.3991 Loss_G: 0.7972 D(x): 0.5500 D(G(z)): 0.5501 / 0.4512\n",
            "[2/200][379/391] Loss_D: 1.3986 Loss_G: 0.6037 D(x): 0.4512 D(G(z)): 0.4512 / 0.5475\n",
            "[2/200][380/391] Loss_D: 1.3981 Loss_G: 0.7917 D(x): 0.5475 D(G(z)): 0.5476 / 0.4537\n",
            "[2/200][381/391] Loss_D: 1.3976 Loss_G: 0.6082 D(x): 0.4537 D(G(z)): 0.4537 / 0.5451\n",
            "[2/200][382/391] Loss_D: 1.3972 Loss_G: 0.7864 D(x): 0.5451 D(G(z)): 0.5451 / 0.4561\n",
            "[2/200][383/391] Loss_D: 1.3967 Loss_G: 0.6107 D(x): 0.4561 D(G(z)): 0.4561 / 0.5437\n",
            "[2/200][384/391] Loss_D: 1.3967 Loss_G: 0.7872 D(x): 0.5437 D(G(z)): 0.5438 / 0.4557\n",
            "[2/200][385/391] Loss_D: 1.3968 Loss_G: 0.6084 D(x): 0.4557 D(G(z)): 0.4557 / 0.5450\n",
            "[2/200][386/391] Loss_D: 1.3971 Loss_G: 0.7908 D(x): 0.5450 D(G(z)): 0.5450 / 0.4541\n",
            "[2/200][387/391] Loss_D: 1.3974 Loss_G: 0.6049 D(x): 0.4541 D(G(z)): 0.4541 / 0.5468\n",
            "[2/200][388/391] Loss_D: 1.3978 Loss_G: 0.7949 D(x): 0.5469 D(G(z)): 0.5469 / 0.4522\n",
            "[2/200][389/391] Loss_D: 1.3981 Loss_G: 0.6015 D(x): 0.4522 D(G(z)): 0.4522 / 0.5487\n",
            "[2/200][390/391] Loss_D: 1.3985 Loss_G: 0.7989 D(x): 0.5487 D(G(z)): 0.5488 / 0.4504\n",
            "[3/200][0/391] Loss_D: 1.3988 Loss_G: 0.5987 D(x): 0.4504 D(G(z)): 0.4504 / 0.5503\n",
            "[3/200][1/391] Loss_D: 1.3991 Loss_G: 0.8018 D(x): 0.5503 D(G(z)): 0.5503 / 0.4491\n",
            "[3/200][2/391] Loss_D: 1.3993 Loss_G: 0.5975 D(x): 0.4491 D(G(z)): 0.4491 / 0.5509\n",
            "[3/200][3/391] Loss_D: 1.3994 Loss_G: 0.8005 D(x): 0.5509 D(G(z)): 0.5510 / 0.4497\n",
            "[3/200][4/391] Loss_D: 1.3991 Loss_G: 0.6002 D(x): 0.4497 D(G(z)): 0.4497 / 0.5494\n",
            "[3/200][5/391] Loss_D: 1.3987 Loss_G: 0.7962 D(x): 0.5494 D(G(z)): 0.5494 / 0.4516\n",
            "[3/200][6/391] Loss_D: 1.3983 Loss_G: 0.6041 D(x): 0.4516 D(G(z)): 0.4516 / 0.5473\n",
            "[3/200][7/391] Loss_D: 1.3979 Loss_G: 0.7926 D(x): 0.5473 D(G(z)): 0.5473 / 0.4533\n",
            "[3/200][8/391] Loss_D: 1.3976 Loss_G: 0.6053 D(x): 0.4533 D(G(z)): 0.4532 / 0.5466\n",
            "[3/200][9/391] Loss_D: 1.3977 Loss_G: 0.7930 D(x): 0.5466 D(G(z)): 0.5466 / 0.4531\n",
            "[3/200][10/391] Loss_D: 1.3977 Loss_G: 0.6040 D(x): 0.4531 D(G(z)): 0.4531 / 0.5473\n",
            "[3/200][11/391] Loss_D: 1.3979 Loss_G: 0.7949 D(x): 0.5473 D(G(z)): 0.5473 / 0.4522\n",
            "[3/200][12/391] Loss_D: 1.3980 Loss_G: 0.6023 D(x): 0.4522 D(G(z)): 0.4522 / 0.5482\n",
            "[3/200][13/391] Loss_D: 1.3982 Loss_G: 0.7967 D(x): 0.5482 D(G(z)): 0.5483 / 0.4514\n",
            "[3/200][14/391] Loss_D: 1.3983 Loss_G: 0.6011 D(x): 0.4514 D(G(z)): 0.4514 / 0.5489\n",
            "[3/200][15/391] Loss_D: 1.3985 Loss_G: 0.7979 D(x): 0.5489 D(G(z)): 0.5489 / 0.4508\n",
            "[3/200][16/391] Loss_D: 1.3985 Loss_G: 0.6000 D(x): 0.4508 D(G(z)): 0.4508 / 0.5495\n",
            "[3/200][17/391] Loss_D: 1.3987 Loss_G: 0.7990 D(x): 0.5495 D(G(z)): 0.5495 / 0.4503\n",
            "[3/200][18/391] Loss_D: 1.3987 Loss_G: 0.5996 D(x): 0.4503 D(G(z)): 0.4503 / 0.5497\n",
            "[3/200][19/391] Loss_D: 1.3988 Loss_G: 0.7995 D(x): 0.5498 D(G(z)): 0.5498 / 0.4501\n",
            "[3/200][20/391] Loss_D: 1.3988 Loss_G: 0.5992 D(x): 0.4501 D(G(z)): 0.4501 / 0.5500\n",
            "[3/200][21/391] Loss_D: 1.3989 Loss_G: 0.7997 D(x): 0.5500 D(G(z)): 0.5500 / 0.4500\n",
            "[3/200][22/391] Loss_D: 1.3988 Loss_G: 0.5992 D(x): 0.4500 D(G(z)): 0.4500 / 0.5499\n",
            "[3/200][23/391] Loss_D: 1.3989 Loss_G: 0.8002 D(x): 0.5499 D(G(z)): 0.5500 / 0.4498\n",
            "[3/200][24/391] Loss_D: 1.3989 Loss_G: 0.5980 D(x): 0.4498 D(G(z)): 0.4498 / 0.5506\n",
            "[3/200][25/391] Loss_D: 1.3991 Loss_G: 0.8020 D(x): 0.5506 D(G(z)): 0.5506 / 0.4490\n",
            "[3/200][26/391] Loss_D: 1.3992 Loss_G: 0.5965 D(x): 0.4490 D(G(z)): 0.4490 / 0.5514\n",
            "[3/200][27/391] Loss_D: 1.3994 Loss_G: 0.8037 D(x): 0.5514 D(G(z)): 0.5514 / 0.4482\n",
            "[3/200][28/391] Loss_D: 1.3995 Loss_G: 0.5955 D(x): 0.4482 D(G(z)): 0.4482 / 0.5520\n",
            "[3/200][29/391] Loss_D: 1.3997 Loss_G: 0.8039 D(x): 0.5520 D(G(z)): 0.5520 / 0.4481\n",
            "[3/200][30/391] Loss_D: 1.3996 Loss_G: 0.5964 D(x): 0.4481 D(G(z)): 0.4481 / 0.5515\n",
            "[3/200][31/391] Loss_D: 1.3994 Loss_G: 0.8019 D(x): 0.5515 D(G(z)): 0.5515 / 0.4490\n",
            "[3/200][32/391] Loss_D: 1.3992 Loss_G: 0.5985 D(x): 0.4490 D(G(z)): 0.4490 / 0.5503\n",
            "[3/200][33/391] Loss_D: 1.3989 Loss_G: 0.7986 D(x): 0.5503 D(G(z)): 0.5503 / 0.4505\n",
            "[3/200][34/391] Loss_D: 1.3986 Loss_G: 0.6016 D(x): 0.4505 D(G(z)): 0.4505 / 0.5486\n",
            "[3/200][35/391] Loss_D: 1.3983 Loss_G: 0.7945 D(x): 0.5486 D(G(z)): 0.5486 / 0.4524\n",
            "[3/200][36/391] Loss_D: 1.3978 Loss_G: 0.6053 D(x): 0.4524 D(G(z)): 0.4524 / 0.5466\n",
            "[3/200][37/391] Loss_D: 1.3975 Loss_G: 0.7898 D(x): 0.5466 D(G(z)): 0.5466 / 0.4545\n",
            "[3/200][38/391] Loss_D: 1.3970 Loss_G: 0.6090 D(x): 0.4545 D(G(z)): 0.4544 / 0.5445\n",
            "[3/200][39/391] Loss_D: 1.3967 Loss_G: 0.7855 D(x): 0.5445 D(G(z)): 0.5445 / 0.4564\n",
            "[3/200][40/391] Loss_D: 1.3963 Loss_G: 0.6124 D(x): 0.4564 D(G(z)): 0.4564 / 0.5427\n",
            "[3/200][41/391] Loss_D: 1.3960 Loss_G: 0.7821 D(x): 0.5427 D(G(z)): 0.5427 / 0.4580\n",
            "[3/200][42/391] Loss_D: 1.3957 Loss_G: 0.6146 D(x): 0.4580 D(G(z)): 0.4579 / 0.5415\n",
            "[3/200][43/391] Loss_D: 1.3956 Loss_G: 0.7800 D(x): 0.5415 D(G(z)): 0.5415 / 0.4590\n",
            "[3/200][44/391] Loss_D: 1.3954 Loss_G: 0.6161 D(x): 0.4590 D(G(z)): 0.4590 / 0.5407\n",
            "[3/200][45/391] Loss_D: 1.3954 Loss_G: 0.7786 D(x): 0.5407 D(G(z)): 0.5407 / 0.4596\n",
            "[3/200][46/391] Loss_D: 1.3953 Loss_G: 0.6171 D(x): 0.4596 D(G(z)): 0.4596 / 0.5401\n",
            "[3/200][47/391] Loss_D: 1.3952 Loss_G: 0.7776 D(x): 0.5401 D(G(z)): 0.5402 / 0.4601\n",
            "[3/200][48/391] Loss_D: 1.3951 Loss_G: 0.6177 D(x): 0.4600 D(G(z)): 0.4600 / 0.5398\n",
            "[3/200][49/391] Loss_D: 1.3951 Loss_G: 0.7772 D(x): 0.5398 D(G(z)): 0.5398 / 0.4603\n",
            "[3/200][50/391] Loss_D: 1.3950 Loss_G: 0.6179 D(x): 0.4602 D(G(z)): 0.4602 / 0.5397\n",
            "[3/200][51/391] Loss_D: 1.3950 Loss_G: 0.7773 D(x): 0.5398 D(G(z)): 0.5398 / 0.4602\n",
            "[3/200][52/391] Loss_D: 1.3950 Loss_G: 0.6175 D(x): 0.4602 D(G(z)): 0.4602 / 0.5399\n",
            "[3/200][53/391] Loss_D: 1.3951 Loss_G: 0.7779 D(x): 0.5399 D(G(z)): 0.5399 / 0.4599\n",
            "[3/200][54/391] Loss_D: 1.3951 Loss_G: 0.6168 D(x): 0.4599 D(G(z)): 0.4599 / 0.5403\n",
            "[3/200][55/391] Loss_D: 1.3952 Loss_G: 0.7791 D(x): 0.5403 D(G(z)): 0.5403 / 0.4593\n",
            "[3/200][56/391] Loss_D: 1.3953 Loss_G: 0.6153 D(x): 0.4593 D(G(z)): 0.4593 / 0.5411\n",
            "[3/200][57/391] Loss_D: 1.3954 Loss_G: 0.7825 D(x): 0.5411 D(G(z)): 0.5411 / 0.4578\n",
            "[3/200][58/391] Loss_D: 1.3958 Loss_G: 0.6113 D(x): 0.4578 D(G(z)): 0.4578 / 0.5433\n",
            "[3/200][59/391] Loss_D: 1.3962 Loss_G: 0.7875 D(x): 0.5433 D(G(z)): 0.5433 / 0.4555\n",
            "[3/200][60/391] Loss_D: 1.3966 Loss_G: 0.6031 D(x): 0.4555 D(G(z)): 0.4555 / 0.5478\n",
            "[3/200][61/391] Loss_D: 1.3979 Loss_G: 0.8049 D(x): 0.5478 D(G(z)): 0.5478 / 0.4476\n",
            "[3/200][62/391] Loss_D: 1.3997 Loss_G: 0.5854 D(x): 0.4476 D(G(z)): 0.4476 / 0.5576\n",
            "[3/200][63/391] Loss_D: 1.4021 Loss_G: 0.8294 D(x): 0.5576 D(G(z)): 0.5576 / 0.4368\n",
            "[3/200][64/391] Loss_D: 1.4047 Loss_G: 0.5653 D(x): 0.4368 D(G(z)): 0.4368 / 0.5688\n",
            "[3/200][65/391] Loss_D: 1.4078 Loss_G: 0.8555 D(x): 0.5689 D(G(z)): 0.5689 / 0.4256\n",
            "[3/200][66/391] Loss_D: 1.4110 Loss_G: 0.5459 D(x): 0.4256 D(G(z)): 0.4255 / 0.5800\n",
            "[3/200][67/391] Loss_D: 1.4146 Loss_G: 0.8810 D(x): 0.5800 D(G(z)): 0.5801 / 0.4148\n",
            "[3/200][68/391] Loss_D: 1.4180 Loss_G: 0.5301 D(x): 0.4148 D(G(z)): 0.4148 / 0.5892\n",
            "[3/200][69/391] Loss_D: 1.4211 Loss_G: 0.8992 D(x): 0.5892 D(G(z)): 0.5893 / 0.4074\n",
            "[3/200][70/391] Loss_D: 1.4236 Loss_G: 0.5232 D(x): 0.4074 D(G(z)): 0.4073 / 0.5933\n",
            "[3/200][71/391] Loss_D: 1.4243 Loss_G: 0.8974 D(x): 0.5934 D(G(z)): 0.5934 / 0.4081\n",
            "[3/200][72/391] Loss_D: 1.4231 Loss_G: 0.5316 D(x): 0.4081 D(G(z)): 0.4081 / 0.5884\n",
            "[3/200][73/391] Loss_D: 1.4206 Loss_G: 0.8788 D(x): 0.5884 D(G(z)): 0.5885 / 0.4158\n",
            "[3/200][74/391] Loss_D: 1.4176 Loss_G: 0.5472 D(x): 0.4158 D(G(z)): 0.4157 / 0.5793\n",
            "[3/200][75/391] Loss_D: 1.4143 Loss_G: 0.8617 D(x): 0.5793 D(G(z)): 0.5793 / 0.4230\n",
            "[3/200][76/391] Loss_D: 1.4128 Loss_G: 0.5534 D(x): 0.4229 D(G(z)): 0.4229 / 0.5757\n",
            "[3/200][77/391] Loss_D: 1.4121 Loss_G: 0.8575 D(x): 0.5757 D(G(z)): 0.5758 / 0.4248\n",
            "[3/200][78/391] Loss_D: 1.4117 Loss_G: 0.5557 D(x): 0.4247 D(G(z)): 0.4247 / 0.5744\n",
            "[3/200][79/391] Loss_D: 1.4113 Loss_G: 0.8524 D(x): 0.5744 D(G(z)): 0.5744 / 0.4270\n",
            "[3/200][80/391] Loss_D: 1.4104 Loss_G: 0.5616 D(x): 0.4269 D(G(z)): 0.4269 / 0.5710\n",
            "[3/200][81/391] Loss_D: 1.4093 Loss_G: 0.8419 D(x): 0.5711 D(G(z)): 0.5711 / 0.4315\n",
            "[3/200][82/391] Loss_D: 1.4078 Loss_G: 0.5710 D(x): 0.4314 D(G(z)): 0.4314 / 0.5657\n",
            "[3/200][83/391] Loss_D: 1.4063 Loss_G: 0.8294 D(x): 0.5657 D(G(z)): 0.5657 / 0.4369\n",
            "[3/200][84/391] Loss_D: 1.4049 Loss_G: 0.5804 D(x): 0.4368 D(G(z)): 0.4368 / 0.5604\n",
            "[3/200][85/391] Loss_D: 1.4035 Loss_G: 0.8204 D(x): 0.5604 D(G(z)): 0.5604 / 0.4408\n",
            "[3/200][86/391] Loss_D: 1.4029 Loss_G: 0.5835 D(x): 0.4408 D(G(z)): 0.4407 / 0.5587\n",
            "[3/200][87/391] Loss_D: 1.4027 Loss_G: 0.8181 D(x): 0.5587 D(G(z)): 0.5587 / 0.4418\n",
            "[3/200][88/391] Loss_D: 1.4024 Loss_G: 0.5852 D(x): 0.4418 D(G(z)): 0.4417 / 0.5577\n",
            "[3/200][89/391] Loss_D: 1.4022 Loss_G: 0.8155 D(x): 0.5577 D(G(z)): 0.5577 / 0.4430\n",
            "[3/200][90/391] Loss_D: 1.4019 Loss_G: 0.5877 D(x): 0.4429 D(G(z)): 0.4429 / 0.5563\n",
            "[3/200][91/391] Loss_D: 1.4016 Loss_G: 0.8119 D(x): 0.5563 D(G(z)): 0.5563 / 0.4446\n",
            "[3/200][92/391] Loss_D: 1.4011 Loss_G: 0.5911 D(x): 0.4446 D(G(z)): 0.4445 / 0.5544\n",
            "[3/200][93/391] Loss_D: 1.4007 Loss_G: 0.8067 D(x): 0.5544 D(G(z)): 0.5544 / 0.4469\n",
            "[3/200][94/391] Loss_D: 1.4001 Loss_G: 0.5961 D(x): 0.4469 D(G(z)): 0.4469 / 0.5516\n",
            "[3/200][95/391] Loss_D: 1.3995 Loss_G: 0.7994 D(x): 0.5516 D(G(z)): 0.5516 / 0.4501\n",
            "[3/200][96/391] Loss_D: 1.3987 Loss_G: 0.6027 D(x): 0.4501 D(G(z)): 0.4501 / 0.5480\n",
            "[3/200][97/391] Loss_D: 1.3980 Loss_G: 0.7912 D(x): 0.5480 D(G(z)): 0.5480 / 0.4539\n",
            "[3/200][98/391] Loss_D: 1.3972 Loss_G: 0.6095 D(x): 0.4538 D(G(z)): 0.4538 / 0.5443\n",
            "[3/200][99/391] Loss_D: 1.3966 Loss_G: 0.7834 D(x): 0.5443 D(G(z)): 0.5443 / 0.4574\n",
            "[3/200][100/391] Loss_D: 1.3959 Loss_G: 0.6154 D(x): 0.4574 D(G(z)): 0.4573 / 0.5411\n",
            "[3/200][101/391] Loss_D: 1.3954 Loss_G: 0.7769 D(x): 0.5411 D(G(z)): 0.5411 / 0.4604\n",
            "[3/200][102/391] Loss_D: 1.3949 Loss_G: 0.6205 D(x): 0.4604 D(G(z)): 0.4604 / 0.5383\n",
            "[3/200][103/391] Loss_D: 1.3945 Loss_G: 0.7713 D(x): 0.5383 D(G(z)): 0.5383 / 0.4630\n",
            "[3/200][104/391] Loss_D: 1.3941 Loss_G: 0.6250 D(x): 0.4630 D(G(z)): 0.4629 / 0.5359\n",
            "[3/200][105/391] Loss_D: 1.3938 Loss_G: 0.7665 D(x): 0.5359 D(G(z)): 0.5359 / 0.4652\n",
            "[3/200][106/391] Loss_D: 1.3934 Loss_G: 0.6287 D(x): 0.4652 D(G(z)): 0.4651 / 0.5339\n",
            "[3/200][107/391] Loss_D: 1.3932 Loss_G: 0.7626 D(x): 0.5339 D(G(z)): 0.5339 / 0.4670\n",
            "[3/200][108/391] Loss_D: 1.3929 Loss_G: 0.6318 D(x): 0.4670 D(G(z)): 0.4670 / 0.5322\n",
            "[3/200][109/391] Loss_D: 1.3927 Loss_G: 0.7594 D(x): 0.5322 D(G(z)): 0.5322 / 0.4685\n",
            "[3/200][110/391] Loss_D: 1.3925 Loss_G: 0.6340 D(x): 0.4685 D(G(z)): 0.4685 / 0.5311\n",
            "[3/200][111/391] Loss_D: 1.3924 Loss_G: 0.7579 D(x): 0.5311 D(G(z)): 0.5311 / 0.4692\n",
            "[3/200][112/391] Loss_D: 1.3923 Loss_G: 0.6348 D(x): 0.4692 D(G(z)): 0.4692 / 0.5306\n",
            "[3/200][113/391] Loss_D: 1.3923 Loss_G: 0.7573 D(x): 0.5306 D(G(z)): 0.5307 / 0.4695\n",
            "[3/200][114/391] Loss_D: 1.3922 Loss_G: 0.6359 D(x): 0.4695 D(G(z)): 0.4694 / 0.5300\n",
            "[3/200][115/391] Loss_D: 1.3921 Loss_G: 0.7556 D(x): 0.5300 D(G(z)): 0.5300 / 0.4703\n",
            "[3/200][116/391] Loss_D: 1.3920 Loss_G: 0.6363 D(x): 0.4702 D(G(z)): 0.4702 / 0.5298\n",
            "[3/200][117/391] Loss_D: 1.3921 Loss_G: 0.7562 D(x): 0.5298 D(G(z)): 0.5298 / 0.4700\n",
            "[3/200][118/391] Loss_D: 1.3921 Loss_G: 0.6352 D(x): 0.4700 D(G(z)): 0.4700 / 0.5304\n",
            "[3/200][119/391] Loss_D: 1.3922 Loss_G: 0.7579 D(x): 0.5304 D(G(z)): 0.5304 / 0.4691\n",
            "[3/200][120/391] Loss_D: 1.3923 Loss_G: 0.6333 D(x): 0.4691 D(G(z)): 0.4691 / 0.5314\n",
            "[3/200][121/391] Loss_D: 1.3924 Loss_G: 0.7604 D(x): 0.5314 D(G(z)): 0.5314 / 0.4680\n",
            "[3/200][122/391] Loss_D: 1.3925 Loss_G: 0.6309 D(x): 0.4680 D(G(z)): 0.4680 / 0.5327\n",
            "[3/200][123/391] Loss_D: 1.3927 Loss_G: 0.7635 D(x): 0.5327 D(G(z)): 0.5327 / 0.4665\n",
            "[3/200][124/391] Loss_D: 1.3929 Loss_G: 0.6279 D(x): 0.4665 D(G(z)): 0.4665 / 0.5343\n",
            "[3/200][125/391] Loss_D: 1.3931 Loss_G: 0.7671 D(x): 0.5343 D(G(z)): 0.5343 / 0.4648\n",
            "[3/200][126/391] Loss_D: 1.3933 Loss_G: 0.6245 D(x): 0.4648 D(G(z)): 0.4648 / 0.5361\n",
            "[3/200][127/391] Loss_D: 1.3936 Loss_G: 0.7714 D(x): 0.5361 D(G(z)): 0.5361 / 0.4629\n",
            "[3/200][128/391] Loss_D: 1.3939 Loss_G: 0.6206 D(x): 0.4629 D(G(z)): 0.4629 / 0.5382\n",
            "[3/200][129/391] Loss_D: 1.3943 Loss_G: 0.7762 D(x): 0.5382 D(G(z)): 0.5382 / 0.4606\n",
            "[3/200][130/391] Loss_D: 1.3946 Loss_G: 0.6162 D(x): 0.4606 D(G(z)): 0.4606 / 0.5406\n",
            "[3/200][131/391] Loss_D: 1.3950 Loss_G: 0.7815 D(x): 0.5406 D(G(z)): 0.5406 / 0.4582\n",
            "[3/200][132/391] Loss_D: 1.3954 Loss_G: 0.6117 D(x): 0.4582 D(G(z)): 0.4582 / 0.5430\n",
            "[3/200][133/391] Loss_D: 1.3958 Loss_G: 0.7868 D(x): 0.5430 D(G(z)): 0.5430 / 0.4558\n",
            "[3/200][134/391] Loss_D: 1.3962 Loss_G: 0.6072 D(x): 0.4558 D(G(z)): 0.4558 / 0.5454\n",
            "[3/200][135/391] Loss_D: 1.3967 Loss_G: 0.7918 D(x): 0.5454 D(G(z)): 0.5454 / 0.4535\n",
            "[3/200][136/391] Loss_D: 1.3970 Loss_G: 0.6035 D(x): 0.4535 D(G(z)): 0.4535 / 0.5475\n",
            "[3/200][137/391] Loss_D: 1.3974 Loss_G: 0.7959 D(x): 0.5475 D(G(z)): 0.5475 / 0.4516\n",
            "[3/200][138/391] Loss_D: 1.3977 Loss_G: 0.6002 D(x): 0.4516 D(G(z)): 0.4516 / 0.5492\n",
            "[3/200][139/391] Loss_D: 1.3981 Loss_G: 0.8000 D(x): 0.5493 D(G(z)): 0.5493 / 0.4498\n",
            "[3/200][140/391] Loss_D: 1.3985 Loss_G: 0.5964 D(x): 0.4498 D(G(z)): 0.4498 / 0.5514\n",
            "[3/200][141/391] Loss_D: 1.3990 Loss_G: 0.8051 D(x): 0.5514 D(G(z)): 0.5514 / 0.4475\n",
            "[3/200][142/391] Loss_D: 1.3994 Loss_G: 0.5926 D(x): 0.4475 D(G(z)): 0.4475 / 0.5535\n",
            "[3/200][143/391] Loss_D: 1.3999 Loss_G: 0.8089 D(x): 0.5535 D(G(z)): 0.5535 / 0.4458\n",
            "[3/200][144/391] Loss_D: 1.4001 Loss_G: 0.5901 D(x): 0.4458 D(G(z)): 0.4458 / 0.5548\n",
            "[3/200][145/391] Loss_D: 1.4004 Loss_G: 0.8114 D(x): 0.5548 D(G(z)): 0.5548 / 0.4447\n",
            "[3/200][146/391] Loss_D: 1.4006 Loss_G: 0.5884 D(x): 0.4447 D(G(z)): 0.4446 / 0.5558\n",
            "[3/200][147/391] Loss_D: 1.4009 Loss_G: 0.8134 D(x): 0.5558 D(G(z)): 0.5558 / 0.4438\n",
            "[3/200][148/391] Loss_D: 1.4010 Loss_G: 0.5868 D(x): 0.4438 D(G(z)): 0.4437 / 0.5567\n",
            "[3/200][149/391] Loss_D: 1.4013 Loss_G: 0.8154 D(x): 0.5567 D(G(z)): 0.5567 / 0.4429\n",
            "[3/200][150/391] Loss_D: 1.4014 Loss_G: 0.5851 D(x): 0.4429 D(G(z)): 0.4429 / 0.5576\n",
            "[3/200][151/391] Loss_D: 1.4017 Loss_G: 0.8175 D(x): 0.5577 D(G(z)): 0.5577 / 0.4420\n",
            "[3/200][152/391] Loss_D: 1.4019 Loss_G: 0.5838 D(x): 0.4420 D(G(z)): 0.4419 / 0.5583\n",
            "[3/200][153/391] Loss_D: 1.4021 Loss_G: 0.8186 D(x): 0.5584 D(G(z)): 0.5584 / 0.4415\n",
            "[3/200][154/391] Loss_D: 1.4021 Loss_G: 0.5836 D(x): 0.4415 D(G(z)): 0.4415 / 0.5585\n",
            "[3/200][155/391] Loss_D: 1.4021 Loss_G: 0.8182 D(x): 0.5585 D(G(z)): 0.5585 / 0.4417\n",
            "[3/200][156/391] Loss_D: 1.4020 Loss_G: 0.5818 D(x): 0.4417 D(G(z)): 0.4417 / 0.5595\n",
            "[3/200][157/391] Loss_D: 1.4026 Loss_G: 0.8248 D(x): 0.5595 D(G(z)): 0.5595 / 0.4388\n",
            "[3/200][158/391] Loss_D: 1.4034 Loss_G: 0.5758 D(x): 0.4388 D(G(z)): 0.4388 / 0.5628\n",
            "[3/200][159/391] Loss_D: 1.4043 Loss_G: 0.8327 D(x): 0.5628 D(G(z)): 0.5629 / 0.4353\n",
            "[3/200][160/391] Loss_D: 1.4052 Loss_G: 0.5695 D(x): 0.4353 D(G(z)): 0.4353 / 0.5664\n",
            "[3/200][161/391] Loss_D: 1.4062 Loss_G: 0.8400 D(x): 0.5664 D(G(z)): 0.5664 / 0.4321\n",
            "[3/200][162/391] Loss_D: 1.4069 Loss_G: 0.5652 D(x): 0.4321 D(G(z)): 0.4321 / 0.5688\n",
            "[3/200][163/391] Loss_D: 1.4075 Loss_G: 0.8433 D(x): 0.5689 D(G(z)): 0.5689 / 0.4307\n",
            "[3/200][164/391] Loss_D: 1.4077 Loss_G: 0.5655 D(x): 0.4307 D(G(z)): 0.4307 / 0.5686\n",
            "[3/200][165/391] Loss_D: 1.4074 Loss_G: 0.8377 D(x): 0.5687 D(G(z)): 0.5687 / 0.4331\n",
            "[3/200][166/391] Loss_D: 1.4064 Loss_G: 0.5723 D(x): 0.4331 D(G(z)): 0.4331 / 0.5648\n",
            "[3/200][167/391] Loss_D: 1.4053 Loss_G: 0.8277 D(x): 0.5648 D(G(z)): 0.5648 / 0.4375\n",
            "[3/200][168/391] Loss_D: 1.4041 Loss_G: 0.5807 D(x): 0.4375 D(G(z)): 0.4375 / 0.5601\n",
            "[3/200][169/391] Loss_D: 1.4030 Loss_G: 0.8164 D(x): 0.5601 D(G(z)): 0.5601 / 0.4425\n",
            "[3/200][170/391] Loss_D: 1.4017 Loss_G: 0.5900 D(x): 0.4425 D(G(z)): 0.4425 / 0.5549\n",
            "[3/200][171/391] Loss_D: 1.4005 Loss_G: 0.8048 D(x): 0.5549 D(G(z)): 0.5549 / 0.4477\n",
            "[3/200][172/391] Loss_D: 1.3994 Loss_G: 0.5991 D(x): 0.4476 D(G(z)): 0.4476 / 0.5499\n",
            "[3/200][173/391] Loss_D: 1.3984 Loss_G: 0.7941 D(x): 0.5499 D(G(z)): 0.5499 / 0.4524\n",
            "[3/200][174/391] Loss_D: 1.3974 Loss_G: 0.6073 D(x): 0.4524 D(G(z)): 0.4524 / 0.5454\n",
            "[3/200][175/391] Loss_D: 1.3966 Loss_G: 0.7848 D(x): 0.5454 D(G(z)): 0.5454 / 0.4567\n",
            "[3/200][176/391] Loss_D: 1.3959 Loss_G: 0.6145 D(x): 0.4566 D(G(z)): 0.4566 / 0.5415\n",
            "[3/200][177/391] Loss_D: 1.3952 Loss_G: 0.7768 D(x): 0.5415 D(G(z)): 0.5415 / 0.4603\n",
            "[3/200][178/391] Loss_D: 1.3946 Loss_G: 0.6210 D(x): 0.4603 D(G(z)): 0.4603 / 0.5380\n",
            "[3/200][179/391] Loss_D: 1.3941 Loss_G: 0.7696 D(x): 0.5380 D(G(z)): 0.5380 / 0.4637\n",
            "[3/200][180/391] Loss_D: 1.3936 Loss_G: 0.6268 D(x): 0.4636 D(G(z)): 0.4636 / 0.5348\n",
            "[3/200][181/391] Loss_D: 1.3932 Loss_G: 0.7634 D(x): 0.5349 D(G(z)): 0.5349 / 0.4665\n",
            "[3/200][182/391] Loss_D: 1.3928 Loss_G: 0.6317 D(x): 0.4665 D(G(z)): 0.4665 / 0.5322\n",
            "[3/200][183/391] Loss_D: 1.3924 Loss_G: 0.7583 D(x): 0.5322 D(G(z)): 0.5322 / 0.4689\n",
            "[3/200][184/391] Loss_D: 1.3921 Loss_G: 0.6357 D(x): 0.4689 D(G(z)): 0.4689 / 0.5301\n",
            "[3/200][185/391] Loss_D: 1.3919 Loss_G: 0.7545 D(x): 0.5301 D(G(z)): 0.5301 / 0.4707\n",
            "[3/200][186/391] Loss_D: 1.3917 Loss_G: 0.6383 D(x): 0.4707 D(G(z)): 0.4707 / 0.5287\n",
            "[3/200][187/391] Loss_D: 1.3916 Loss_G: 0.7524 D(x): 0.5287 D(G(z)): 0.5287 / 0.4717\n",
            "[3/200][188/391] Loss_D: 1.3914 Loss_G: 0.6397 D(x): 0.4717 D(G(z)): 0.4717 / 0.5280\n",
            "[3/200][189/391] Loss_D: 1.3914 Loss_G: 0.7512 D(x): 0.5280 D(G(z)): 0.5280 / 0.4723\n",
            "[3/200][190/391] Loss_D: 1.3913 Loss_G: 0.6404 D(x): 0.4723 D(G(z)): 0.4722 / 0.5276\n",
            "[3/200][191/391] Loss_D: 1.3913 Loss_G: 0.7507 D(x): 0.5276 D(G(z)): 0.5276 / 0.4725\n",
            "[3/200][192/391] Loss_D: 1.3912 Loss_G: 0.6406 D(x): 0.4725 D(G(z)): 0.4725 / 0.5275\n",
            "[3/200][193/391] Loss_D: 1.3912 Loss_G: 0.7508 D(x): 0.5275 D(G(z)): 0.5275 / 0.4725\n",
            "[3/200][194/391] Loss_D: 1.3912 Loss_G: 0.6402 D(x): 0.4724 D(G(z)): 0.4724 / 0.5277\n",
            "[3/200][195/391] Loss_D: 1.3912 Loss_G: 0.7516 D(x): 0.5277 D(G(z)): 0.5277 / 0.4721\n",
            "[3/200][196/391] Loss_D: 1.3913 Loss_G: 0.6390 D(x): 0.4721 D(G(z)): 0.4721 / 0.5283\n",
            "[3/200][197/391] Loss_D: 1.3914 Loss_G: 0.7533 D(x): 0.5283 D(G(z)): 0.5283 / 0.4712\n",
            "[3/200][198/391] Loss_D: 1.3914 Loss_G: 0.6370 D(x): 0.4712 D(G(z)): 0.4712 / 0.5293\n",
            "[3/200][199/391] Loss_D: 1.3916 Loss_G: 0.7559 D(x): 0.5293 D(G(z)): 0.5294 / 0.4700\n",
            "[3/200][200/391] Loss_D: 1.3917 Loss_G: 0.6345 D(x): 0.4700 D(G(z)): 0.4700 / 0.5307\n",
            "[3/200][201/391] Loss_D: 1.3919 Loss_G: 0.7590 D(x): 0.5307 D(G(z)): 0.5307 / 0.4686\n",
            "[3/200][202/391] Loss_D: 1.3921 Loss_G: 0.6315 D(x): 0.4686 D(G(z)): 0.4686 / 0.5323\n",
            "[3/200][203/391] Loss_D: 1.3923 Loss_G: 0.7629 D(x): 0.5323 D(G(z)): 0.5323 / 0.4668\n",
            "[3/200][204/391] Loss_D: 1.3925 Loss_G: 0.6278 D(x): 0.4667 D(G(z)): 0.4667 / 0.5343\n",
            "[3/200][205/391] Loss_D: 1.3928 Loss_G: 0.7674 D(x): 0.5343 D(G(z)): 0.5343 / 0.4646\n",
            "[3/200][206/391] Loss_D: 1.3931 Loss_G: 0.6235 D(x): 0.4646 D(G(z)): 0.4646 / 0.5365\n",
            "[3/200][207/391] Loss_D: 1.3935 Loss_G: 0.7726 D(x): 0.5365 D(G(z)): 0.5365 / 0.4622\n",
            "[3/200][208/391] Loss_D: 1.3938 Loss_G: 0.6188 D(x): 0.4622 D(G(z)): 0.4622 / 0.5391\n",
            "[3/200][209/391] Loss_D: 1.3942 Loss_G: 0.7791 D(x): 0.5391 D(G(z)): 0.5391 / 0.4592\n",
            "[3/200][210/391] Loss_D: 1.3947 Loss_G: 0.6121 D(x): 0.4592 D(G(z)): 0.4592 / 0.5427\n",
            "[3/200][211/391] Loss_D: 1.3954 Loss_G: 0.7881 D(x): 0.5427 D(G(z)): 0.5427 / 0.4551\n",
            "[3/200][212/391] Loss_D: 1.3961 Loss_G: 0.6032 D(x): 0.4551 D(G(z)): 0.4551 / 0.5475\n",
            "[3/200][213/391] Loss_D: 1.3972 Loss_G: 0.8003 D(x): 0.5475 D(G(z)): 0.5475 / 0.4496\n",
            "[3/200][214/391] Loss_D: 1.3983 Loss_G: 0.5927 D(x): 0.4496 D(G(z)): 0.4496 / 0.5533\n",
            "[3/200][215/391] Loss_D: 1.3995 Loss_G: 0.8150 D(x): 0.5533 D(G(z)): 0.5533 / 0.4430\n",
            "[3/200][216/391] Loss_D: 1.4011 Loss_G: 0.5790 D(x): 0.4430 D(G(z)): 0.4430 / 0.5610\n",
            "[3/200][217/391] Loss_D: 1.4031 Loss_G: 0.8332 D(x): 0.5610 D(G(z)): 0.5610 / 0.4351\n",
            "[3/200][218/391] Loss_D: 1.4051 Loss_G: 0.5644 D(x): 0.4350 D(G(z)): 0.4350 / 0.5692\n",
            "[3/200][219/391] Loss_D: 1.4075 Loss_G: 0.8527 D(x): 0.5692 D(G(z)): 0.5692 / 0.4266\n",
            "[3/200][220/391] Loss_D: 1.4098 Loss_G: 0.5504 D(x): 0.4266 D(G(z)): 0.4266 / 0.5772\n",
            "[3/200][221/391] Loss_D: 1.4123 Loss_G: 0.8706 D(x): 0.5773 D(G(z)): 0.5773 / 0.4191\n",
            "[3/200][222/391] Loss_D: 1.4146 Loss_G: 0.5391 D(x): 0.4191 D(G(z)): 0.4190 / 0.5838\n",
            "[3/200][223/391] Loss_D: 1.4167 Loss_G: 0.8826 D(x): 0.5838 D(G(z)): 0.5838 / 0.4141\n",
            "[3/200][224/391] Loss_D: 1.4181 Loss_G: 0.5334 D(x): 0.4141 D(G(z)): 0.4140 / 0.5872\n",
            "[3/200][225/391] Loss_D: 1.4191 Loss_G: 0.8854 D(x): 0.5872 D(G(z)): 0.5872 / 0.4129\n",
            "[3/200][226/391] Loss_D: 1.4190 Loss_G: 0.5328 D(x): 0.4129 D(G(z)): 0.4129 / 0.5876\n",
            "[3/200][227/391] Loss_D: 1.4194 Loss_G: 0.8870 D(x): 0.5876 D(G(z)): 0.5876 / 0.4123\n",
            "[3/200][228/391] Loss_D: 1.4195 Loss_G: 0.5324 D(x): 0.4123 D(G(z)): 0.4123 / 0.5878\n",
            "[3/200][229/391] Loss_D: 1.4197 Loss_G: 0.8868 D(x): 0.5878 D(G(z)): 0.5878 / 0.4124\n",
            "[3/200][230/391] Loss_D: 1.4195 Loss_G: 0.5334 D(x): 0.4124 D(G(z)): 0.4124 / 0.5872\n",
            "[3/200][231/391] Loss_D: 1.4194 Loss_G: 0.8831 D(x): 0.5872 D(G(z)): 0.5873 / 0.4139\n",
            "[3/200][232/391] Loss_D: 1.4184 Loss_G: 0.5374 D(x): 0.4139 D(G(z)): 0.4139 / 0.5849\n",
            "[3/200][233/391] Loss_D: 1.4177 Loss_G: 0.8768 D(x): 0.5849 D(G(z)): 0.5849 / 0.4166\n",
            "[3/200][234/391] Loss_D: 1.4166 Loss_G: 0.5437 D(x): 0.4165 D(G(z)): 0.4165 / 0.5812\n",
            "[3/200][235/391] Loss_D: 1.4153 Loss_G: 0.8652 D(x): 0.5813 D(G(z)): 0.5813 / 0.4214\n",
            "[3/200][236/391] Loss_D: 1.4134 Loss_G: 0.5531 D(x): 0.4214 D(G(z)): 0.4214 / 0.5758\n",
            "[3/200][237/391] Loss_D: 1.4117 Loss_G: 0.8518 D(x): 0.5758 D(G(z)): 0.5758 / 0.4271\n",
            "[3/200][238/391] Loss_D: 1.4099 Loss_G: 0.5627 D(x): 0.4271 D(G(z)): 0.4271 / 0.5703\n",
            "[3/200][239/391] Loss_D: 1.4085 Loss_G: 0.8395 D(x): 0.5703 D(G(z)): 0.5704 / 0.4324\n",
            "[3/200][240/391] Loss_D: 1.4069 Loss_G: 0.5729 D(x): 0.4324 D(G(z)): 0.4324 / 0.5645\n",
            "[3/200][241/391] Loss_D: 1.4053 Loss_G: 0.8246 D(x): 0.5645 D(G(z)): 0.5645 / 0.4389\n",
            "[3/200][242/391] Loss_D: 1.4035 Loss_G: 0.5853 D(x): 0.4389 D(G(z)): 0.4389 / 0.5576\n",
            "[3/200][243/391] Loss_D: 1.4018 Loss_G: 0.8086 D(x): 0.5576 D(G(z)): 0.5576 / 0.4460\n",
            "[3/200][244/391] Loss_D: 1.4002 Loss_G: 0.5979 D(x): 0.4460 D(G(z)): 0.4460 / 0.5506\n",
            "[3/200][245/391] Loss_D: 1.3987 Loss_G: 0.7936 D(x): 0.5506 D(G(z)): 0.5506 / 0.4527\n",
            "[3/200][246/391] Loss_D: 1.3974 Loss_G: 0.6095 D(x): 0.4527 D(G(z)): 0.4527 / 0.5442\n",
            "[3/200][247/391] Loss_D: 1.3963 Loss_G: 0.7805 D(x): 0.5442 D(G(z)): 0.5442 / 0.4587\n",
            "[3/200][248/391] Loss_D: 1.3952 Loss_G: 0.6198 D(x): 0.4587 D(G(z)): 0.4587 / 0.5386\n",
            "[3/200][249/391] Loss_D: 1.3944 Loss_G: 0.7691 D(x): 0.5386 D(G(z)): 0.5386 / 0.4639\n",
            "[3/200][250/391] Loss_D: 1.3936 Loss_G: 0.6284 D(x): 0.4639 D(G(z)): 0.4639 / 0.5340\n",
            "[3/200][251/391] Loss_D: 1.3930 Loss_G: 0.7606 D(x): 0.5340 D(G(z)): 0.5340 / 0.4678\n",
            "[3/200][252/391] Loss_D: 1.3925 Loss_G: 0.6348 D(x): 0.4678 D(G(z)): 0.4678 / 0.5306\n",
            "[3/200][253/391] Loss_D: 1.3921 Loss_G: 0.7544 D(x): 0.5306 D(G(z)): 0.5306 / 0.4708\n",
            "[3/200][254/391] Loss_D: 1.3917 Loss_G: 0.6395 D(x): 0.4708 D(G(z)): 0.4708 / 0.5281\n",
            "[3/200][255/391] Loss_D: 1.3914 Loss_G: 0.7497 D(x): 0.5281 D(G(z)): 0.5281 / 0.4730\n",
            "[3/200][256/391] Loss_D: 1.3912 Loss_G: 0.6432 D(x): 0.4730 D(G(z)): 0.4730 / 0.5261\n",
            "[3/200][257/391] Loss_D: 1.3910 Loss_G: 0.7462 D(x): 0.5261 D(G(z)): 0.5262 / 0.4746\n",
            "[3/200][258/391] Loss_D: 1.3908 Loss_G: 0.6459 D(x): 0.4746 D(G(z)): 0.4746 / 0.5247\n",
            "[3/200][259/391] Loss_D: 1.3907 Loss_G: 0.7435 D(x): 0.5247 D(G(z)): 0.5247 / 0.4759\n",
            "[3/200][260/391] Loss_D: 1.3905 Loss_G: 0.6480 D(x): 0.4759 D(G(z)): 0.4759 / 0.5236\n",
            "[3/200][261/391] Loss_D: 1.3904 Loss_G: 0.7415 D(x): 0.5236 D(G(z)): 0.5236 / 0.4769\n",
            "[3/200][262/391] Loss_D: 1.3903 Loss_G: 0.6495 D(x): 0.4768 D(G(z)): 0.4768 / 0.5228\n",
            "[3/200][263/391] Loss_D: 1.3902 Loss_G: 0.7402 D(x): 0.5228 D(G(z)): 0.5228 / 0.4775\n",
            "[3/200][264/391] Loss_D: 1.3902 Loss_G: 0.6504 D(x): 0.4775 D(G(z)): 0.4775 / 0.5223\n",
            "[3/200][265/391] Loss_D: 1.3901 Loss_G: 0.7394 D(x): 0.5223 D(G(z)): 0.5223 / 0.4778\n",
            "[3/200][266/391] Loss_D: 1.3901 Loss_G: 0.6508 D(x): 0.4778 D(G(z)): 0.4778 / 0.5221\n",
            "[3/200][267/391] Loss_D: 1.3901 Loss_G: 0.7392 D(x): 0.5221 D(G(z)): 0.5221 / 0.4779\n",
            "[3/200][268/391] Loss_D: 1.3900 Loss_G: 0.6507 D(x): 0.4779 D(G(z)): 0.4779 / 0.5221\n",
            "[3/200][269/391] Loss_D: 1.3901 Loss_G: 0.7395 D(x): 0.5221 D(G(z)): 0.5221 / 0.4778\n",
            "[3/200][270/391] Loss_D: 1.3901 Loss_G: 0.6502 D(x): 0.4778 D(G(z)): 0.4777 / 0.5224\n",
            "[3/200][271/391] Loss_D: 1.3901 Loss_G: 0.7404 D(x): 0.5224 D(G(z)): 0.5224 / 0.4773\n",
            "[3/200][272/391] Loss_D: 1.3901 Loss_G: 0.6491 D(x): 0.4773 D(G(z)): 0.4773 / 0.5230\n",
            "[3/200][273/391] Loss_D: 1.3902 Loss_G: 0.7418 D(x): 0.5230 D(G(z)): 0.5230 / 0.4767\n",
            "[3/200][274/391] Loss_D: 1.3902 Loss_G: 0.6476 D(x): 0.4767 D(G(z)): 0.4767 / 0.5238\n",
            "[3/200][275/391] Loss_D: 1.3903 Loss_G: 0.7438 D(x): 0.5238 D(G(z)): 0.5238 / 0.4757\n",
            "[3/200][276/391] Loss_D: 1.3904 Loss_G: 0.6455 D(x): 0.4757 D(G(z)): 0.4757 / 0.5249\n",
            "[3/200][277/391] Loss_D: 1.3905 Loss_G: 0.7464 D(x): 0.5249 D(G(z)): 0.5249 / 0.4745\n",
            "[3/200][278/391] Loss_D: 1.3906 Loss_G: 0.6429 D(x): 0.4745 D(G(z)): 0.4745 / 0.5262\n",
            "[3/200][279/391] Loss_D: 1.3908 Loss_G: 0.7496 D(x): 0.5262 D(G(z)): 0.5262 / 0.4730\n",
            "[3/200][280/391] Loss_D: 1.3909 Loss_G: 0.6396 D(x): 0.4730 D(G(z)): 0.4729 / 0.5279\n",
            "[3/200][281/391] Loss_D: 1.3911 Loss_G: 0.7535 D(x): 0.5279 D(G(z)): 0.5279 / 0.4711\n",
            "[3/200][282/391] Loss_D: 1.3913 Loss_G: 0.6358 D(x): 0.4711 D(G(z)): 0.4711 / 0.5300\n",
            "[3/200][283/391] Loss_D: 1.3916 Loss_G: 0.7582 D(x): 0.5300 D(G(z)): 0.5300 / 0.4689\n",
            "[3/200][284/391] Loss_D: 1.3918 Loss_G: 0.6313 D(x): 0.4689 D(G(z)): 0.4689 / 0.5324\n",
            "[3/200][285/391] Loss_D: 1.3922 Loss_G: 0.7637 D(x): 0.5324 D(G(z)): 0.5324 / 0.4663\n",
            "[3/200][286/391] Loss_D: 1.3925 Loss_G: 0.6262 D(x): 0.4663 D(G(z)): 0.4663 / 0.5351\n",
            "[3/200][287/391] Loss_D: 1.3929 Loss_G: 0.7700 D(x): 0.5351 D(G(z)): 0.5351 / 0.4634\n",
            "[3/200][288/391] Loss_D: 1.3933 Loss_G: 0.6202 D(x): 0.4634 D(G(z)): 0.4634 / 0.5383\n",
            "[3/200][289/391] Loss_D: 1.3938 Loss_G: 0.7773 D(x): 0.5383 D(G(z)): 0.5383 / 0.4600\n",
            "[3/200][290/391] Loss_D: 1.3943 Loss_G: 0.6137 D(x): 0.4600 D(G(z)): 0.4600 / 0.5418\n",
            "[3/200][291/391] Loss_D: 1.3949 Loss_G: 0.7853 D(x): 0.5418 D(G(z)): 0.5418 / 0.4564\n",
            "[3/200][292/391] Loss_D: 1.3956 Loss_G: 0.6030 D(x): 0.4564 D(G(z)): 0.4564 / 0.5476\n",
            "[3/200][293/391] Loss_D: 1.3972 Loss_G: 0.8020 D(x): 0.5477 D(G(z)): 0.5477 / 0.4488\n",
            "[3/200][294/391] Loss_D: 1.3985 Loss_G: 0.5894 D(x): 0.4488 D(G(z)): 0.4489 / 0.5552\n",
            "[3/200][295/391] Loss_D: 1.4004 Loss_G: 0.8220 D(x): 0.5552 D(G(z)): 0.5553 / 0.4399\n",
            "[3/200][296/391] Loss_D: 1.4025 Loss_G: 0.5721 D(x): 0.4399 D(G(z)): 0.4400 / 0.5648\n",
            "[3/200][297/391] Loss_D: 1.4051 Loss_G: 0.8445 D(x): 0.5649 D(G(z)): 0.5649 / 0.4301\n",
            "[3/200][298/391] Loss_D: 1.4077 Loss_G: 0.5553 D(x): 0.4301 D(G(z)): 0.4301 / 0.5744\n",
            "[3/200][299/391] Loss_D: 1.4105 Loss_G: 0.8651 D(x): 0.5744 D(G(z)): 0.5744 / 0.4214\n",
            "[3/200][300/391] Loss_D: 1.4131 Loss_G: 0.5426 D(x): 0.4214 D(G(z)): 0.4214 / 0.5817\n",
            "[3/200][301/391] Loss_D: 1.4152 Loss_G: 0.8842 D(x): 0.5818 D(G(z)): 0.5818 / 0.4134\n",
            "[3/200][302/391] Loss_D: 1.4185 Loss_G: 0.5268 D(x): 0.4134 D(G(z)): 0.4133 / 0.5910\n",
            "[3/200][303/391] Loss_D: 1.4218 Loss_G: 0.9029 D(x): 0.5910 D(G(z)): 0.5910 / 0.4057\n",
            "[3/200][304/391] Loss_D: 1.4242 Loss_G: 0.5196 D(x): 0.4057 D(G(z)): 0.4057 / 0.5953\n",
            "[3/200][305/391] Loss_D: 1.4251 Loss_G: 0.9026 D(x): 0.5953 D(G(z)): 0.5953 / 0.4059\n",
            "[3/200][306/391] Loss_D: 1.4242 Loss_G: 0.5263 D(x): 0.4059 D(G(z)): 0.4059 / 0.5913\n",
            "[3/200][307/391] Loss_D: 1.4221 Loss_G: 0.8865 D(x): 0.5913 D(G(z)): 0.5913 / 0.4125\n",
            "[3/200][308/391] Loss_D: 1.4192 Loss_G: 0.5402 D(x): 0.4124 D(G(z)): 0.4124 / 0.5832\n",
            "[3/200][309/391] Loss_D: 1.4162 Loss_G: 0.8649 D(x): 0.5832 D(G(z)): 0.5832 / 0.4215\n",
            "[3/200][310/391] Loss_D: 1.4131 Loss_G: 0.5565 D(x): 0.4215 D(G(z)): 0.4214 / 0.5738\n",
            "[3/200][311/391] Loss_D: 1.4102 Loss_G: 0.8426 D(x): 0.5738 D(G(z)): 0.5738 / 0.4310\n",
            "[3/200][312/391] Loss_D: 1.4074 Loss_G: 0.5728 D(x): 0.4310 D(G(z)): 0.4310 / 0.5644\n",
            "[3/200][313/391] Loss_D: 1.4050 Loss_G: 0.8218 D(x): 0.5645 D(G(z)): 0.5645 / 0.4400\n",
            "[3/200][314/391] Loss_D: 1.4027 Loss_G: 0.5881 D(x): 0.4400 D(G(z)): 0.4400 / 0.5559\n",
            "[3/200][315/391] Loss_D: 1.4008 Loss_G: 0.8033 D(x): 0.5559 D(G(z)): 0.5559 / 0.4483\n",
            "[3/200][316/391] Loss_D: 1.3989 Loss_G: 0.6021 D(x): 0.4483 D(G(z)): 0.4483 / 0.5482\n",
            "[3/200][317/391] Loss_D: 1.3975 Loss_G: 0.7888 D(x): 0.5482 D(G(z)): 0.5482 / 0.4548\n",
            "[3/200][318/391] Loss_D: 1.3963 Loss_G: 0.6126 D(x): 0.4548 D(G(z)): 0.4548 / 0.5425\n",
            "[3/200][319/391] Loss_D: 1.3954 Loss_G: 0.7775 D(x): 0.5425 D(G(z)): 0.5425 / 0.4600\n",
            "[3/200][320/391] Loss_D: 1.3946 Loss_G: 0.6212 D(x): 0.4600 D(G(z)): 0.4600 / 0.5378\n",
            "[3/200][321/391] Loss_D: 1.3939 Loss_G: 0.7685 D(x): 0.5378 D(G(z)): 0.5378 / 0.4641\n",
            "[3/200][322/391] Loss_D: 1.3933 Loss_G: 0.6282 D(x): 0.4641 D(G(z)): 0.4641 / 0.5341\n",
            "[3/200][323/391] Loss_D: 1.3928 Loss_G: 0.7611 D(x): 0.5341 D(G(z)): 0.5341 / 0.4676\n",
            "[3/200][324/391] Loss_D: 1.3923 Loss_G: 0.6340 D(x): 0.4676 D(G(z)): 0.4676 / 0.5309\n",
            "[3/200][325/391] Loss_D: 1.3919 Loss_G: 0.7550 D(x): 0.5309 D(G(z)): 0.5309 / 0.4704\n",
            "[3/200][326/391] Loss_D: 1.3916 Loss_G: 0.6388 D(x): 0.4704 D(G(z)): 0.4704 / 0.5284\n",
            "[3/200][327/391] Loss_D: 1.3913 Loss_G: 0.7502 D(x): 0.5284 D(G(z)): 0.5284 / 0.4727\n",
            "[3/200][328/391] Loss_D: 1.3910 Loss_G: 0.6426 D(x): 0.4727 D(G(z)): 0.4727 / 0.5264\n",
            "[3/200][329/391] Loss_D: 1.3908 Loss_G: 0.7464 D(x): 0.5264 D(G(z)): 0.5264 / 0.4745\n",
            "[3/200][330/391] Loss_D: 1.3906 Loss_G: 0.6456 D(x): 0.4745 D(G(z)): 0.4745 / 0.5248\n",
            "[3/200][331/391] Loss_D: 1.3905 Loss_G: 0.7435 D(x): 0.5248 D(G(z)): 0.5248 / 0.4759\n",
            "[3/200][332/391] Loss_D: 1.3903 Loss_G: 0.6479 D(x): 0.4759 D(G(z)): 0.4758 / 0.5236\n",
            "[3/200][333/391] Loss_D: 1.3902 Loss_G: 0.7413 D(x): 0.5236 D(G(z)): 0.5236 / 0.4769\n",
            "[3/200][334/391] Loss_D: 1.3901 Loss_G: 0.6495 D(x): 0.4769 D(G(z)): 0.4769 / 0.5228\n",
            "[3/200][335/391] Loss_D: 1.3900 Loss_G: 0.7400 D(x): 0.5228 D(G(z)): 0.5228 / 0.4775\n",
            "[3/200][336/391] Loss_D: 1.3900 Loss_G: 0.6503 D(x): 0.4775 D(G(z)): 0.4775 / 0.5223\n",
            "[3/200][337/391] Loss_D: 1.3899 Loss_G: 0.7393 D(x): 0.5223 D(G(z)): 0.5223 / 0.4778\n",
            "[3/200][338/391] Loss_D: 1.3899 Loss_G: 0.6506 D(x): 0.4778 D(G(z)): 0.4778 / 0.5221\n",
            "[3/200][339/391] Loss_D: 1.3899 Loss_G: 0.7392 D(x): 0.5221 D(G(z)): 0.5221 / 0.4779\n",
            "[3/200][340/391] Loss_D: 1.3899 Loss_G: 0.6505 D(x): 0.4779 D(G(z)): 0.4778 / 0.5222\n",
            "[3/200][341/391] Loss_D: 1.3899 Loss_G: 0.7397 D(x): 0.5222 D(G(z)): 0.5222 / 0.4776\n",
            "[3/200][342/391] Loss_D: 1.3899 Loss_G: 0.6498 D(x): 0.4776 D(G(z)): 0.4776 / 0.5226\n",
            "[3/200][343/391] Loss_D: 1.3899 Loss_G: 0.7407 D(x): 0.5226 D(G(z)): 0.5226 / 0.4772\n",
            "[3/200][344/391] Loss_D: 1.3899 Loss_G: 0.6486 D(x): 0.4771 D(G(z)): 0.4771 / 0.5232\n",
            "[3/200][345/391] Loss_D: 1.3900 Loss_G: 0.7423 D(x): 0.5232 D(G(z)): 0.5232 / 0.4764\n",
            "[3/200][346/391] Loss_D: 1.3901 Loss_G: 0.6469 D(x): 0.4764 D(G(z)): 0.4764 / 0.5241\n",
            "[3/200][347/391] Loss_D: 1.3902 Loss_G: 0.7444 D(x): 0.5241 D(G(z)): 0.5241 / 0.4754\n",
            "[3/200][348/391] Loss_D: 1.3903 Loss_G: 0.6447 D(x): 0.4754 D(G(z)): 0.4754 / 0.5252\n",
            "[3/200][349/391] Loss_D: 1.3904 Loss_G: 0.7471 D(x): 0.5252 D(G(z)): 0.5252 / 0.4741\n",
            "[3/200][350/391] Loss_D: 1.3905 Loss_G: 0.6419 D(x): 0.4741 D(G(z)): 0.4741 / 0.5267\n",
            "[3/200][351/391] Loss_D: 1.3907 Loss_G: 0.7508 D(x): 0.5267 D(G(z)): 0.5267 / 0.4724\n",
            "[3/200][352/391] Loss_D: 1.3909 Loss_G: 0.6382 D(x): 0.4724 D(G(z)): 0.4724 / 0.5286\n",
            "[3/200][353/391] Loss_D: 1.3911 Loss_G: 0.7551 D(x): 0.5286 D(G(z)): 0.5286 / 0.4703\n",
            "[3/200][354/391] Loss_D: 1.3913 Loss_G: 0.6341 D(x): 0.4703 D(G(z)): 0.4703 / 0.5308\n",
            "[3/200][355/391] Loss_D: 1.3916 Loss_G: 0.7602 D(x): 0.5308 D(G(z)): 0.5308 / 0.4679\n",
            "[3/200][356/391] Loss_D: 1.3919 Loss_G: 0.6292 D(x): 0.4679 D(G(z)): 0.4679 / 0.5334\n",
            "[3/200][357/391] Loss_D: 1.3923 Loss_G: 0.7661 D(x): 0.5334 D(G(z)): 0.5334 / 0.4652\n",
            "[3/200][358/391] Loss_D: 1.3926 Loss_G: 0.6213 D(x): 0.4652 D(G(z)): 0.4652 / 0.5376\n",
            "[3/200][359/391] Loss_D: 1.3936 Loss_G: 0.7776 D(x): 0.5377 D(G(z)): 0.5377 / 0.4599\n",
            "[3/200][360/391] Loss_D: 1.3944 Loss_G: 0.6121 D(x): 0.4599 D(G(z)): 0.4599 / 0.5427\n",
            "[3/200][361/391] Loss_D: 1.3953 Loss_G: 0.7896 D(x): 0.5427 D(G(z)): 0.5427 / 0.4544\n",
            "[3/200][362/391] Loss_D: 1.3963 Loss_G: 0.6010 D(x): 0.4544 D(G(z)): 0.4544 / 0.5487\n",
            "[3/200][363/391] Loss_D: 1.3975 Loss_G: 0.8043 D(x): 0.5487 D(G(z)): 0.5488 / 0.4478\n",
            "[3/200][364/391] Loss_D: 1.3989 Loss_G: 0.5880 D(x): 0.4478 D(G(z)): 0.4478 / 0.5559\n",
            "[3/200][365/391] Loss_D: 1.4005 Loss_G: 0.8209 D(x): 0.5559 D(G(z)): 0.5559 / 0.4404\n",
            "[3/200][366/391] Loss_D: 1.4022 Loss_G: 0.5750 D(x): 0.4404 D(G(z)): 0.4404 / 0.5632\n",
            "[3/200][367/391] Loss_D: 1.4040 Loss_G: 0.8366 D(x): 0.5632 D(G(z)): 0.5632 / 0.4335\n",
            "[3/200][368/391] Loss_D: 1.4057 Loss_G: 0.5640 D(x): 0.4335 D(G(z)): 0.4335 / 0.5694\n",
            "[3/200][369/391] Loss_D: 1.4074 Loss_G: 0.8493 D(x): 0.5694 D(G(z)): 0.5694 / 0.4281\n",
            "[3/200][370/391] Loss_D: 1.4088 Loss_G: 0.5561 D(x): 0.4281 D(G(z)): 0.4281 / 0.5739\n",
            "[3/200][371/391] Loss_D: 1.4100 Loss_G: 0.8576 D(x): 0.5739 D(G(z)): 0.5739 / 0.4245\n",
            "[3/200][372/391] Loss_D: 1.4109 Loss_G: 0.5515 D(x): 0.4245 D(G(z)): 0.4245 / 0.5765\n",
            "[3/200][373/391] Loss_D: 1.4116 Loss_G: 0.8611 D(x): 0.5765 D(G(z)): 0.5765 / 0.4230\n",
            "[3/200][374/391] Loss_D: 1.4119 Loss_G: 0.5512 D(x): 0.4230 D(G(z)): 0.4230 / 0.5767\n",
            "[3/200][375/391] Loss_D: 1.4117 Loss_G: 0.8582 D(x): 0.5767 D(G(z)): 0.5767 / 0.4243\n",
            "[3/200][376/391] Loss_D: 1.4111 Loss_G: 0.5559 D(x): 0.4243 D(G(z)): 0.4243 / 0.5740\n",
            "[3/200][377/391] Loss_D: 1.4101 Loss_G: 0.8488 D(x): 0.5740 D(G(z)): 0.5740 / 0.4283\n",
            "[3/200][378/391] Loss_D: 1.4087 Loss_G: 0.5644 D(x): 0.4282 D(G(z)): 0.4282 / 0.5691\n",
            "[3/200][379/391] Loss_D: 1.4072 Loss_G: 0.8361 D(x): 0.5691 D(G(z)): 0.5691 / 0.4338\n",
            "[3/200][380/391] Loss_D: 1.4056 Loss_G: 0.5750 D(x): 0.4337 D(G(z)): 0.4337 / 0.5631\n",
            "[3/200][381/391] Loss_D: 1.4040 Loss_G: 0.8221 D(x): 0.5632 D(G(z)): 0.5632 / 0.4399\n",
            "[3/200][382/391] Loss_D: 1.4025 Loss_G: 0.5855 D(x): 0.4398 D(G(z)): 0.4398 / 0.5573\n",
            "[3/200][383/391] Loss_D: 1.4011 Loss_G: 0.8079 D(x): 0.5573 D(G(z)): 0.5573 / 0.4462\n",
            "[3/200][384/391] Loss_D: 1.3996 Loss_G: 0.5969 D(x): 0.4462 D(G(z)): 0.4462 / 0.5510\n",
            "[3/200][385/391] Loss_D: 1.3984 Loss_G: 0.7969 D(x): 0.5510 D(G(z)): 0.5510 / 0.4511\n",
            "[3/200][386/391] Loss_D: 1.3975 Loss_G: 0.6034 D(x): 0.4511 D(G(z)): 0.4511 / 0.5474\n",
            "[3/200][387/391] Loss_D: 1.3969 Loss_G: 0.7907 D(x): 0.5474 D(G(z)): 0.5474 / 0.4539\n",
            "[3/200][388/391] Loss_D: 1.3964 Loss_G: 0.6077 D(x): 0.4539 D(G(z)): 0.4539 / 0.5451\n",
            "[3/200][389/391] Loss_D: 1.3961 Loss_G: 0.7865 D(x): 0.5451 D(G(z)): 0.5451 / 0.4558\n",
            "[3/200][390/391] Loss_D: 1.3957 Loss_G: 0.6106 D(x): 0.4558 D(G(z)): 0.4558 / 0.5434\n",
            "[4/200][0/391] Loss_D: 1.3955 Loss_G: 0.7833 D(x): 0.5434 D(G(z)): 0.5434 / 0.4573\n",
            "[4/200][1/391] Loss_D: 1.3952 Loss_G: 0.6132 D(x): 0.4573 D(G(z)): 0.4572 / 0.5420\n",
            "[4/200][2/391] Loss_D: 1.3950 Loss_G: 0.7802 D(x): 0.5421 D(G(z)): 0.5421 / 0.4587\n",
            "[4/200][3/391] Loss_D: 1.3947 Loss_G: 0.6157 D(x): 0.4586 D(G(z)): 0.4586 / 0.5407\n",
            "[4/200][4/391] Loss_D: 1.3945 Loss_G: 0.7773 D(x): 0.5407 D(G(z)): 0.5407 / 0.4600\n",
            "[4/200][5/391] Loss_D: 1.3942 Loss_G: 0.6182 D(x): 0.4600 D(G(z)): 0.4600 / 0.5393\n",
            "[4/200][6/391] Loss_D: 1.3940 Loss_G: 0.7747 D(x): 0.5393 D(G(z)): 0.5393 / 0.4612\n",
            "[4/200][7/391] Loss_D: 1.3939 Loss_G: 0.6200 D(x): 0.4612 D(G(z)): 0.4612 / 0.5384\n",
            "[4/200][8/391] Loss_D: 1.3937 Loss_G: 0.7728 D(x): 0.5384 D(G(z)): 0.5384 / 0.4621\n",
            "[4/200][9/391] Loss_D: 1.3936 Loss_G: 0.6214 D(x): 0.4620 D(G(z)): 0.4620 / 0.5376\n",
            "[4/200][10/391] Loss_D: 1.3935 Loss_G: 0.7713 D(x): 0.5376 D(G(z)): 0.5376 / 0.4627\n",
            "[4/200][11/391] Loss_D: 1.3934 Loss_G: 0.6225 D(x): 0.4627 D(G(z)): 0.4627 / 0.5370\n",
            "[4/200][12/391] Loss_D: 1.3933 Loss_G: 0.7702 D(x): 0.5370 D(G(z)): 0.5370 / 0.4633\n",
            "[4/200][13/391] Loss_D: 1.3932 Loss_G: 0.6234 D(x): 0.4633 D(G(z)): 0.4633 / 0.5365\n",
            "[4/200][14/391] Loss_D: 1.3931 Loss_G: 0.7693 D(x): 0.5365 D(G(z)): 0.5365 / 0.4637\n",
            "[4/200][15/391] Loss_D: 1.3931 Loss_G: 0.6240 D(x): 0.4637 D(G(z)): 0.4636 / 0.5362\n",
            "[4/200][16/391] Loss_D: 1.3930 Loss_G: 0.7689 D(x): 0.5362 D(G(z)): 0.5362 / 0.4639\n",
            "[4/200][17/391] Loss_D: 1.3930 Loss_G: 0.6242 D(x): 0.4639 D(G(z)): 0.4639 / 0.5361\n",
            "[4/200][18/391] Loss_D: 1.3930 Loss_G: 0.7687 D(x): 0.5361 D(G(z)): 0.5361 / 0.4639\n",
            "[4/200][19/391] Loss_D: 1.3930 Loss_G: 0.6242 D(x): 0.4639 D(G(z)): 0.4639 / 0.5361\n",
            "[4/200][20/391] Loss_D: 1.3930 Loss_G: 0.7690 D(x): 0.5361 D(G(z)): 0.5361 / 0.4638\n",
            "[4/200][21/391] Loss_D: 1.3930 Loss_G: 0.6238 D(x): 0.4638 D(G(z)): 0.4638 / 0.5363\n",
            "[4/200][22/391] Loss_D: 1.3930 Loss_G: 0.7696 D(x): 0.5363 D(G(z)): 0.5363 / 0.4636\n",
            "[4/200][23/391] Loss_D: 1.3931 Loss_G: 0.6231 D(x): 0.4635 D(G(z)): 0.4635 / 0.5366\n",
            "[4/200][24/391] Loss_D: 1.3931 Loss_G: 0.7705 D(x): 0.5367 D(G(z)): 0.5367 / 0.4631\n",
            "[4/200][25/391] Loss_D: 1.3932 Loss_G: 0.6221 D(x): 0.4631 D(G(z)): 0.4631 / 0.5372\n",
            "[4/200][26/391] Loss_D: 1.3933 Loss_G: 0.7720 D(x): 0.5372 D(G(z)): 0.5372 / 0.4624\n",
            "[4/200][27/391] Loss_D: 1.3934 Loss_G: 0.6206 D(x): 0.4624 D(G(z)): 0.4624 / 0.5380\n",
            "[4/200][28/391] Loss_D: 1.3935 Loss_G: 0.7738 D(x): 0.5380 D(G(z)): 0.5380 / 0.4616\n",
            "[4/200][29/391] Loss_D: 1.3936 Loss_G: 0.6189 D(x): 0.4616 D(G(z)): 0.4616 / 0.5389\n",
            "[4/200][30/391] Loss_D: 1.3938 Loss_G: 0.7760 D(x): 0.5389 D(G(z)): 0.5389 / 0.4606\n",
            "[4/200][31/391] Loss_D: 1.3939 Loss_G: 0.6169 D(x): 0.4606 D(G(z)): 0.4606 / 0.5400\n",
            "[4/200][32/391] Loss_D: 1.3941 Loss_G: 0.7785 D(x): 0.5400 D(G(z)): 0.5400 / 0.4594\n",
            "[4/200][33/391] Loss_D: 1.3943 Loss_G: 0.6147 D(x): 0.4594 D(G(z)): 0.4594 / 0.5412\n",
            "[4/200][34/391] Loss_D: 1.3945 Loss_G: 0.7813 D(x): 0.5412 D(G(z)): 0.5412 / 0.4582\n",
            "[4/200][35/391] Loss_D: 1.3947 Loss_G: 0.6124 D(x): 0.4581 D(G(z)): 0.4581 / 0.5424\n",
            "[4/200][36/391] Loss_D: 1.3949 Loss_G: 0.7838 D(x): 0.5425 D(G(z)): 0.5425 / 0.4570\n",
            "[4/200][37/391] Loss_D: 1.3951 Loss_G: 0.6102 D(x): 0.4570 D(G(z)): 0.4570 / 0.5436\n",
            "[4/200][38/391] Loss_D: 1.3953 Loss_G: 0.7862 D(x): 0.5436 D(G(z)): 0.5436 / 0.4559\n",
            "[4/200][39/391] Loss_D: 1.3955 Loss_G: 0.6084 D(x): 0.4559 D(G(z)): 0.4559 / 0.5446\n",
            "[4/200][40/391] Loss_D: 1.3957 Loss_G: 0.7882 D(x): 0.5446 D(G(z)): 0.5446 / 0.4550\n",
            "[4/200][41/391] Loss_D: 1.3958 Loss_G: 0.6069 D(x): 0.4550 D(G(z)): 0.4550 / 0.5454\n",
            "[4/200][42/391] Loss_D: 1.3960 Loss_G: 0.7899 D(x): 0.5454 D(G(z)): 0.5454 / 0.4542\n",
            "[4/200][43/391] Loss_D: 1.3961 Loss_G: 0.6056 D(x): 0.4542 D(G(z)): 0.4542 / 0.5461\n",
            "[4/200][44/391] Loss_D: 1.3962 Loss_G: 0.7914 D(x): 0.5461 D(G(z)): 0.5461 / 0.4535\n",
            "[4/200][45/391] Loss_D: 1.3963 Loss_G: 0.6044 D(x): 0.4535 D(G(z)): 0.4535 / 0.5468\n",
            "[4/200][46/391] Loss_D: 1.3965 Loss_G: 0.7925 D(x): 0.5468 D(G(z)): 0.5468 / 0.4530\n",
            "[4/200][47/391] Loss_D: 1.3965 Loss_G: 0.6036 D(x): 0.4530 D(G(z)): 0.4530 / 0.5472\n",
            "[4/200][48/391] Loss_D: 1.3966 Loss_G: 0.7937 D(x): 0.5472 D(G(z)): 0.5472 / 0.4525\n",
            "[4/200][49/391] Loss_D: 1.3967 Loss_G: 0.6022 D(x): 0.4525 D(G(z)): 0.4524 / 0.5480\n",
            "[4/200][50/391] Loss_D: 1.3969 Loss_G: 0.7957 D(x): 0.5480 D(G(z)): 0.5480 / 0.4516\n",
            "[4/200][51/391] Loss_D: 1.3971 Loss_G: 0.6006 D(x): 0.4516 D(G(z)): 0.4516 / 0.5489\n",
            "[4/200][52/391] Loss_D: 1.3973 Loss_G: 0.7976 D(x): 0.5489 D(G(z)): 0.5489 / 0.4507\n",
            "[4/200][53/391] Loss_D: 1.3974 Loss_G: 0.5990 D(x): 0.4507 D(G(z)): 0.4507 / 0.5497\n",
            "[4/200][54/391] Loss_D: 1.3976 Loss_G: 0.7997 D(x): 0.5497 D(G(z)): 0.5497 / 0.4498\n",
            "[4/200][55/391] Loss_D: 1.3978 Loss_G: 0.5968 D(x): 0.4498 D(G(z)): 0.4498 / 0.5509\n",
            "[4/200][56/391] Loss_D: 1.3981 Loss_G: 0.8033 D(x): 0.5510 D(G(z)): 0.5510 / 0.4481\n",
            "[4/200][57/391] Loss_D: 1.3985 Loss_G: 0.5935 D(x): 0.4481 D(G(z)): 0.4481 / 0.5527\n",
            "[4/200][58/391] Loss_D: 1.3989 Loss_G: 0.8076 D(x): 0.5528 D(G(z)): 0.5528 / 0.4463\n",
            "[4/200][59/391] Loss_D: 1.3993 Loss_G: 0.5900 D(x): 0.4462 D(G(z)): 0.4462 / 0.5547\n",
            "[4/200][60/391] Loss_D: 1.3997 Loss_G: 0.8117 D(x): 0.5547 D(G(z)): 0.5547 / 0.4444\n",
            "[4/200][61/391] Loss_D: 1.4001 Loss_G: 0.5870 D(x): 0.4444 D(G(z)): 0.4444 / 0.5563\n",
            "[4/200][62/391] Loss_D: 1.4004 Loss_G: 0.8152 D(x): 0.5564 D(G(z)): 0.5564 / 0.4428\n",
            "[4/200][63/391] Loss_D: 1.4008 Loss_G: 0.5843 D(x): 0.4428 D(G(z)): 0.4428 / 0.5579\n",
            "[4/200][64/391] Loss_D: 1.4012 Loss_G: 0.8182 D(x): 0.5579 D(G(z)): 0.5579 / 0.4415\n",
            "[4/200][65/391] Loss_D: 1.4014 Loss_G: 0.5824 D(x): 0.4415 D(G(z)): 0.4415 / 0.5589\n",
            "[4/200][66/391] Loss_D: 1.4017 Loss_G: 0.8199 D(x): 0.5589 D(G(z)): 0.5589 / 0.4408\n",
            "[4/200][67/391] Loss_D: 1.4018 Loss_G: 0.5814 D(x): 0.4408 D(G(z)): 0.4407 / 0.5595\n",
            "[4/200][68/391] Loss_D: 1.4019 Loss_G: 0.8206 D(x): 0.5595 D(G(z)): 0.5595 / 0.4405\n",
            "[4/200][69/391] Loss_D: 1.4019 Loss_G: 0.5818 D(x): 0.4404 D(G(z)): 0.4404 / 0.5593\n",
            "[4/200][70/391] Loss_D: 1.4018 Loss_G: 0.8183 D(x): 0.5593 D(G(z)): 0.5593 / 0.4415\n",
            "[4/200][71/391] Loss_D: 1.4014 Loss_G: 0.5846 D(x): 0.4415 D(G(z)): 0.4415 / 0.5577\n",
            "[4/200][72/391] Loss_D: 1.4011 Loss_G: 0.8145 D(x): 0.5577 D(G(z)): 0.5577 / 0.4432\n",
            "[4/200][73/391] Loss_D: 1.4007 Loss_G: 0.5879 D(x): 0.4432 D(G(z)): 0.4431 / 0.5559\n",
            "[4/200][74/391] Loss_D: 1.4003 Loss_G: 0.8102 D(x): 0.5559 D(G(z)): 0.5559 / 0.4451\n",
            "[4/200][75/391] Loss_D: 1.3998 Loss_G: 0.5915 D(x): 0.4451 D(G(z)): 0.4451 / 0.5539\n",
            "[4/200][76/391] Loss_D: 1.3994 Loss_G: 0.8055 D(x): 0.5539 D(G(z)): 0.5539 / 0.4472\n",
            "[4/200][77/391] Loss_D: 1.3989 Loss_G: 0.5953 D(x): 0.4472 D(G(z)): 0.4471 / 0.5518\n",
            "[4/200][78/391] Loss_D: 1.3985 Loss_G: 0.8008 D(x): 0.5518 D(G(z)): 0.5518 / 0.4493\n",
            "[4/200][79/391] Loss_D: 1.3980 Loss_G: 0.5992 D(x): 0.4493 D(G(z)): 0.4493 / 0.5496\n",
            "[4/200][80/391] Loss_D: 1.3976 Loss_G: 0.7960 D(x): 0.5496 D(G(z)): 0.5496 / 0.4515\n",
            "[4/200][81/391] Loss_D: 1.3971 Loss_G: 0.6031 D(x): 0.4514 D(G(z)): 0.4514 / 0.5475\n",
            "[4/200][82/391] Loss_D: 1.3967 Loss_G: 0.7914 D(x): 0.5475 D(G(z)): 0.5475 / 0.4535\n",
            "[4/200][83/391] Loss_D: 1.3963 Loss_G: 0.6067 D(x): 0.4535 D(G(z)): 0.4535 / 0.5455\n",
            "[4/200][84/391] Loss_D: 1.3960 Loss_G: 0.7871 D(x): 0.5455 D(G(z)): 0.5455 / 0.4555\n",
            "[4/200][85/391] Loss_D: 1.3956 Loss_G: 0.6102 D(x): 0.4554 D(G(z)): 0.4554 / 0.5436\n",
            "[4/200][86/391] Loss_D: 1.3953 Loss_G: 0.7830 D(x): 0.5436 D(G(z)): 0.5436 / 0.4573\n",
            "[4/200][87/391] Loss_D: 1.3949 Loss_G: 0.6134 D(x): 0.4573 D(G(z)): 0.4573 / 0.5419\n",
            "[4/200][88/391] Loss_D: 1.3947 Loss_G: 0.7796 D(x): 0.5419 D(G(z)): 0.5419 / 0.4589\n",
            "[4/200][89/391] Loss_D: 1.3944 Loss_G: 0.6160 D(x): 0.4589 D(G(z)): 0.4589 / 0.5404\n",
            "[4/200][90/391] Loss_D: 1.3942 Loss_G: 0.7768 D(x): 0.5405 D(G(z)): 0.5405 / 0.4602\n",
            "[4/200][91/391] Loss_D: 1.3940 Loss_G: 0.6182 D(x): 0.4602 D(G(z)): 0.4602 / 0.5393\n",
            "[4/200][92/391] Loss_D: 1.3938 Loss_G: 0.7746 D(x): 0.5393 D(G(z)): 0.5393 / 0.4612\n",
            "[4/200][93/391] Loss_D: 1.3937 Loss_G: 0.6199 D(x): 0.4612 D(G(z)): 0.4612 / 0.5384\n",
            "[4/200][94/391] Loss_D: 1.3935 Loss_G: 0.7728 D(x): 0.5384 D(G(z)): 0.5384 / 0.4620\n",
            "[4/200][95/391] Loss_D: 1.3934 Loss_G: 0.6211 D(x): 0.4620 D(G(z)): 0.4620 / 0.5377\n",
            "[4/200][96/391] Loss_D: 1.3933 Loss_G: 0.7716 D(x): 0.5377 D(G(z)): 0.5377 / 0.4626\n",
            "[4/200][97/391] Loss_D: 1.3932 Loss_G: 0.6220 D(x): 0.4626 D(G(z)): 0.4626 / 0.5372\n",
            "[4/200][98/391] Loss_D: 1.3931 Loss_G: 0.7707 D(x): 0.5372 D(G(z)): 0.5372 / 0.4630\n",
            "[4/200][99/391] Loss_D: 1.3931 Loss_G: 0.6226 D(x): 0.4630 D(G(z)): 0.4630 / 0.5369\n",
            "[4/200][100/391] Loss_D: 1.3931 Loss_G: 0.7704 D(x): 0.5369 D(G(z)): 0.5369 / 0.4631\n",
            "[4/200][101/391] Loss_D: 1.3930 Loss_G: 0.6227 D(x): 0.4631 D(G(z)): 0.4631 / 0.5368\n",
            "[4/200][102/391] Loss_D: 1.3930 Loss_G: 0.7704 D(x): 0.5368 D(G(z)): 0.5368 / 0.4631\n",
            "[4/200][103/391] Loss_D: 1.3930 Loss_G: 0.6225 D(x): 0.4631 D(G(z)): 0.4631 / 0.5370\n",
            "[4/200][104/391] Loss_D: 1.3931 Loss_G: 0.7712 D(x): 0.5370 D(G(z)): 0.5370 / 0.4628\n",
            "[4/200][105/391] Loss_D: 1.3931 Loss_G: 0.6213 D(x): 0.4628 D(G(z)): 0.4628 / 0.5376\n",
            "[4/200][106/391] Loss_D: 1.3932 Loss_G: 0.7729 D(x): 0.5376 D(G(z)): 0.5376 / 0.4620\n",
            "[4/200][107/391] Loss_D: 1.3934 Loss_G: 0.6195 D(x): 0.4620 D(G(z)): 0.4620 / 0.5386\n",
            "[4/200][108/391] Loss_D: 1.3935 Loss_G: 0.7752 D(x): 0.5386 D(G(z)): 0.5386 / 0.4609\n",
            "[4/200][109/391] Loss_D: 1.3937 Loss_G: 0.6173 D(x): 0.4609 D(G(z)): 0.4609 / 0.5397\n",
            "[4/200][110/391] Loss_D: 1.3939 Loss_G: 0.7781 D(x): 0.5397 D(G(z)): 0.5397 / 0.4596\n",
            "[4/200][111/391] Loss_D: 1.3941 Loss_G: 0.6143 D(x): 0.4596 D(G(z)): 0.4596 / 0.5413\n",
            "[4/200][112/391] Loss_D: 1.3944 Loss_G: 0.7823 D(x): 0.5414 D(G(z)): 0.5414 / 0.4576\n",
            "[4/200][113/391] Loss_D: 1.3947 Loss_G: 0.6103 D(x): 0.4576 D(G(z)): 0.4576 / 0.5435\n",
            "[4/200][114/391] Loss_D: 1.3952 Loss_G: 0.7878 D(x): 0.5435 D(G(z)): 0.5436 / 0.4551\n",
            "[4/200][115/391] Loss_D: 1.3956 Loss_G: 0.6052 D(x): 0.4551 D(G(z)): 0.4551 / 0.5463\n",
            "[4/200][116/391] Loss_D: 1.3962 Loss_G: 0.7945 D(x): 0.5463 D(G(z)): 0.5463 / 0.4521\n",
            "[4/200][117/391] Loss_D: 1.3968 Loss_G: 0.5995 D(x): 0.4521 D(G(z)): 0.4521 / 0.5494\n",
            "[4/200][118/391] Loss_D: 1.3974 Loss_G: 0.8015 D(x): 0.5494 D(G(z)): 0.5494 / 0.4489\n",
            "[4/200][119/391] Loss_D: 1.3980 Loss_G: 0.5919 D(x): 0.4489 D(G(z)): 0.4489 / 0.5536\n",
            "[4/200][120/391] Loss_D: 1.3991 Loss_G: 0.8142 D(x): 0.5536 D(G(z)): 0.5537 / 0.4433\n",
            "[4/200][121/391] Loss_D: 1.4005 Loss_G: 0.5807 D(x): 0.4433 D(G(z)): 0.4432 / 0.5599\n",
            "[4/200][122/391] Loss_D: 1.4020 Loss_G: 0.8289 D(x): 0.5599 D(G(z)): 0.5599 / 0.4368\n",
            "[4/200][123/391] Loss_D: 1.4036 Loss_G: 0.5690 D(x): 0.4368 D(G(z)): 0.4368 / 0.5665\n",
            "[4/200][124/391] Loss_D: 1.4054 Loss_G: 0.8434 D(x): 0.5665 D(G(z)): 0.5665 / 0.4305\n",
            "[4/200][125/391] Loss_D: 1.4071 Loss_G: 0.5592 D(x): 0.4305 D(G(z)): 0.4305 / 0.5720\n",
            "[4/200][126/391] Loss_D: 1.4086 Loss_G: 0.8553 D(x): 0.5721 D(G(z)): 0.5721 / 0.4254\n",
            "[4/200][127/391] Loss_D: 1.4101 Loss_G: 0.5522 D(x): 0.4254 D(G(z)): 0.4254 / 0.5761\n",
            "[4/200][128/391] Loss_D: 1.4110 Loss_G: 0.8599 D(x): 0.5761 D(G(z)): 0.5761 / 0.4235\n",
            "[4/200][129/391] Loss_D: 1.4113 Loss_G: 0.5522 D(x): 0.4235 D(G(z)): 0.4235 / 0.5761\n",
            "[4/200][130/391] Loss_D: 1.4111 Loss_G: 0.8561 D(x): 0.5761 D(G(z)): 0.5761 / 0.4251\n",
            "[4/200][131/391] Loss_D: 1.4103 Loss_G: 0.5573 D(x): 0.4251 D(G(z)): 0.4251 / 0.5731\n",
            "[4/200][132/391] Loss_D: 1.4093 Loss_G: 0.8461 D(x): 0.5731 D(G(z)): 0.5731 / 0.4294\n",
            "[4/200][133/391] Loss_D: 1.4078 Loss_G: 0.5651 D(x): 0.4294 D(G(z)): 0.4294 / 0.5687\n",
            "[4/200][134/391] Loss_D: 1.4068 Loss_G: 0.8381 D(x): 0.5687 D(G(z)): 0.5687 / 0.4328\n",
            "[4/200][135/391] Loss_D: 1.4059 Loss_G: 0.5707 D(x): 0.4328 D(G(z)): 0.4329 / 0.5655\n",
            "[4/200][136/391] Loss_D: 1.4050 Loss_G: 0.8308 D(x): 0.5655 D(G(z)): 0.5655 / 0.4360\n",
            "[4/200][137/391] Loss_D: 1.4042 Loss_G: 0.5764 D(x): 0.4360 D(G(z)): 0.4360 / 0.5623\n",
            "[4/200][138/391] Loss_D: 1.4034 Loss_G: 0.8229 D(x): 0.5623 D(G(z)): 0.5623 / 0.4394\n",
            "[4/200][139/391] Loss_D: 1.4025 Loss_G: 0.5829 D(x): 0.4394 D(G(z)): 0.4394 / 0.5587\n",
            "[4/200][140/391] Loss_D: 1.4016 Loss_G: 0.8144 D(x): 0.5587 D(G(z)): 0.5587 / 0.4432\n",
            "[4/200][141/391] Loss_D: 1.4007 Loss_G: 0.5897 D(x): 0.4432 D(G(z)): 0.4432 / 0.5549\n",
            "[4/200][142/391] Loss_D: 1.3998 Loss_G: 0.8057 D(x): 0.5549 D(G(z)): 0.5549 / 0.4471\n",
            "[4/200][143/391] Loss_D: 1.3989 Loss_G: 0.5967 D(x): 0.4471 D(G(z)): 0.4471 / 0.5510\n",
            "[4/200][144/391] Loss_D: 1.3981 Loss_G: 0.7973 D(x): 0.5510 D(G(z)): 0.5510 / 0.4509\n",
            "[4/200][145/391] Loss_D: 1.3974 Loss_G: 0.6034 D(x): 0.4509 D(G(z)): 0.4508 / 0.5473\n",
            "[4/200][146/391] Loss_D: 1.3967 Loss_G: 0.7895 D(x): 0.5473 D(G(z)): 0.5473 / 0.4544\n",
            "[4/200][147/391] Loss_D: 1.3960 Loss_G: 0.6095 D(x): 0.4544 D(G(z)): 0.4544 / 0.5440\n",
            "[4/200][148/391] Loss_D: 1.3954 Loss_G: 0.7826 D(x): 0.5440 D(G(z)): 0.5440 / 0.4575\n",
            "[4/200][149/391] Loss_D: 1.3949 Loss_G: 0.6149 D(x): 0.4575 D(G(z)): 0.4575 / 0.5411\n",
            "[4/200][150/391] Loss_D: 1.3944 Loss_G: 0.7767 D(x): 0.5411 D(G(z)): 0.5411 / 0.4602\n",
            "[4/200][151/391] Loss_D: 1.3940 Loss_G: 0.6196 D(x): 0.4602 D(G(z)): 0.4602 / 0.5385\n",
            "[4/200][152/391] Loss_D: 1.3936 Loss_G: 0.7719 D(x): 0.5385 D(G(z)): 0.5385 / 0.4624\n",
            "[4/200][153/391] Loss_D: 1.3933 Loss_G: 0.6227 D(x): 0.4624 D(G(z)): 0.4624 / 0.5369\n",
            "[4/200][154/391] Loss_D: 1.3931 Loss_G: 0.7693 D(x): 0.5369 D(G(z)): 0.5369 / 0.4636\n",
            "[4/200][155/391] Loss_D: 1.3929 Loss_G: 0.6244 D(x): 0.4636 D(G(z)): 0.4636 / 0.5359\n",
            "[4/200][156/391] Loss_D: 1.3928 Loss_G: 0.7676 D(x): 0.5359 D(G(z)): 0.5359 / 0.4644\n",
            "[4/200][157/391] Loss_D: 1.3927 Loss_G: 0.6256 D(x): 0.4644 D(G(z)): 0.4644 / 0.5353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-548503308613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# train with real\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mreal_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fe7riNvWoko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_images(tensor):\n",
        "\n",
        "    min_val = float(tensor.min())\n",
        "    max_val = float(tensor.max())\n",
        "    tensor.clamp_(min=min_val, max=max_val)\n",
        "    tensor.add_(-min_val).div_(max_val-min_val+1e-5)\n",
        "\n",
        "    images = (\n",
        "        tensor\n",
        "        .mul_(255)\n",
        "        .add_(0.5)\n",
        "        .clamp_(0, 255)\n",
        "        .permute(0, 2, 3, 1)\n",
        "        .to(\"cpu\", dtype=torch.uint8)\n",
        "        .numpy()\n",
        "    )\n",
        "\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BibIj2CnhmUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_quantizer(model, optimzier, niters, fname):\n",
        "    model.train()\n",
        "    with tqdm(range(niters), position=0, leave=True) as pbar:\n",
        "        for idx in pbar:\n",
        "\n",
        "            quantize, loss, embedding_idx = model(torch.load(fname).detach())\n",
        "\n",
        "            model.zero_grad()\n",
        "            if loss.grad_fn is not None: \n",
        "                loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.set_description(f\"loss: {loss.item():.6f}\")\n",
        "\n",
        "    return quantize.cpu(), loss.cpu(), embedding_idx.cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZxLRGN3l6DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_histgram(embedding_idx):\n",
        "    indexes, values = np.unique(embedding_idx.numpy(), return_counts=True)\n",
        "    return indexes, values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHV07M0brqbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}