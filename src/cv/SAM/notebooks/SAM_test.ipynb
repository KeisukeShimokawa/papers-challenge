{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAM test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7xbyoNCzW02ORHCV3Gdzq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeisukeShimokawa/papers-challenge/blob/master/src/cv/SAM/notebooks/SAM_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqx2JCVEY80i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b7397ac6-8490-4f68-dd6d-fe529ae9e88b"
      },
      "source": [
        "!pip list | grep torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch                         1.6.0+cu101    \n",
            "torchsummary                  1.5.1          \n",
            "torchtext                     0.3.1          \n",
            "torchvision                   0.7.0+cu101    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9Xxjw0aisRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sR1_1OuZJUB",
        "colab_type": "text"
      },
      "source": [
        "まずは確認のために、以下の特徴マップをSAMの入力値と考える。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gny-uTDWiwou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c7826dd-ba43-4f1c-c786-1882d93d45c2"
      },
      "source": [
        "inputs = torch.randn(10, 64, 16, 16)\n",
        "\n",
        "print(\"input feature map: \", inputs.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input feature map:  torch.Size([10, 64, 16, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnQRrnKoaU2j",
        "colab_type": "text"
      },
      "source": [
        "以下ではパッチワイズのSelf-Attentionを考えていく。\n",
        "\n",
        "$$\\boldsymbol{y}_{i}=\\sum_{j \\in \\mathcal{R}(i)} \\alpha\\left(\\boldsymbol{x}_{R(i)}\\right)_{j} \\odot \\beta\\left(\\boldsymbol{x}_{j}\\right)$$\n",
        "\n",
        "このパッチワイズの計算のうち、左側のパッチ領域に対する計算では、アダマール積を計算する対象と形状を合わせる$\\gamma(\\cdot)$と関係性を計算する$\\delta(\\cdot)$に分解する。\n",
        "\n",
        "$$\\gamma\\left(\\delta\\left(\\boldsymbol{x}_{\\mathcal{R}(i)}\\right)\\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKPhOSlbi5bb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60e58275-d052-4286-f6b8-e8a72c0b71da"
      },
      "source": [
        "in_planes  = inputs.shape[1] # 入力チャンネル\n",
        "rel_planes = in_planes // 16 # α\n",
        "out_planes = in_planes // 4  # β\n",
        "print(in_planes, rel_planes, out_planes)\n",
        "\n",
        "# 計算の設定を行う\n",
        "share_planes = 8\n",
        "kernel_size = 7\n",
        "stride = 1\n",
        "dilation = 1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64 4 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT3gakV0cEOA",
        "colab_type": "text"
      },
      "source": [
        "以下の計算では、Attention計算に利用するパッチ領域に対して、計算コストを削減するため1x1畳み込み演算を使用してチャンネル数を小さくする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAzxGymNjxj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "11930e8d-737a-4978-b221-abcfeb3d4806"
      },
      "source": [
        "# step1\n",
        "conv1 = nn.Conv2d(in_planes, rel_planes, kernel_size=1)\n",
        "conv2 = nn.Conv2d(in_planes, rel_planes, kernel_size=1)\n",
        "conv3 = nn.Conv2d(in_planes, out_planes, kernel_size=1)\n",
        "\n",
        "x1, x2, x3 = conv1(inputs), conv2(inputs), conv3(inputs)\n",
        "\n",
        "print(f\"x1: {x1.shape}\")\n",
        "print(f\"x2: {x2.shape}\")\n",
        "print(f\"x3: {x3.shape}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1: torch.Size([10, 4, 16, 16])\n",
            "x2: torch.Size([10, 4, 16, 16])\n",
            "x3: torch.Size([10, 16, 16, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-NgaCYYc4I_",
        "colab_type": "text"
      },
      "source": [
        "Self-Attention計算では、あるピクセル位置での特徴ベクトルと、その周辺のピクセルを含む特徴ベクトルに対してAttention計算を実施する。\n",
        "\n",
        "そこでまずはQueryとなる各ピクセル位置での特徴ベクトルを計算するために形状を変更する。\n",
        "\n",
        "具体的には、高さと幅の次元を1つにまとめる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BdhJCKckM_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0f3b7cd-6205-4814-974d-f5829684fd40"
      },
      "source": [
        "x1_reshape = x1.view(x1.shape[0], -1, 1, x1.shape[2] * x1.shape[3])\n",
        "\n",
        "print(f\"x1 reshape: {x1_reshape.shape}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1 reshape: torch.Size([10, 4, 1, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQIPzpymlzKe",
        "colab_type": "text"
      },
      "source": [
        "pytorchのUnfold関数の出力値\n",
        "\n",
        "$$\n",
        "(N, C \\times \\Pi(\\text { kernel_size }), L)\n",
        "$$\n",
        "\n",
        "この$L$とは以下の計算に従う。なお$d$は空間方向の次元数である。\n",
        "\n",
        "$$\n",
        "L=\\prod_{d}\\left[\\frac{\\text{spatial_size}[d]+2 \\times \\text{padding}[d]-\\text{dilation}[d] \\times\\left(\\text{kernel_size}[d]-1\\right)-1}{\\text{stride}[d]}+1\\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfF1CyjGmaqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "84f7027c-5bce-47ff-f1c6-a44fa7c75f97"
      },
      "source": [
        "# paddingしたサイズと、Kernel_size-1のサイズが等しくなるので\n",
        "# 単純に入力された空間次元数をかけ合わせたものになる。(16x16=256)\n",
        "(((16+3*2) + 2 * 0 - (kernel_size - 1) - 1) + 1) ** 2"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACZX83i3mziY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dfc59808-1e9a-4082-ccf4-57304c67f39d"
      },
      "source": [
        "# C x Product(kernel_size)\n",
        "4   * kernel_size ** 2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mug0qZd5lsqv",
        "colab_type": "text"
      },
      "source": [
        "ここで行うPaddingとUnfoldのイメージは以下のようなものになる。\n",
        "\n",
        "![](https://www.dropbox.com/s/ieal9ylytzdga44/SAMPatch.jpg?dl=1)\n",
        "\n",
        "このイメージに従い、パッチ領域に合わせて特徴マップを変形させていく。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO5x_a5JkkE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "22f8c588-6ed8-4e1f-fa0c-d67a1177cc05"
      },
      "source": [
        "# 設定していたとおり、PaddingとUnfoldを初期化する\n",
        "unfold_x2 = nn.Unfold(kernel_size=kernel_size, dilation=dilation, padding=0, stride=stride)\n",
        "pad = nn.ReflectionPad2d(kernel_size // 2)\n",
        "\n",
        "# カーネルサイズに合わせてPaddingを設定する。\n",
        "# Paddingは通常の畳み込み演算を行う場合と考え方は変わらない\n",
        "x2_padded = pad(x2)\n",
        "print(f\"x2 padded: {x2_padded.shape}\")\n",
        "\n",
        "# これで上のイメージ図の右側のパッチ領域を計算できる\n",
        "x2_unfold = unfold_x2(x2_padded)\n",
        "print(f\"x2 unfold: {x2_unfold.shape}\")\n",
        "\n",
        "# ピクセルごとの特徴ベクトルを計算したテンソルと形状を合わせる\n",
        "x2_reshape = x2_unfold.view(x1_reshape.shape[0], -1, 1, x1_reshape.shape[-1])\n",
        "print(f\"s2 reshape: {x2_reshape.shape}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x2 padded: torch.Size([10, 4, 22, 22])\n",
            "x2 unfold: torch.Size([10, 196, 256])\n",
            "s2 reshape: torch.Size([10, 196, 1, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcvDTxF3oV8c",
        "colab_type": "text"
      },
      "source": [
        "これで以下のように特徴ベクトルとパッチ領域のベクトルを取得できた。\n",
        "\n",
        "$$x_{1}:\\left[B, C, 1, H\\times{W}\\right]$$\n",
        "\n",
        "$$x_{2}:\\left[B, C\\times{\\text{kernel_size}^2}, 1, H\\times{W}\\right]$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WvAnPG_lA9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "07a3e690-3f4f-4be8-99dd-1f0fbbb03ed7"
      },
      "source": [
        "print(f\"x1 reshape: {x1_reshape.shape}\")\n",
        "print(f\"x2 reshape: {x2_reshape.shape}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1 reshape: torch.Size([10, 4, 1, 256])\n",
            "x2 reshape: torch.Size([10, 196, 1, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRg2j1akpB_R",
        "colab_type": "text"
      },
      "source": [
        "次に、QueryとKeyの特徴マップを結合させる。\n",
        "\n",
        "$$\\text { Concatenation: } \\delta\\left(\\mathbf{x}_{\\mathcal{R}(i)}\\right)=\\left[\\varphi\\left(\\mathbf{x}_{i}\\right),\\left[\\psi\\left(\\mathbf{x}_{j}\\right)\\right]_{V j \\in \\mathcal{R}(i)}\\right]$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZXiiGJ8p3Cl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "07068e81-fad6-47c3-fd96-f85b3afefc15"
      },
      "source": [
        "w_concat = torch.cat((x1_reshape, x2_reshape), dim=1)\n",
        "print(f\"w concat: {w_concat.shape}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w concat: torch.Size([10, 200, 1, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-UbVsTstywe",
        "colab_type": "text"
      },
      "source": [
        "次に結合させた特徴マップを、Valueとなる特徴マップと計算する前に、非線形な変換を行う。\n",
        "\n",
        "この際には論文中の以下の表に則り、2層のマッピング関数を使用する。\n",
        "\n",
        "![](https://www.dropbox.com/s/8zway0blqmeopc5/SAM%20mapping.png?dl=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4ZVjpy6vd44",
        "colab_type": "text"
      },
      "source": [
        "以下で計算した特徴マップを$\\beta$側に組み込むが、カーネルを共有する設定を設けているため、そのまま出力するのではなく、共有するカーネル分に合わせてチャンネル数を調整する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEM8O9CHpHbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cefa8f74-43ee-4ba5-f923-3db7b9f39757"
      },
      "source": [
        "# 以下では1x1畳み込みを使用する。その際にはボトルネック構造を採用してチャンネル数を削減している。\n",
        "conv_w = nn.Sequential(\n",
        "    nn.BatchNorm2d(rel_planes * (1 + pow(kernel_size, 2))),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(rel_planes * (1 + pow(kernel_size, 2)), out_planes // share_planes, kernel_size=1, bias=False),\n",
        "    nn.BatchNorm2d(out_planes // share_planes),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(out_planes // share_planes, pow(kernel_size, 2) * out_planes // share_planes, kernel_size=1)\n",
        ")\n",
        "\n",
        "w_conv = conv_w(w_concat)\n",
        "print(f\"w conv: {w_conv.shape}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w conv: torch.Size([10, 98, 1, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Nn-SFuxP1S",
        "colab_type": "text"
      },
      "source": [
        "次にカーネルサイズの大きさの次元を、他の次元に分離させ、各ピクセル位置でのパッチサイズに合わせた、チャンネル数に従う次元をもつ特徴マップを取得することができる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WglI_dZXvFnV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3739e74a-8d52-4993-957d-7879bec3bfdf"
      },
      "source": [
        "w_reshape = w_conv.view(x1_reshape.shape[0], -1, pow(kernel_size, 2), x1_reshape.shape[-1])\n",
        "print(f\"w reshape: {w_reshape.shape}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w reshape: torch.Size([10, 2, 49, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLCbEuq2yLcY",
        "colab_type": "text"
      },
      "source": [
        "ここまでで$\\alpha$部分と$\\beta$部分を計算することができた。\n",
        "\n",
        "ここで`shared_kernel`に従ってAttentionの重みを共有する。\n",
        "\n",
        "$$\\beta\\left(\\boldsymbol{x}_{j}\\right):\\left[B, C_{out}, H, W\\right]$$\n",
        "\n",
        "$$\\alpha\\left(\\boldsymbol{x}_{R(i)}\\right)_{j}:\\left[B, \\frac{C_{out}}{\\text{groups}}, \\text{kernel_size}^2, H\\times{W}\\right]$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvIzAhs6Vzao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6VwNF1OVzBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3ae4434e-6bdc-4db5-a461-ccff291e9b45"
      },
      "source": [
        "print('beta feature map:  {}'.format(x3.shape))\n",
        "print('alpha feature map: {}'.format(w_reshape.shape))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beta feature map:  torch.Size([10, 16, 16, 16])\n",
            "alpha feature map: torch.Size([10, 2, 49, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1anloS6Wktc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0e7f6566-8160-46b1-9a83-93a8f4a9ee2c"
      },
      "source": [
        "unfold_x3 = nn.Unfold(kernel_size=kernel_size, dilation=dilation, padding=0, stride=stride)\n",
        "pad_x3 = nn.ReflectionPad2d(kernel_size // 2)\n",
        "\n",
        "x3_padded = pad_x3(x3)\n",
        "print(x3_padded.shape)\n",
        "\n",
        "x3_unfold = unfold_x3(x3_padded)\n",
        "print(x3_unfold.shape)\n",
        "\n",
        "x3_reshape = x3_unfold.view(x3_padded.shape[0], -1, pow(kernel_size, 2), x3_unfold.shape[-1])\n",
        "print(x3_reshape.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 16, 22, 22])\n",
            "torch.Size([10, 784, 256])\n",
            "torch.Size([10, 16, 49, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq4srIRQtJsj",
        "colab_type": "text"
      },
      "source": [
        "## Autual Sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2Et8I23PYdy",
        "colab_type": "text"
      },
      "source": [
        "なおカーネルサイズはストライドなど、高さと幅方向に同じ値を設定する場合は、以下のようにスカラー値からタプル形式のオブジェクトを取得できる。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r-TKLNumPTi3",
        "colab": {}
      },
      "source": [
        "from torch.nn.modules.utils import _pair\n",
        "\n",
        "\n",
        "pad_mode = 1\n",
        "\n",
        "\n",
        "kernel_size_pair = _pair(kernel_size)\n",
        "stride_pair = _pair(stride)\n",
        "padding_pair = _pair(kernel_size // 2)\n",
        "dilation_pair = _pair(dilation)\n",
        "\n",
        "print(kernel_size_pair)\n",
        "print(stride_pair)\n",
        "print(padding_pair)\n",
        "print(dilation_pair)\n",
        "print(pad_mode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTLXqrTGyhug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SAM(nn.Module):\n",
        "    def __init__(self, sa_type, in_planes, rel_planes, out_planes, share_planes, kernel_size=3, stride=1, dilation=1):\n",
        "        super(SAM, self).__init__()\n",
        "        self.sa_type, self.kernel_size, self.stride = sa_type, kernel_size, stride\n",
        "        self.conv1 = nn.Conv2d(in_planes, rel_planes, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(in_planes, rel_planes, kernel_size=1)\n",
        "        self.conv3 = nn.Conv2d(in_planes, out_planes, kernel_size=1)\n",
        "        self.conv_w = nn.Sequential(nn.BatchNorm2d(rel_planes * (pow(kernel_size, 2) + 1)),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(rel_planes * (pow(kernel_size, 2) + 1), out_planes // share_planes, kernel_size=1, bias=False),\n",
        "                                    nn.BatchNorm2d(out_planes // share_planes),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(out_planes // share_planes, pow(kernel_size, 2) * out_planes // share_planes, kernel_size=1))\n",
        "        self.unfold_i = nn.Unfold(kernel_size=1, dilation=dilation, padding=0, stride=stride)\n",
        "        self.unfold_j = nn.Unfold(kernel_size=kernel_size, dilation=dilation, padding=0, stride=stride)\n",
        "        self.pad = nn.ReflectionPad2d(kernel_size // 2)\n",
        "        # self.aggregation = Aggregation(kernel_size, stride, (dilation * (kernel_size - 1) + 1) // 2, dilation, pad_mode=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1, x2, x3 = self.conv1(x), self.conv2(x), self.conv3(x)\n",
        "        if self.sa_type == 0:  # pairwise\n",
        "            p = self.conv_p(position(x.shape[2], x.shape[3], x.is_cuda))\n",
        "            w = self.softmax(self.conv_w(torch.cat([self.subtraction2(x1, x2), self.subtraction(p).repeat(x.shape[0], 1, 1, 1)], 1)))\n",
        "        else:  # patchwise\n",
        "            if self.stride != 1:\n",
        "                x1 = self.unfold_i(x1)\n",
        "            x1 = x1.view(x.shape[0], -1, 1, x.shape[2]*x.shape[3])\n",
        "            x2 = self.unfold_j(self.pad(x2)).view(x.shape[0], -1, 1, x1.shape[-1])\n",
        "            w = self.conv_w(torch.cat([x1, x2], 1)).view(x.shape[0], -1, pow(self.kernel_size, 2), x1.shape[-1])\n",
        "        print(x3.shape)\n",
        "        print(w.shape)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUnJgvLRyscH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sam_sample = SAM(sa_type=1,\n",
        "                 in_planes=in_planes,\n",
        "                 rel_planes=rel_planes,\n",
        "                 out_planes=out_planes,\n",
        "                 share_planes=share_planes,\n",
        "                 kernel_size=kernel_size,\n",
        "                 stride=stride,\n",
        "                 dilation=dilation)\n",
        "\n",
        "sam_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT0Xtooky9Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = sam_sample(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6ScwVugzJz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXWeqv_rFn7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Conv2d(10, 20, kernel_size=3, stride=1, padding=1, groups=1).weight.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTKtcAUQFuFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Conv2d(10, 20, kernel_size=3, stride=1, padding=1, groups=2).weight.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwDTQQUEF1fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Conv2d(4, 6, kernel_size=3, stride=1, padding=1, groups=2).weight.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbf0NefJMfvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}